{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Public code for submitted paper \"DMBGN: Deep Multi-Behavior Graph Networks for Voucher Redemption Rate Prediction\" for SIGKDD 2021. This code covers the experimental results in Chapter 5 in the submitted paper. Note that the following experiments are conducted on a randomly desensitized sampled dataset from original dataset (Region C) mentioned in the paper, all related id features are hashed for public use.\n",
    "\n",
    "This notebook is organized into 5 parts:\n",
    "1. Data Processing: generate the training data from the original log table (for log description, please refer to README.md file under ./data directory\n",
    "2. Baseline Models: corresponding to 5 baseline models compared in the submitted paper, including LR, GBDT, DNN, WDL and DIN model.\n",
    "3. Proposed Method: DMBGN: our proposed model, which includes experiment 2 variants of DMBGN (AvgPooling and Pretrained) with our final model DMBGN\n",
    "4. Summary: a summary of experiment results\n",
    "5. Reference\n",
    "\n",
    "The content of this notebook is as:\n",
    "- 1 Data Processing\n",
    "  - 1.1 Logs Processing\n",
    "  - 1.2 Label Encoding and Normalization\n",
    "- 2 Baseline Models\n",
    "  - 2.1 LR\n",
    "  - 2.2 GBDT\n",
    "  - 2.3 DNN\n",
    "  - 2.4 WDL\n",
    "  - 2.5 DIN\n",
    "- 3 Proposed Method: DMBGN\n",
    "  - 3.1 DMBGN-AvgPooling\n",
    "  - 3.2 DMBGN-Pretrained\n",
    "    - 3.2.1 UVG Graphs\n",
    "    - 3.2.2 GNN Networks\n",
    "      - 3.2.2.1 Get Pretrained Item Embedding\n",
    "      - 3.2.2.2 Train GNN\n",
    "      - 3.2.2.3 Generate Pretrained UVG Embedding\n",
    "      - 3.2.2.4 GMBDN Log Processing\n",
    "  - 3.3 DMBGN\n",
    "- 4 Summary\n",
    "- 5 Reference\n",
    "\n",
    "\n",
    "Note that you can run all codes directly for all the results. For DMBGN it might takes a longer time and we used 8 GPUs for accerlation purpose.\n",
    "\n",
    "\n",
    "Author: \\\n",
    "    Lin Li (boolean.ll@alibaba-inc.com) \\\n",
    "    Fengtong Xiao (fengtong.xiao@alibaba-inc.com) \\\n",
    "    Weinan Xu (stella.xu@lazada.com)\n",
    "\n",
    "References: \\\n",
    "    DMBGN: Deep Multi-Behavior Graph Networks for Voucher Redemption Rate Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:70% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:70% !important; }</style>\"))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandasql as ps\n",
    "\n",
    "import warnings\n",
    "import logging\n",
    "import sys\n",
    "import pickle\n",
    "import csv\n",
    "import os\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "import torch\n",
    "from deepctr_torch.inputs import SparseFeat, DenseFeat,VarLenSparseFeat, get_feature_names\n",
    "from deepctr_torch.models import *\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.setrecursionlimit(9000000) \n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s]: %(message)s')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from models.util import *\n",
    "from models import LabelEncoderExt\n",
    "from models.din import DIN\n",
    "from models.DMBGN import DMBGN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "# def get_device(idx=0):\n",
    "#     if torch.cuda.is_available():\n",
    "#         device = torch.device('cuda')\n",
    "#     else:\n",
    "#         device = torch.device('cpu')\n",
    "#     return device\n",
    "# device_count = torch.cuda.device_count()\n",
    "# device = get_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-20 13:31:22,216 [WARNING]: \n",
      "DeepCTR-PyTorch version 0.2.9 detected. Your version is 0.2.3.\n",
      "Use `pip install -U deepctr-torch` to upgrade.Changelog: https://github.com/shenweichen/DeepCTR-Torch/releases/tag/v0.2.9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((62068, 19), (1118593, 14), (286735, 6))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the pickle file, note you might need to unzip the kdd_data.pkl.zip to recover the pkl file\n",
    "# To unzip, use the following linux commands:\n",
    "# $ cd ./data\n",
    "# $ unzip kdd_data.pkl.zip\n",
    "\n",
    "file_path = './data/kdd_data.pkl'\n",
    "with open(file_path, \"rb\") as f:\n",
    "    log_df = pickle.load(f)\n",
    "    session_df = pickle.load(f)\n",
    "    item_df = pickle.load(f)\n",
    "log_df.shape, session_df.shape, item_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Logs Processing\n",
    "construct the historical UVG sequence following the chronological order \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>label</th>\n",
       "      <th>user_id</th>\n",
       "      <th>promotion_id</th>\n",
       "      <th>voucher_min_spend</th>\n",
       "      <th>voucher_discount</th>\n",
       "      <th>voucher_collect_time</th>\n",
       "      <th>voucher_redeem_time</th>\n",
       "      <th>campaign_name</th>\n",
       "      <th>user_age_level</th>\n",
       "      <th>user_gender</th>\n",
       "      <th>user_purchase_level</th>\n",
       "      <th>user_trd__orders_cnt_hist</th>\n",
       "      <th>user_trd__actual_gmv_usd_hist</th>\n",
       "      <th>user_trd__orders_cnt_platform_discount_hist</th>\n",
       "      <th>user_trd__max_gmv_usd_hist</th>\n",
       "      <th>user_trd__avg_gmv_usd_hist</th>\n",
       "      <th>user_trd__min_gmv_usd_hist</th>\n",
       "      <th>dtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12130_38</td>\n",
       "      <td>1</td>\n",
       "      <td>12130</td>\n",
       "      <td>38</td>\n",
       "      <td>888</td>\n",
       "      <td>80</td>\n",
       "      <td>14363</td>\n",
       "      <td>28292</td>\n",
       "      <td>C3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>706.648652</td>\n",
       "      <td>4.0</td>\n",
       "      <td>79.950388</td>\n",
       "      <td>11.584404</td>\n",
       "      <td>0.827519</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12130_85</td>\n",
       "      <td>0</td>\n",
       "      <td>12130</td>\n",
       "      <td>85</td>\n",
       "      <td>4999</td>\n",
       "      <td>500</td>\n",
       "      <td>49983</td>\n",
       "      <td>49983</td>\n",
       "      <td>C2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>822.218764</td>\n",
       "      <td>9.0</td>\n",
       "      <td>60.165341</td>\n",
       "      <td>8.747008</td>\n",
       "      <td>0.601405</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12156_64</td>\n",
       "      <td>0</td>\n",
       "      <td>12156</td>\n",
       "      <td>64</td>\n",
       "      <td>7799</td>\n",
       "      <td>700</td>\n",
       "      <td>21441</td>\n",
       "      <td>21441</td>\n",
       "      <td>C3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>349.797257</td>\n",
       "      <td>4.0</td>\n",
       "      <td>118.703723</td>\n",
       "      <td>8.531640</td>\n",
       "      <td>0.928380</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12156_91</td>\n",
       "      <td>1</td>\n",
       "      <td>12156</td>\n",
       "      <td>91</td>\n",
       "      <td>799</td>\n",
       "      <td>80</td>\n",
       "      <td>46418</td>\n",
       "      <td>52254</td>\n",
       "      <td>C2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>793.370613</td>\n",
       "      <td>7.0</td>\n",
       "      <td>215.294128</td>\n",
       "      <td>7.778143</td>\n",
       "      <td>0.517295</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12156_310</td>\n",
       "      <td>1</td>\n",
       "      <td>12156</td>\n",
       "      <td>310</td>\n",
       "      <td>349</td>\n",
       "      <td>30</td>\n",
       "      <td>121387</td>\n",
       "      <td>131549</td>\n",
       "      <td>C1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>842.410759</td>\n",
       "      <td>8.0</td>\n",
       "      <td>215.294128</td>\n",
       "      <td>7.589286</td>\n",
       "      <td>0.517295</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62063</th>\n",
       "      <td>11873_319</td>\n",
       "      <td>0</td>\n",
       "      <td>11873</td>\n",
       "      <td>319</td>\n",
       "      <td>1999</td>\n",
       "      <td>200</td>\n",
       "      <td>120575</td>\n",
       "      <td>120575</td>\n",
       "      <td>C1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>884.002906</td>\n",
       "      <td>16.0</td>\n",
       "      <td>260.133633</td>\n",
       "      <td>21.047688</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62064</th>\n",
       "      <td>11873_305</td>\n",
       "      <td>1</td>\n",
       "      <td>11873</td>\n",
       "      <td>305</td>\n",
       "      <td>4999</td>\n",
       "      <td>500</td>\n",
       "      <td>120576</td>\n",
       "      <td>131797</td>\n",
       "      <td>C1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>884.002906</td>\n",
       "      <td>16.0</td>\n",
       "      <td>260.133633</td>\n",
       "      <td>21.047688</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62065</th>\n",
       "      <td>11879_159</td>\n",
       "      <td>0</td>\n",
       "      <td>11879</td>\n",
       "      <td>159</td>\n",
       "      <td>799</td>\n",
       "      <td>70</td>\n",
       "      <td>72071</td>\n",
       "      <td>72071</td>\n",
       "      <td>C0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>340.424720</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.094769</td>\n",
       "      <td>28.368727</td>\n",
       "      <td>3.595659</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62066</th>\n",
       "      <td>11880_38</td>\n",
       "      <td>0</td>\n",
       "      <td>11880</td>\n",
       "      <td>38</td>\n",
       "      <td>888</td>\n",
       "      <td>80</td>\n",
       "      <td>3867</td>\n",
       "      <td>4451</td>\n",
       "      <td>C3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>5085.468023</td>\n",
       "      <td>24.0</td>\n",
       "      <td>501.537557</td>\n",
       "      <td>14.009554</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62067</th>\n",
       "      <td>11880_454</td>\n",
       "      <td>0</td>\n",
       "      <td>11880</td>\n",
       "      <td>454</td>\n",
       "      <td>799</td>\n",
       "      <td>70</td>\n",
       "      <td>125362</td>\n",
       "      <td>125362</td>\n",
       "      <td>C1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>7470.998268</td>\n",
       "      <td>34.0</td>\n",
       "      <td>501.537557</td>\n",
       "      <td>14.852879</td>\n",
       "      <td>0.094030</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62068 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      session_id  label user_id promotion_id  voucher_min_spend  \\\n",
       "0       12130_38      1   12130           38                888   \n",
       "1       12130_85      0   12130           85               4999   \n",
       "2       12156_64      0   12156           64               7799   \n",
       "3       12156_91      1   12156           91                799   \n",
       "4      12156_310      1   12156          310                349   \n",
       "...          ...    ...     ...          ...                ...   \n",
       "62063  11873_319      0   11873          319               1999   \n",
       "62064  11873_305      1   11873          305               4999   \n",
       "62065  11879_159      0   11879          159                799   \n",
       "62066   11880_38      0   11880           38                888   \n",
       "62067  11880_454      0   11880          454                799   \n",
       "\n",
       "       voucher_discount voucher_collect_time voucher_redeem_time  \\\n",
       "0                    80                14363               28292   \n",
       "1                   500                49983               49983   \n",
       "2                   700                21441               21441   \n",
       "3                    80                46418               52254   \n",
       "4                    30               121387              131549   \n",
       "...                 ...                  ...                 ...   \n",
       "62063               200               120575              120575   \n",
       "62064               500               120576              131797   \n",
       "62065                70                72071               72071   \n",
       "62066                80                 3867                4451   \n",
       "62067                70               125362              125362   \n",
       "\n",
       "      campaign_name  user_age_level user_gender  user_purchase_level  \\\n",
       "0                C3             5.0           1                  8.0   \n",
       "1                C2             5.0           1                  8.0   \n",
       "2                C3             4.0           0                  9.0   \n",
       "3                C2             4.0           0                  9.0   \n",
       "4                C1             4.0           0                  9.0   \n",
       "...             ...             ...         ...                  ...   \n",
       "62063            C1             2.0           1                  9.0   \n",
       "62064            C1             2.0           1                  9.0   \n",
       "62065            C0             4.0           0                  8.0   \n",
       "62066            C3             2.0           1                  9.0   \n",
       "62067            C1             2.0           1                  9.0   \n",
       "\n",
       "       user_trd__orders_cnt_hist  user_trd__actual_gmv_usd_hist  \\\n",
       "0                           52.0                     706.648652   \n",
       "1                           69.0                     822.218764   \n",
       "2                           26.0                     349.797257   \n",
       "3                           61.0                     793.370613   \n",
       "4                           65.0                     842.410759   \n",
       "...                          ...                            ...   \n",
       "62063                       18.0                     884.002906   \n",
       "62064                       18.0                     884.002906   \n",
       "62065                       10.0                     340.424720   \n",
       "62066                      169.0                    5085.468023   \n",
       "62067                      214.0                    7470.998268   \n",
       "\n",
       "       user_trd__orders_cnt_platform_discount_hist  \\\n",
       "0                                              4.0   \n",
       "1                                              9.0   \n",
       "2                                              4.0   \n",
       "3                                              7.0   \n",
       "4                                              8.0   \n",
       "...                                            ...   \n",
       "62063                                         16.0   \n",
       "62064                                         16.0   \n",
       "62065                                          1.0   \n",
       "62066                                         24.0   \n",
       "62067                                         34.0   \n",
       "\n",
       "       user_trd__max_gmv_usd_hist  user_trd__avg_gmv_usd_hist  \\\n",
       "0                       79.950388                   11.584404   \n",
       "1                       60.165341                    8.747008   \n",
       "2                      118.703723                    8.531640   \n",
       "3                      215.294128                    7.778143   \n",
       "4                      215.294128                    7.589286   \n",
       "...                           ...                         ...   \n",
       "62063                  260.133633                   21.047688   \n",
       "62064                  260.133633                   21.047688   \n",
       "62065                   53.094769                   28.368727   \n",
       "62066                  501.537557                   14.009554   \n",
       "62067                  501.537557                   14.852879   \n",
       "\n",
       "       user_trd__min_gmv_usd_hist  dtype  \n",
       "0                        0.827519  train  \n",
       "1                        0.601405   test  \n",
       "2                        0.928380   test  \n",
       "3                        0.517295   test  \n",
       "4                        0.517295  train  \n",
       "...                           ...    ...  \n",
       "62063                    0.000000  train  \n",
       "62064                    0.000000  train  \n",
       "62065                    3.595659   test  \n",
       "62066                    0.000000  train  \n",
       "62067                    0.094030   test  \n",
       "\n",
       "[62068 rows x 19 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = \"select *, ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY CAST(voucher_collect_time AS BIGINT) ASC) as rk from {logdf}\".format(logdf=\"log_df\")\n",
    "log_df = ps.sqldf(q1, locals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>label</th>\n",
       "      <th>user_id</th>\n",
       "      <th>promotion_id</th>\n",
       "      <th>voucher_min_spend</th>\n",
       "      <th>voucher_discount</th>\n",
       "      <th>voucher_collect_time</th>\n",
       "      <th>voucher_redeem_time</th>\n",
       "      <th>campaign_name</th>\n",
       "      <th>user_age_level</th>\n",
       "      <th>...</th>\n",
       "      <th>user_trd__orders_cnt_platform_discount_hist</th>\n",
       "      <th>user_trd__max_gmv_usd_hist</th>\n",
       "      <th>user_trd__avg_gmv_usd_hist</th>\n",
       "      <th>user_trd__min_gmv_usd_hist</th>\n",
       "      <th>dtype</th>\n",
       "      <th>rk</th>\n",
       "      <th>hist_session_id</th>\n",
       "      <th>hist_promotion_id</th>\n",
       "      <th>hist_rk</th>\n",
       "      <th>hist_voucher_collect_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>299</td>\n",
       "      <td>30</td>\n",
       "      <td>45451</td>\n",
       "      <td>45521</td>\n",
       "      <td>C2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.376755</td>\n",
       "      <td>3.917888</td>\n",
       "      <td>2.518198</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_425</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>425</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>100489</td>\n",
       "      <td>132869</td>\n",
       "      <td>C1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.976711</td>\n",
       "      <td>8.408431</td>\n",
       "      <td>0.739039</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10_82</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>82</td>\n",
       "      <td>299</td>\n",
       "      <td>30</td>\n",
       "      <td>46827</td>\n",
       "      <td>48182</td>\n",
       "      <td>C2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.972645</td>\n",
       "      <td>3.039102</td>\n",
       "      <td>1.498169</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100_82</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>82</td>\n",
       "      <td>299</td>\n",
       "      <td>30</td>\n",
       "      <td>46227</td>\n",
       "      <td>46227</td>\n",
       "      <td>C2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>34.0</td>\n",
       "      <td>397.755770</td>\n",
       "      <td>17.843147</td>\n",
       "      <td>0.003525</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000_386</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>386</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>96836</td>\n",
       "      <td>96836</td>\n",
       "      <td>C1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83457</th>\n",
       "      <td>6777_391</td>\n",
       "      <td>0</td>\n",
       "      <td>6777</td>\n",
       "      <td>391</td>\n",
       "      <td>199</td>\n",
       "      <td>30</td>\n",
       "      <td>128346</td>\n",
       "      <td>128346</td>\n",
       "      <td>C1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>93.471440</td>\n",
       "      <td>7.419820</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>train</td>\n",
       "      <td>102</td>\n",
       "      <td>6777_248</td>\n",
       "      <td>248</td>\n",
       "      <td>39</td>\n",
       "      <td>74788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83458</th>\n",
       "      <td>6777_383</td>\n",
       "      <td>0</td>\n",
       "      <td>6777</td>\n",
       "      <td>383</td>\n",
       "      <td>500</td>\n",
       "      <td>50</td>\n",
       "      <td>128346</td>\n",
       "      <td>128346</td>\n",
       "      <td>C1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>93.471440</td>\n",
       "      <td>7.419820</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>train</td>\n",
       "      <td>103</td>\n",
       "      <td>6777_138</td>\n",
       "      <td>138</td>\n",
       "      <td>2</td>\n",
       "      <td>39379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83459</th>\n",
       "      <td>6777_383</td>\n",
       "      <td>0</td>\n",
       "      <td>6777</td>\n",
       "      <td>383</td>\n",
       "      <td>500</td>\n",
       "      <td>50</td>\n",
       "      <td>128346</td>\n",
       "      <td>128346</td>\n",
       "      <td>C1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>93.471440</td>\n",
       "      <td>7.419820</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>train</td>\n",
       "      <td>103</td>\n",
       "      <td>6777_206</td>\n",
       "      <td>206</td>\n",
       "      <td>17</td>\n",
       "      <td>59004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83460</th>\n",
       "      <td>6777_383</td>\n",
       "      <td>0</td>\n",
       "      <td>6777</td>\n",
       "      <td>383</td>\n",
       "      <td>500</td>\n",
       "      <td>50</td>\n",
       "      <td>128346</td>\n",
       "      <td>128346</td>\n",
       "      <td>C1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>93.471440</td>\n",
       "      <td>7.419820</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>train</td>\n",
       "      <td>103</td>\n",
       "      <td>6777_215</td>\n",
       "      <td>215</td>\n",
       "      <td>27</td>\n",
       "      <td>64992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83461</th>\n",
       "      <td>6777_383</td>\n",
       "      <td>0</td>\n",
       "      <td>6777</td>\n",
       "      <td>383</td>\n",
       "      <td>500</td>\n",
       "      <td>50</td>\n",
       "      <td>128346</td>\n",
       "      <td>128346</td>\n",
       "      <td>C1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>93.471440</td>\n",
       "      <td>7.419820</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>train</td>\n",
       "      <td>103</td>\n",
       "      <td>6777_248</td>\n",
       "      <td>248</td>\n",
       "      <td>39</td>\n",
       "      <td>74788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83462 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      session_id  label user_id promotion_id  voucher_min_spend  \\\n",
       "0           0_82      0       0           82                299   \n",
       "1          1_425      0       1          425                 40   \n",
       "2          10_82      0      10           82                299   \n",
       "3         100_82      0     100           82                299   \n",
       "4       1000_386      0    1000          386                  0   \n",
       "...          ...    ...     ...          ...                ...   \n",
       "83457   6777_391      0    6777          391                199   \n",
       "83458   6777_383      0    6777          383                500   \n",
       "83459   6777_383      0    6777          383                500   \n",
       "83460   6777_383      0    6777          383                500   \n",
       "83461   6777_383      0    6777          383                500   \n",
       "\n",
       "       voucher_discount voucher_collect_time voucher_redeem_time  \\\n",
       "0                    30                45451               45521   \n",
       "1                     4               100489              132869   \n",
       "2                    30                46827               48182   \n",
       "3                    30                46227               46227   \n",
       "4                    60                96836               96836   \n",
       "...                 ...                  ...                 ...   \n",
       "83457                30               128346              128346   \n",
       "83458                50               128346              128346   \n",
       "83459                50               128346              128346   \n",
       "83460                50               128346              128346   \n",
       "83461                50               128346              128346   \n",
       "\n",
       "      campaign_name  user_age_level  ...  \\\n",
       "0                C2             4.0  ...   \n",
       "1                C1             0.0  ...   \n",
       "2                C2             NaN  ...   \n",
       "3                C2             3.0  ...   \n",
       "4                C1             3.0  ...   \n",
       "...             ...             ...  ...   \n",
       "83457            C1             4.0  ...   \n",
       "83458            C1             4.0  ...   \n",
       "83459            C1             4.0  ...   \n",
       "83460            C1             4.0  ...   \n",
       "83461            C1             4.0  ...   \n",
       "\n",
       "      user_trd__orders_cnt_platform_discount_hist  user_trd__max_gmv_usd_hist  \\\n",
       "0                                             0.0                    6.376755   \n",
       "1                                             1.0                   27.976711   \n",
       "2                                             0.0                    4.972645   \n",
       "3                                            34.0                  397.755770   \n",
       "4                                             0.0                    0.000000   \n",
       "...                                           ...                         ...   \n",
       "83457                                        50.0                   93.471440   \n",
       "83458                                        50.0                   93.471440   \n",
       "83459                                        50.0                   93.471440   \n",
       "83460                                        50.0                   93.471440   \n",
       "83461                                        50.0                   93.471440   \n",
       "\n",
       "       user_trd__avg_gmv_usd_hist  user_trd__min_gmv_usd_hist  dtype   rk  \\\n",
       "0                        3.917888                    2.518198  train    1   \n",
       "1                        8.408431                    0.739039  train    1   \n",
       "2                        3.039102                    1.498169  train    1   \n",
       "3                       17.843147                    0.003525  train    1   \n",
       "4                        0.000000                    0.000000  train    1   \n",
       "...                           ...                         ...    ...  ...   \n",
       "83457                    7.419820                    0.000000  train  102   \n",
       "83458                    7.419820                    0.000000  train  103   \n",
       "83459                    7.419820                    0.000000  train  103   \n",
       "83460                    7.419820                    0.000000  train  103   \n",
       "83461                    7.419820                    0.000000  train  103   \n",
       "\n",
       "       hist_session_id  hist_promotion_id hist_rk  hist_voucher_collect_time  \n",
       "0                                                                       None  \n",
       "1                                                                       None  \n",
       "2                                                                       None  \n",
       "3                                                                       None  \n",
       "4                                                                       None  \n",
       "...                ...                ...     ...                        ...  \n",
       "83457         6777_248                248      39                      74788  \n",
       "83458         6777_138                138       2                      39379  \n",
       "83459         6777_206                206      17                      59004  \n",
       "83460         6777_215                215      27                      64992  \n",
       "83461         6777_248                248      39                      74788  \n",
       "\n",
       "[83462 rows x 24 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = \" SELECT L.* \\\n",
    "            , coalesce(R.session_id, '') AS hist_session_id \\\n",
    "            , coalesce(R.promotion_id, '') AS hist_promotion_id \\\n",
    "            , coalesce(R.rk, '') AS hist_rk \\\n",
    "            , R.voucher_collect_time AS hist_voucher_collect_time \\\n",
    "        FROM {df} L \\\n",
    "        LEFT JOIN {df} R \\\n",
    "        ON L.user_id = R.user_id \\\n",
    "        AND L.session_id != R.session_id \\\n",
    "        AND L.campaign_name != R.campaign_name \\\n",
    "        AND R.label = 1 \\\n",
    "        AND L.rk > R.rk \\\n",
    "        ORDER BY L.rk ASC, R.rk ASC\".format(df='log_df')\n",
    "log_df_tmp = ps.sqldf(sql, locals())\n",
    "log_df_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_voucher_log = log_df_tmp.groupby([ 'session_id', 'label', 'user_id', 'promotion_id', 'voucher_min_spend', \n",
    "                       'voucher_discount', 'voucher_collect_time', 'voucher_redeem_time',\n",
    "                       'user_age_level', 'user_gender', 'user_purchase_level',\n",
    "                       'user_trd__orders_cnt_hist', 'user_trd__actual_gmv_usd_hist',\n",
    "                       'user_trd__orders_cnt_platform_discount_hist',\n",
    "                       'user_trd__max_gmv_usd_hist', 'user_trd__avg_gmv_usd_hist',\n",
    "                       'user_trd__min_gmv_usd_hist', 'dtype']) \\\n",
    "                .agg({'hist_session_id': lambda x: \"%s\" % ','.join(x),\n",
    "                      'hist_promotion_id': lambda x: \"%s\" % ','.join(x),\n",
    "                      'hist_rk': lambda x: list(x),\n",
    "                      'hist_voucher_collect_time': \"count\"}).reset_index()\n",
    "\n",
    "user_voucher_log['keys_length'] = user_voucher_log['hist_voucher_collect_time']\n",
    "user_voucher_log = user_voucher_log.drop(columns=['hist_rk', 'hist_voucher_collect_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>label</th>\n",
       "      <th>user_id</th>\n",
       "      <th>promotion_id</th>\n",
       "      <th>voucher_min_spend</th>\n",
       "      <th>voucher_discount</th>\n",
       "      <th>voucher_collect_time</th>\n",
       "      <th>voucher_redeem_time</th>\n",
       "      <th>user_age_level</th>\n",
       "      <th>user_gender</th>\n",
       "      <th>...</th>\n",
       "      <th>user_trd__orders_cnt_hist</th>\n",
       "      <th>user_trd__actual_gmv_usd_hist</th>\n",
       "      <th>user_trd__orders_cnt_platform_discount_hist</th>\n",
       "      <th>user_trd__max_gmv_usd_hist</th>\n",
       "      <th>user_trd__avg_gmv_usd_hist</th>\n",
       "      <th>user_trd__min_gmv_usd_hist</th>\n",
       "      <th>dtype</th>\n",
       "      <th>hist_session_id</th>\n",
       "      <th>hist_promotion_id</th>\n",
       "      <th>keys_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>299</td>\n",
       "      <td>30</td>\n",
       "      <td>45451</td>\n",
       "      <td>45521</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>23.507327</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.376755</td>\n",
       "      <td>3.917888</td>\n",
       "      <td>2.518198</td>\n",
       "      <td>train</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000_38</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>38</td>\n",
       "      <td>888</td>\n",
       "      <td>80</td>\n",
       "      <td>13253</td>\n",
       "      <td>13254</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>218.105824</td>\n",
       "      <td>9.0</td>\n",
       "      <td>42.643151</td>\n",
       "      <td>12.116990</td>\n",
       "      <td>3.581674</td>\n",
       "      <td>train</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10001_159</td>\n",
       "      <td>1</td>\n",
       "      <td>10001</td>\n",
       "      <td>159</td>\n",
       "      <td>799</td>\n",
       "      <td>70</td>\n",
       "      <td>80001</td>\n",
       "      <td>89306</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>39.0</td>\n",
       "      <td>373.530611</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.090705</td>\n",
       "      <td>6.225510</td>\n",
       "      <td>0.561611</td>\n",
       "      <td>train</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10001_319</td>\n",
       "      <td>0</td>\n",
       "      <td>10001</td>\n",
       "      <td>319</td>\n",
       "      <td>1999</td>\n",
       "      <td>200</td>\n",
       "      <td>115663</td>\n",
       "      <td>115663</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>42.0</td>\n",
       "      <td>381.810513</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.090705</td>\n",
       "      <td>5.614860</td>\n",
       "      <td>0.487420</td>\n",
       "      <td>train</td>\n",
       "      <td>10001_159</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10001_38</td>\n",
       "      <td>0</td>\n",
       "      <td>10001</td>\n",
       "      <td>38</td>\n",
       "      <td>888</td>\n",
       "      <td>80</td>\n",
       "      <td>12867</td>\n",
       "      <td>19625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>133.172685</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.419591</td>\n",
       "      <td>11.097724</td>\n",
       "      <td>1.811817</td>\n",
       "      <td>train</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58046</th>\n",
       "      <td>99_82</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>82</td>\n",
       "      <td>299</td>\n",
       "      <td>30</td>\n",
       "      <td>46577</td>\n",
       "      <td>46577</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2462.818244</td>\n",
       "      <td>50.0</td>\n",
       "      <td>329.698604</td>\n",
       "      <td>18.944756</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>train</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58047</th>\n",
       "      <td>99_83</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>83</td>\n",
       "      <td>1999</td>\n",
       "      <td>200</td>\n",
       "      <td>35523</td>\n",
       "      <td>53242</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2397.249462</td>\n",
       "      <td>46.0</td>\n",
       "      <td>329.698604</td>\n",
       "      <td>19.025789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>test</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58048</th>\n",
       "      <td>99_91</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>91</td>\n",
       "      <td>799</td>\n",
       "      <td>80</td>\n",
       "      <td>35523</td>\n",
       "      <td>46578</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2397.249462</td>\n",
       "      <td>46.0</td>\n",
       "      <td>329.698604</td>\n",
       "      <td>19.025789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>train</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58049</th>\n",
       "      <td>9_61</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>61</td>\n",
       "      <td>2999</td>\n",
       "      <td>300</td>\n",
       "      <td>24981</td>\n",
       "      <td>28017</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>715.893947</td>\n",
       "      <td>23.0</td>\n",
       "      <td>150.129713</td>\n",
       "      <td>9.419657</td>\n",
       "      <td>1.116494</td>\n",
       "      <td>train</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58050</th>\n",
       "      <td>9_69</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>69</td>\n",
       "      <td>888</td>\n",
       "      <td>80</td>\n",
       "      <td>24983</td>\n",
       "      <td>24983</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>715.893947</td>\n",
       "      <td>23.0</td>\n",
       "      <td>150.129713</td>\n",
       "      <td>9.419657</td>\n",
       "      <td>1.116494</td>\n",
       "      <td>train</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58051 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      session_id  label user_id promotion_id  voucher_min_spend  \\\n",
       "0           0_82      0       0           82                299   \n",
       "1       10000_38      0   10000           38                888   \n",
       "2      10001_159      1   10001          159                799   \n",
       "3      10001_319      0   10001          319               1999   \n",
       "4       10001_38      0   10001           38                888   \n",
       "...          ...    ...     ...          ...                ...   \n",
       "58046      99_82      0      99           82                299   \n",
       "58047      99_83      1      99           83               1999   \n",
       "58048      99_91      0      99           91                799   \n",
       "58049       9_61      1       9           61               2999   \n",
       "58050       9_69      0       9           69                888   \n",
       "\n",
       "       voucher_discount voucher_collect_time voucher_redeem_time  \\\n",
       "0                    30                45451               45521   \n",
       "1                    80                13253               13254   \n",
       "2                    70                80001               89306   \n",
       "3                   200               115663              115663   \n",
       "4                    80                12867               19625   \n",
       "...                 ...                  ...                 ...   \n",
       "58046                30                46577               46577   \n",
       "58047               200                35523               53242   \n",
       "58048                80                35523               46578   \n",
       "58049               300                24981               28017   \n",
       "58050                80                24983               24983   \n",
       "\n",
       "       user_age_level user_gender  ...  user_trd__orders_cnt_hist  \\\n",
       "0                 4.0           0  ...                        4.0   \n",
       "1                 3.0           0  ...                        6.0   \n",
       "2                 0.0           0  ...                       39.0   \n",
       "3                 0.0           0  ...                       42.0   \n",
       "4                 0.0           0  ...                       11.0   \n",
       "...               ...         ...  ...                        ...   \n",
       "58046             3.0           0  ...                       44.0   \n",
       "58047             3.0           0  ...                       43.0   \n",
       "58048             3.0           0  ...                       43.0   \n",
       "58049             3.0           1  ...                       22.0   \n",
       "58050             3.0           1  ...                       22.0   \n",
       "\n",
       "       user_trd__actual_gmv_usd_hist  \\\n",
       "0                          23.507327   \n",
       "1                         218.105824   \n",
       "2                         373.530611   \n",
       "3                         381.810513   \n",
       "4                         133.172685   \n",
       "...                              ...   \n",
       "58046                    2462.818244   \n",
       "58047                    2397.249462   \n",
       "58048                    2397.249462   \n",
       "58049                     715.893947   \n",
       "58050                     715.893947   \n",
       "\n",
       "       user_trd__orders_cnt_platform_discount_hist  \\\n",
       "0                                              0.0   \n",
       "1                                              9.0   \n",
       "2                                              3.0   \n",
       "3                                              3.0   \n",
       "4                                              0.0   \n",
       "...                                            ...   \n",
       "58046                                         50.0   \n",
       "58047                                         46.0   \n",
       "58048                                         46.0   \n",
       "58049                                         23.0   \n",
       "58050                                         23.0   \n",
       "\n",
       "       user_trd__max_gmv_usd_hist  user_trd__avg_gmv_usd_hist  \\\n",
       "0                        6.376755                    3.917888   \n",
       "1                       42.643151                   12.116990   \n",
       "2                       32.090705                    6.225510   \n",
       "3                       32.090705                    5.614860   \n",
       "4                       26.419591                   11.097724   \n",
       "...                           ...                         ...   \n",
       "58046                  329.698604                   18.944756   \n",
       "58047                  329.698604                   19.025789   \n",
       "58048                  329.698604                   19.025789   \n",
       "58049                  150.129713                    9.419657   \n",
       "58050                  150.129713                    9.419657   \n",
       "\n",
       "       user_trd__min_gmv_usd_hist  dtype hist_session_id hist_promotion_id  \\\n",
       "0                        2.518198  train                                     \n",
       "1                        3.581674  train                                     \n",
       "2                        0.561611  train                                     \n",
       "3                        0.487420  train       10001_159               159   \n",
       "4                        1.811817  train                                     \n",
       "...                           ...    ...             ...               ...   \n",
       "58046                    0.000000  train                                     \n",
       "58047                    0.000000   test                                     \n",
       "58048                    0.000000  train                                     \n",
       "58049                    1.116494  train                                     \n",
       "58050                    1.116494  train                                     \n",
       "\n",
       "      keys_length  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               1  \n",
       "4               0  \n",
       "...           ...  \n",
       "58046           0  \n",
       "58047           0  \n",
       "58048           0  \n",
       "58049           0  \n",
       "58050           0  \n",
       "\n",
       "[58051 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_voucher_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keys_length</th>\n",
       "      <th>session_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>39908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    keys_length  session_id\n",
       "0             0       39908\n",
       "1             1        8720\n",
       "2             2        4236\n",
       "3             3        2326\n",
       "4             4        1325\n",
       "5             5         721\n",
       "6             6         267\n",
       "7             7         218\n",
       "8             8         115\n",
       "9             9          72\n",
       "10           10          44\n",
       "11           11          45\n",
       "12           12          10\n",
       "13           13          13\n",
       "14           14          12\n",
       "15           18          19"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a statistics of historical UVG sequence distribution\n",
    "user_voucher_log.groupby(['keys_length']).agg({'session_id': \"count\"}).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoding and Normalization\n",
    "Label encoding for sparse features and normlaization for dense features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = user_voucher_log.copy()\n",
    "df = df.take(np.random.permutation(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_feature = ['promotion_id','session_id','user_gender','user_age_level','user_purchase_level'] #['promotion_id','voucher_min_spend','voucher_discount_amount']\n",
    "\n",
    "hist_list_features = ['hist_promotion_id','hist_session_id','keys_length']\n",
    "\n",
    "ignore_features=['dtype','venture','ds','user_id','label','voucher_collect_time','voucher_redeem_time','campaign_name','rk']\n",
    "ignore_features_key_words = ['out', 'emb']\n",
    "\n",
    "dense_feature = []\n",
    "train_features = []\n",
    "\n",
    "for feat in df.columns:\n",
    "    flag = True \n",
    "    for key in ignore_features_key_words:\n",
    "        if key in feat:\n",
    "            flag = False\n",
    "            break\n",
    "    if feat not in ignore_features and flag is True:\n",
    "        if feat not in hist_list_features:\n",
    "            train_features.append(feat)\n",
    "        if feat not in sparse_feature and feat not in hist_list_features:\n",
    "            dense_feature.append(feat)\n",
    "\n",
    "target = 'label'\n",
    "df[['session_id','promotion_id','user_gender','user_age_level','user_purchase_level']]=df[['session_id','promotion_id','user_gender','user_age_level','user_purchase_level']].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-20 13:31:30,381 [WARNING]: LabelEncoder encoding promotion_id len 462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lbe promotion_id\n",
      "LabelEncoderExt fitting...\n",
      "LabelEncoderExt transforming...\n",
      "lbe session_id\n",
      "LabelEncoderExt fitting...\n",
      "LabelEncoderExt transforming...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-20 13:31:30,596 [WARNING]: LabelEncoder encoding session_id len 58052\n",
      "2023-02-20 13:31:30,659 [WARNING]: LabelEncoder encoding user_gender len 4\n",
      "2023-02-20 13:31:30,719 [WARNING]: LabelEncoder encoding user_age_level len 10\n",
      "2023-02-20 13:31:30,779 [WARNING]: LabelEncoder encoding user_purchase_level len 12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lbe user_gender\n",
      "LabelEncoderExt fitting...\n",
      "LabelEncoderExt transforming...\n",
      "lbe user_age_level\n",
      "LabelEncoderExt fitting...\n",
      "LabelEncoderExt transforming...\n",
      "lbe user_purchase_level\n",
      "LabelEncoderExt fitting...\n",
      "LabelEncoderExt transforming...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "label_encoder = {}\n",
    "for feat in sparse_feature:\n",
    "    df[feat] = df[feat].fillna(0)\n",
    "    print(\"lbe {}\".format(feat))\n",
    "    \n",
    "    lbe = LabelEncoderExt()\n",
    "    lbe.fit(df[feat])\n",
    "        \n",
    "    df[feat] = lbe.transform(df[feat])\n",
    "    label_encoder[feat] = lbe\n",
    "    logging.warn('LabelEncoder encoding ' + feat + \" len \" + str(len(lbe)))\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voucher_min_spend\n",
      "voucher_discount\n",
      "user_trd__orders_cnt_hist\n",
      "user_trd__actual_gmv_usd_hist\n",
      "user_trd__orders_cnt_platform_discount_hist\n",
      "user_trd__max_gmv_usd_hist\n",
      "user_trd__avg_gmv_usd_hist\n",
      "user_trd__min_gmv_usd_hist\n"
     ]
    }
   ],
   "source": [
    "mean_kv = {}\n",
    "std_kv = {}\n",
    "for feat in dense_feature:\n",
    "    print(feat)\n",
    "    mean_kv[feat] = df[feat].mean()\n",
    "    std_kv[feat] = df[feat].std()\n",
    "    df[feat] = (df[feat] - mean_kv[feat]) / std_kv[feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_ctr_df = df \n",
    "\n",
    "dctr_train = deep_ctr_df[deep_ctr_df.dtype == 'train']\n",
    "dctr_v1 = deep_ctr_df[deep_ctr_df.dtype == 'test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "results={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 16\n",
    "sparse_feature_columns = [SparseFeat(feat, len(label_encoder[feat].classes_), embedding_dim = embedding_dim) for feat in sparse_feature]\n",
    "dense_feature_columns = [DenseFeat(feat, 1, ) for feat in dense_feature]\n",
    "\n",
    "dnn_feature_columns = sparse_feature_columns + dense_feature_columns\n",
    "linear_feature_columns = sparse_feature_columns + dense_feature_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR\n",
    "LR: Logistic Regression [1] is a shallow model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_model_input_data(feature_names, raw_features, target):\n",
    "    model_input = {}\n",
    "    for name in feature_names:\n",
    "        if name in sparse_feature:\n",
    "            model_input[name] = raw_features[name]\n",
    "        else:\n",
    "            model_input[name] = raw_features[name].fillna(0).astype(np.float32)\n",
    "    return raw_features[target], model_input\n",
    "\n",
    "feature_names = get_feature_names(dense_feature_columns + sparse_feature_columns)\n",
    "train_label, train_model_input = gen_model_input_data(feature_names, dctr_train, target)\n",
    "test_label1, test_model_input1 = gen_model_input_data(feature_names, dctr_v1, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Train on 46361 samples, validate on 11690 samples, 155 steps per epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 78.35it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2s - loss:  0.5891 - auc:  0.6716 - logloss:  0.5889 - val_auc:  0.6825 - val_logloss:  0.5126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 119.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50\n",
      "1s - loss:  0.4735 - auc:  0.7066 - logloss:  0.4735 - val_auc:  0.6916 - val_logloss:  0.4481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 108.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50\n",
      "1s - loss:  0.4315 - auc:  0.7231 - logloss:  0.4316 - val_auc:  0.7018 - val_logloss:  0.4242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 119.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50\n",
      "1s - loss:  0.4149 - auc:  0.7364 - logloss:  0.4148 - val_auc:  0.7112 - val_logloss:  0.4141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 117.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50\n",
      "1s - loss:  0.4068 - auc:  0.7427 - logloss:  0.4068 - val_auc:  0.7180 - val_logloss:  0.4086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 117.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50\n",
      "1s - loss:  0.4018 - auc:  0.7481 - logloss:  0.4017 - val_auc:  0.7230 - val_logloss:  0.4050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 121.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50\n",
      "1s - loss:  0.3982 - auc:  0.7529 - logloss:  0.3982 - val_auc:  0.7269 - val_logloss:  0.4022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 120.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50\n",
      "1s - loss:  0.3954 - auc:  0.7559 - logloss:  0.3954 - val_auc:  0.7301 - val_logloss:  0.3998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 109.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50\n",
      "1s - loss:  0.3930 - auc:  0.7580 - logloss:  0.3931 - val_auc:  0.7332 - val_logloss:  0.3979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 100.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50\n",
      "1s - loss:  0.3911 - auc:  0.7594 - logloss:  0.3910 - val_auc:  0.7353 - val_logloss:  0.3963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 98.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50\n",
      "1s - loss:  0.3894 - auc:  0.7605 - logloss:  0.3893 - val_auc:  0.7373 - val_logloss:  0.3949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 98.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50\n",
      "1s - loss:  0.3881 - auc:  0.7631 - logloss:  0.3881 - val_auc:  0.7385 - val_logloss:  0.3936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 98.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50\n",
      "1s - loss:  0.3869 - auc:  0.7623 - logloss:  0.3868 - val_auc:  0.7398 - val_logloss:  0.3927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 96.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50\n",
      "1s - loss:  0.3859 - auc:  0.7645 - logloss:  0.3860 - val_auc:  0.7408 - val_logloss:  0.3918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 96.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50\n",
      "1s - loss:  0.3851 - auc:  0.7646 - logloss:  0.3853 - val_auc:  0.7416 - val_logloss:  0.3910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 97.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50\n",
      "1s - loss:  0.3843 - auc:  0.7650 - logloss:  0.3843 - val_auc:  0.7426 - val_logloss:  0.3903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 98.73it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50\n",
      "1s - loss:  0.3837 - auc:  0.7656 - logloss:  0.3837 - val_auc:  0.7432 - val_logloss:  0.3897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 99.12it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50\n",
      "1s - loss:  0.3832 - auc:  0.7652 - logloss:  0.3833 - val_auc:  0.7437 - val_logloss:  0.3892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 98.81it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50\n",
      "1s - loss:  0.3827 - auc:  0.7658 - logloss:  0.3827 - val_auc:  0.7447 - val_logloss:  0.3887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 82.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50\n",
      "1s - loss:  0.3823 - auc:  0.7677 - logloss:  0.3822 - val_auc:  0.7447 - val_logloss:  0.3884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 97.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50\n",
      "1s - loss:  0.3819 - auc:  0.7660 - logloss:  0.3821 - val_auc:  0.7450 - val_logloss:  0.3881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 98.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50\n",
      "1s - loss:  0.3816 - auc:  0.7667 - logloss:  0.3818 - val_auc:  0.7454 - val_logloss:  0.3877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 98.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50\n",
      "1s - loss:  0.3813 - auc:  0.7664 - logloss:  0.3812 - val_auc:  0.7457 - val_logloss:  0.3874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 99.25it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50\n",
      "1s - loss:  0.3811 - auc:  0.7667 - logloss:  0.3810 - val_auc:  0.7460 - val_logloss:  0.3872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 99.37it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50\n",
      "1s - loss:  0.3808 - auc:  0.7669 - logloss:  0.3808 - val_auc:  0.7465 - val_logloss:  0.3870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 91.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50\n",
      "1s - loss:  0.3806 - auc:  0.7670 - logloss:  0.3807 - val_auc:  0.7462 - val_logloss:  0.3868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 99.03it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50\n",
      "1s - loss:  0.3804 - auc:  0.7663 - logloss:  0.3804 - val_auc:  0.7463 - val_logloss:  0.3868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 100.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50\n",
      "1s - loss:  0.3803 - auc:  0.7681 - logloss:  0.3803 - val_auc:  0.7465 - val_logloss:  0.3865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 99.67it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50\n",
      "1s - loss:  0.3801 - auc:  0.7680 - logloss:  0.3801 - val_auc:  0.7469 - val_logloss:  0.3862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 98.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50\n",
      "1s - loss:  0.3800 - auc:  0.7674 - logloss:  0.3798 - val_auc:  0.7470 - val_logloss:  0.3862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 98.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50\n",
      "1s - loss:  0.3799 - auc:  0.7672 - logloss:  0.3799 - val_auc:  0.7473 - val_logloss:  0.3861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 97.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50\n",
      "1s - loss:  0.3798 - auc:  0.7670 - logloss:  0.3797 - val_auc:  0.7475 - val_logloss:  0.3859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 97.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50\n",
      "1s - loss:  0.3797 - auc:  0.7680 - logloss:  0.3795 - val_auc:  0.7475 - val_logloss:  0.3859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 89.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50\n",
      "1s - loss:  0.3796 - auc:  0.7675 - logloss:  0.3795 - val_auc:  0.7476 - val_logloss:  0.3858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 99.26it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50\n",
      "1s - loss:  0.3795 - auc:  0.7680 - logloss:  0.3796 - val_auc:  0.7473 - val_logloss:  0.3858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 99.38it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50\n",
      "1s - loss:  0.3794 - auc:  0.7673 - logloss:  0.3795 - val_auc:  0.7475 - val_logloss:  0.3858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 98.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50\n",
      "1s - loss:  0.3793 - auc:  0.7683 - logloss:  0.3792 - val_auc:  0.7477 - val_logloss:  0.3856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 100.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50\n",
      "1s - loss:  0.3793 - auc:  0.7679 - logloss:  0.3793 - val_auc:  0.7478 - val_logloss:  0.3856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 98.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50\n",
      "1s - loss:  0.3792 - auc:  0.7678 - logloss:  0.3789 - val_auc:  0.7478 - val_logloss:  0.3854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 98.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50\n",
      "1s - loss:  0.3792 - auc:  0.7682 - logloss:  0.3791 - val_auc:  0.7479 - val_logloss:  0.3855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 97.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50\n",
      "1s - loss:  0.3791 - auc:  0.7685 - logloss:  0.3792 - val_auc:  0.7478 - val_logloss:  0.3854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 90.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50\n",
      "1s - loss:  0.3791 - auc:  0.7688 - logloss:  0.3790 - val_auc:  0.7480 - val_logloss:  0.3853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 98.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50\n",
      "1s - loss:  0.3790 - auc:  0.7682 - logloss:  0.3788 - val_auc:  0.7478 - val_logloss:  0.3853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 98.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50\n",
      "1s - loss:  0.3790 - auc:  0.7687 - logloss:  0.3789 - val_auc:  0.7479 - val_logloss:  0.3853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 100.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50\n",
      "1s - loss:  0.3789 - auc:  0.7677 - logloss:  0.3789 - val_auc:  0.7479 - val_logloss:  0.3853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 100.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50\n",
      "1s - loss:  0.3789 - auc:  0.7679 - logloss:  0.3789 - val_auc:  0.7480 - val_logloss:  0.3853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 101.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50\n",
      "1s - loss:  0.3788 - auc:  0.7689 - logloss:  0.3789 - val_auc:  0.7482 - val_logloss:  0.3852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 97.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50\n",
      "1s - loss:  0.3788 - auc:  0.7679 - logloss:  0.3787 - val_auc:  0.7483 - val_logloss:  0.3851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 99.11it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50\n",
      "1s - loss:  0.3788 - auc:  0.7673 - logloss:  0.3790 - val_auc:  0.7485 - val_logloss:  0.3851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 90.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50\n",
      "1s - loss:  0.3788 - auc:  0.7687 - logloss:  0.3789 - val_auc:  0.7481 - val_logloss:  0.3851\n"
     ]
    }
   ],
   "source": [
    "model_name = 'LR'\n",
    "epoch = 50\n",
    "batch_size = 300\n",
    "\n",
    "model = WDL(linear_feature_columns=dnn_feature_columns,\n",
    "            dnn_feature_columns=[], \n",
    "            dnn_use_bn=True,\n",
    "            l2_reg_dnn=0.1, \n",
    "            l2_reg_embedding = 0.0001, \n",
    "            dnn_hidden_units=(128,64), \n",
    "            init_std=1, \n",
    "            dnn_dropout=0.5, \n",
    "            task='binary', \n",
    "            dnn_activation='relu', \n",
    "            device=device)\n",
    "\n",
    "model\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.1, amsgrad=True)\n",
    "model.compile(optimizer, 'binary_crossentropy',metrics=['auc','logloss'])\n",
    "model.fit(train_model_input,  train_label.values.astype(int), batch_size=batch_size, epochs=epoch, validation_data=(test_model_input1,test_label1),verbose=1)\n",
    "res = model.evaluate(test_model_input1,test_label1)\n",
    "pred1 = model.predict(test_model_input1)\n",
    "results[model_name] = model, res, pred1, test_label1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBDT\n",
    "GBDT: Gradient Boosting Decision Tree [2] is used to assess the performance of non deep-learning algorithms. Only dense features are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:32:52] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\teval-auc:0.74426\teval-logloss:0.66234\ttrain-auc:0.75173\ttrain-logloss:0.66225\n",
      "[1]\teval-auc:0.74628\teval-logloss:0.63497\ttrain-auc:0.75559\ttrain-logloss:0.63484\n",
      "[2]\teval-auc:0.74539\teval-logloss:0.61074\ttrain-auc:0.75743\ttrain-logloss:0.61042\n",
      "[3]\teval-auc:0.74809\teval-logloss:0.58899\ttrain-auc:0.76167\ttrain-logloss:0.58850\n",
      "[4]\teval-auc:0.74831\teval-logloss:0.56951\ttrain-auc:0.76250\ttrain-logloss:0.56880\n",
      "[5]\teval-auc:0.74857\teval-logloss:0.55195\ttrain-auc:0.76321\ttrain-logloss:0.55111\n",
      "[6]\teval-auc:0.74915\teval-logloss:0.53605\ttrain-auc:0.76352\ttrain-logloss:0.53515\n",
      "[7]\teval-auc:0.74995\teval-logloss:0.52171\ttrain-auc:0.76406\ttrain-logloss:0.52070\n",
      "[8]\teval-auc:0.75152\teval-logloss:0.50867\ttrain-auc:0.76670\ttrain-logloss:0.50752\n",
      "[9]\teval-auc:0.75175\teval-logloss:0.49694\ttrain-auc:0.76707\ttrain-logloss:0.49556\n",
      "[10]\teval-auc:0.75225\teval-logloss:0.48625\ttrain-auc:0.76788\ttrain-logloss:0.48474\n",
      "[11]\teval-auc:0.75309\teval-logloss:0.47645\ttrain-auc:0.76881\ttrain-logloss:0.47479\n",
      "[12]\teval-auc:0.75355\teval-logloss:0.46760\ttrain-auc:0.76983\ttrain-logloss:0.46575\n",
      "[13]\teval-auc:0.75421\teval-logloss:0.45951\ttrain-auc:0.77044\ttrain-logloss:0.45751\n",
      "[14]\teval-auc:0.75502\teval-logloss:0.45212\ttrain-auc:0.77164\ttrain-logloss:0.44999\n",
      "[15]\teval-auc:0.75644\teval-logloss:0.44535\ttrain-auc:0.77403\ttrain-logloss:0.44303\n",
      "[16]\teval-auc:0.75662\teval-logloss:0.43920\ttrain-auc:0.77462\ttrain-logloss:0.43668\n",
      "[17]\teval-auc:0.75641\teval-logloss:0.43364\ttrain-auc:0.77521\ttrain-logloss:0.43089\n",
      "[18]\teval-auc:0.75678\teval-logloss:0.42851\ttrain-auc:0.77555\ttrain-logloss:0.42560\n",
      "[19]\teval-auc:0.75750\teval-logloss:0.42374\ttrain-auc:0.77684\ttrain-logloss:0.42059\n",
      "[20]\teval-auc:0.75767\teval-logloss:0.41939\ttrain-auc:0.77741\ttrain-logloss:0.41597\n",
      "[21]\teval-auc:0.75785\teval-logloss:0.41544\ttrain-auc:0.77776\ttrain-logloss:0.41180\n",
      "[22]\teval-auc:0.75787\teval-logloss:0.41177\ttrain-auc:0.77826\ttrain-logloss:0.40788\n",
      "[23]\teval-auc:0.75886\teval-logloss:0.40837\ttrain-auc:0.77969\ttrain-logloss:0.40425\n",
      "[24]\teval-auc:0.75993\teval-logloss:0.40512\ttrain-auc:0.78142\ttrain-logloss:0.40073\n",
      "[25]\teval-auc:0.76011\teval-logloss:0.40227\ttrain-auc:0.78184\ttrain-logloss:0.39764\n",
      "[26]\teval-auc:0.76183\teval-logloss:0.39934\ttrain-auc:0.78374\ttrain-logloss:0.39452\n",
      "[27]\teval-auc:0.76191\teval-logloss:0.39694\ttrain-auc:0.78409\ttrain-logloss:0.39187\n",
      "[28]\teval-auc:0.76292\teval-logloss:0.39448\ttrain-auc:0.78579\ttrain-logloss:0.38916\n",
      "[29]\teval-auc:0.76343\teval-logloss:0.39242\ttrain-auc:0.78652\ttrain-logloss:0.38687\n",
      "[30]\teval-auc:0.76346\teval-logloss:0.39054\ttrain-auc:0.78683\ttrain-logloss:0.38477\n",
      "[31]\teval-auc:0.76377\teval-logloss:0.38880\ttrain-auc:0.78757\ttrain-logloss:0.38277\n",
      "[32]\teval-auc:0.76405\teval-logloss:0.38716\ttrain-auc:0.78776\ttrain-logloss:0.38093\n",
      "[33]\teval-auc:0.76430\teval-logloss:0.38567\ttrain-auc:0.78831\ttrain-logloss:0.37923\n",
      "[34]\teval-auc:0.76505\teval-logloss:0.38410\ttrain-auc:0.78952\ttrain-logloss:0.37740\n",
      "[35]\teval-auc:0.76545\teval-logloss:0.38287\ttrain-auc:0.79021\ttrain-logloss:0.37595\n",
      "[36]\teval-auc:0.76622\teval-logloss:0.38148\ttrain-auc:0.79155\ttrain-logloss:0.37431\n",
      "[37]\teval-auc:0.76628\teval-logloss:0.38045\ttrain-auc:0.79214\ttrain-logloss:0.37298\n",
      "[38]\teval-auc:0.76661\teval-logloss:0.37938\ttrain-auc:0.79245\ttrain-logloss:0.37174\n",
      "[39]\teval-auc:0.76773\teval-logloss:0.37825\ttrain-auc:0.79411\ttrain-logloss:0.37027\n",
      "[40]\teval-auc:0.76803\teval-logloss:0.37737\ttrain-auc:0.79428\ttrain-logloss:0.36922\n",
      "[41]\teval-auc:0.76837\teval-logloss:0.37658\ttrain-auc:0.79505\ttrain-logloss:0.36812\n",
      "[42]\teval-auc:0.76888\teval-logloss:0.37572\ttrain-auc:0.79580\ttrain-logloss:0.36698\n",
      "[43]\teval-auc:0.76896\teval-logloss:0.37509\ttrain-auc:0.79647\ttrain-logloss:0.36600\n",
      "[44]\teval-auc:0.76906\teval-logloss:0.37447\ttrain-auc:0.79715\ttrain-logloss:0.36508\n",
      "[45]\teval-auc:0.76935\teval-logloss:0.37385\ttrain-auc:0.79800\ttrain-logloss:0.36412\n",
      "[46]\teval-auc:0.76971\teval-logloss:0.37324\ttrain-auc:0.79879\ttrain-logloss:0.36323\n",
      "[47]\teval-auc:0.77003\teval-logloss:0.37264\ttrain-auc:0.79968\ttrain-logloss:0.36233\n",
      "[48]\teval-auc:0.77020\teval-logloss:0.37216\ttrain-auc:0.80019\ttrain-logloss:0.36160\n",
      "[49]\teval-auc:0.77071\teval-logloss:0.37160\ttrain-auc:0.80125\ttrain-logloss:0.36070\n",
      "[50]\teval-auc:0.77096\teval-logloss:0.37112\ttrain-auc:0.80188\ttrain-logloss:0.36001\n",
      "[51]\teval-auc:0.77107\teval-logloss:0.37070\ttrain-auc:0.80229\ttrain-logloss:0.35932\n",
      "[52]\teval-auc:0.77138\teval-logloss:0.37028\ttrain-auc:0.80319\ttrain-logloss:0.35855\n",
      "[53]\teval-auc:0.77144\teval-logloss:0.36993\ttrain-auc:0.80353\ttrain-logloss:0.35798\n",
      "[54]\teval-auc:0.77178\teval-logloss:0.36954\ttrain-auc:0.80439\ttrain-logloss:0.35729\n",
      "[55]\teval-auc:0.77178\teval-logloss:0.36930\ttrain-auc:0.80521\ttrain-logloss:0.35665\n",
      "[56]\teval-auc:0.77187\teval-logloss:0.36904\ttrain-auc:0.80581\ttrain-logloss:0.35608\n",
      "[57]\teval-auc:0.77202\teval-logloss:0.36877\ttrain-auc:0.80689\ttrain-logloss:0.35540\n",
      "[58]\teval-auc:0.77216\teval-logloss:0.36853\ttrain-auc:0.80736\ttrain-logloss:0.35483\n",
      "[59]\teval-auc:0.77214\teval-logloss:0.36835\ttrain-auc:0.80795\ttrain-logloss:0.35433\n",
      "[60]\teval-auc:0.77260\teval-logloss:0.36806\ttrain-auc:0.80875\ttrain-logloss:0.35378\n",
      "[61]\teval-auc:0.77280\teval-logloss:0.36786\ttrain-auc:0.80911\ttrain-logloss:0.35335\n",
      "[62]\teval-auc:0.77297\teval-logloss:0.36762\ttrain-auc:0.80992\ttrain-logloss:0.35282\n",
      "[63]\teval-auc:0.77302\teval-logloss:0.36744\ttrain-auc:0.81052\ttrain-logloss:0.35235\n",
      "[64]\teval-auc:0.77307\teval-logloss:0.36731\ttrain-auc:0.81174\ttrain-logloss:0.35179\n",
      "[65]\teval-auc:0.77307\teval-logloss:0.36719\ttrain-auc:0.81231\ttrain-logloss:0.35133\n",
      "[66]\teval-auc:0.77315\teval-logloss:0.36706\ttrain-auc:0.81261\ttrain-logloss:0.35095\n",
      "[67]\teval-auc:0.77349\teval-logloss:0.36683\ttrain-auc:0.81419\ttrain-logloss:0.35027\n",
      "[68]\teval-auc:0.77338\teval-logloss:0.36674\ttrain-auc:0.81524\ttrain-logloss:0.34968\n",
      "[69]\teval-auc:0.77355\teval-logloss:0.36658\ttrain-auc:0.81586\ttrain-logloss:0.34922\n",
      "[70]\teval-auc:0.77355\teval-logloss:0.36652\ttrain-auc:0.81619\ttrain-logloss:0.34889\n",
      "[71]\teval-auc:0.77383\teval-logloss:0.36634\ttrain-auc:0.81701\ttrain-logloss:0.34839\n",
      "[72]\teval-auc:0.77409\teval-logloss:0.36613\ttrain-auc:0.81787\ttrain-logloss:0.34787\n",
      "[73]\teval-auc:0.77436\teval-logloss:0.36599\ttrain-auc:0.81878\ttrain-logloss:0.34735\n",
      "[74]\teval-auc:0.77428\teval-logloss:0.36592\ttrain-auc:0.81960\ttrain-logloss:0.34686\n",
      "[75]\teval-auc:0.77443\teval-logloss:0.36580\ttrain-auc:0.82050\ttrain-logloss:0.34632\n",
      "[76]\teval-auc:0.77456\teval-logloss:0.36566\ttrain-auc:0.82090\ttrain-logloss:0.34594\n",
      "[77]\teval-auc:0.77480\teval-logloss:0.36553\ttrain-auc:0.82142\ttrain-logloss:0.34559\n",
      "[78]\teval-auc:0.77486\teval-logloss:0.36548\ttrain-auc:0.82180\ttrain-logloss:0.34527\n",
      "[79]\teval-auc:0.77484\teval-logloss:0.36540\ttrain-auc:0.82228\ttrain-logloss:0.34489\n",
      "[80]\teval-auc:0.77501\teval-logloss:0.36525\ttrain-auc:0.82292\ttrain-logloss:0.34445\n",
      "[81]\teval-auc:0.77515\teval-logloss:0.36518\ttrain-auc:0.82339\ttrain-logloss:0.34415\n",
      "[82]\teval-auc:0.77533\teval-logloss:0.36508\ttrain-auc:0.82409\ttrain-logloss:0.34381\n",
      "[83]\teval-auc:0.77534\teval-logloss:0.36500\ttrain-auc:0.82465\ttrain-logloss:0.34340\n",
      "[84]\teval-auc:0.77549\teval-logloss:0.36490\ttrain-auc:0.82509\ttrain-logloss:0.34309\n",
      "[85]\teval-auc:0.77540\teval-logloss:0.36490\ttrain-auc:0.82568\ttrain-logloss:0.34274\n",
      "[86]\teval-auc:0.77538\teval-logloss:0.36485\ttrain-auc:0.82571\ttrain-logloss:0.34260\n",
      "[87]\teval-auc:0.77535\teval-logloss:0.36486\ttrain-auc:0.82620\ttrain-logloss:0.34233\n",
      "[88]\teval-auc:0.77532\teval-logloss:0.36484\ttrain-auc:0.82652\ttrain-logloss:0.34203\n",
      "[89]\teval-auc:0.77534\teval-logloss:0.36478\ttrain-auc:0.82702\ttrain-logloss:0.34178\n",
      "[90]\teval-auc:0.77543\teval-logloss:0.36471\ttrain-auc:0.82736\ttrain-logloss:0.34150\n",
      "[91]\teval-auc:0.77545\teval-logloss:0.36466\ttrain-auc:0.82782\ttrain-logloss:0.34123\n",
      "[92]\teval-auc:0.77571\teval-logloss:0.36450\ttrain-auc:0.82843\ttrain-logloss:0.34080\n",
      "[93]\teval-auc:0.77577\teval-logloss:0.36448\ttrain-auc:0.82886\ttrain-logloss:0.34059\n",
      "[94]\teval-auc:0.77581\teval-logloss:0.36446\ttrain-auc:0.82913\ttrain-logloss:0.34035\n",
      "[95]\teval-auc:0.77584\teval-logloss:0.36447\ttrain-auc:0.82944\ttrain-logloss:0.34017\n",
      "[96]\teval-auc:0.77573\teval-logloss:0.36448\ttrain-auc:0.82984\ttrain-logloss:0.33989\n",
      "[97]\teval-auc:0.77586\teval-logloss:0.36442\ttrain-auc:0.83057\ttrain-logloss:0.33958\n",
      "[98]\teval-auc:0.77578\teval-logloss:0.36444\ttrain-auc:0.83085\ttrain-logloss:0.33938\n",
      "[99]\teval-auc:0.77582\teval-logloss:0.36445\ttrain-auc:0.83106\ttrain-logloss:0.33927\n",
      "[100]\teval-auc:0.77615\teval-logloss:0.36430\ttrain-auc:0.83159\ttrain-logloss:0.33888\n",
      "[101]\teval-auc:0.77622\teval-logloss:0.36426\ttrain-auc:0.83198\ttrain-logloss:0.33866\n",
      "[102]\teval-auc:0.77626\teval-logloss:0.36422\ttrain-auc:0.83243\ttrain-logloss:0.33840\n",
      "[103]\teval-auc:0.77624\teval-logloss:0.36424\ttrain-auc:0.83250\ttrain-logloss:0.33834\n",
      "[104]\teval-auc:0.77633\teval-logloss:0.36415\ttrain-auc:0.83272\ttrain-logloss:0.33811\n",
      "[105]\teval-auc:0.77618\teval-logloss:0.36415\ttrain-auc:0.83314\ttrain-logloss:0.33781\n",
      "[106]\teval-auc:0.77615\teval-logloss:0.36416\ttrain-auc:0.83333\ttrain-logloss:0.33771\n",
      "[107]\teval-auc:0.77643\teval-logloss:0.36406\ttrain-auc:0.83384\ttrain-logloss:0.33743\n",
      "[108]\teval-auc:0.77647\teval-logloss:0.36403\ttrain-auc:0.83423\ttrain-logloss:0.33722\n",
      "[109]\teval-auc:0.77641\teval-logloss:0.36399\ttrain-auc:0.83481\ttrain-logloss:0.33685\n",
      "[110]\teval-auc:0.77630\teval-logloss:0.36404\ttrain-auc:0.83517\ttrain-logloss:0.33667\n",
      "[111]\teval-auc:0.77626\teval-logloss:0.36403\ttrain-auc:0.83551\ttrain-logloss:0.33646\n",
      "[112]\teval-auc:0.77614\teval-logloss:0.36407\ttrain-auc:0.83582\ttrain-logloss:0.33625\n",
      "[113]\teval-auc:0.77611\teval-logloss:0.36409\ttrain-auc:0.83589\ttrain-logloss:0.33620\n",
      "[114]\teval-auc:0.77613\teval-logloss:0.36406\ttrain-auc:0.83636\ttrain-logloss:0.33599\n",
      "[115]\teval-auc:0.77602\teval-logloss:0.36407\ttrain-auc:0.83661\ttrain-logloss:0.33582\n",
      "[116]\teval-auc:0.77594\teval-logloss:0.36409\ttrain-auc:0.83718\ttrain-logloss:0.33556\n",
      "[117]\teval-auc:0.77599\teval-logloss:0.36408\ttrain-auc:0.83827\ttrain-logloss:0.33508\n",
      "[118]\teval-auc:0.77596\teval-logloss:0.36409\ttrain-auc:0.83839\ttrain-logloss:0.33500\n",
      "[119]\teval-auc:0.77594\teval-logloss:0.36408\ttrain-auc:0.83873\ttrain-logloss:0.33479\n",
      "[120]\teval-auc:0.77600\teval-logloss:0.36401\ttrain-auc:0.83901\ttrain-logloss:0.33457\n",
      "[121]\teval-auc:0.77602\teval-logloss:0.36402\ttrain-auc:0.83929\ttrain-logloss:0.33435\n",
      "[122]\teval-auc:0.77600\teval-logloss:0.36403\ttrain-auc:0.83981\ttrain-logloss:0.33407\n",
      "[123]\teval-auc:0.77598\teval-logloss:0.36398\ttrain-auc:0.84025\ttrain-logloss:0.33380\n",
      "[124]\teval-auc:0.77600\teval-logloss:0.36396\ttrain-auc:0.84039\ttrain-logloss:0.33371\n",
      "[125]\teval-auc:0.77597\teval-logloss:0.36396\ttrain-auc:0.84091\ttrain-logloss:0.33339\n",
      "[126]\teval-auc:0.77587\teval-logloss:0.36400\ttrain-auc:0.84114\ttrain-logloss:0.33324\n",
      "[127]\teval-auc:0.77600\teval-logloss:0.36395\ttrain-auc:0.84157\ttrain-logloss:0.33296\n",
      "[128]\teval-auc:0.77600\teval-logloss:0.36396\ttrain-auc:0.84160\ttrain-logloss:0.33293\n",
      "[129]\teval-auc:0.77593\teval-logloss:0.36400\ttrain-auc:0.84186\ttrain-logloss:0.33277\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "model_name = \"xgBoost\"\n",
    "xgb_data_train = dctr_train\n",
    "df_xgb_train =  xgb.DMatrix(xgb_data_train[dense_feature], \n",
    "                            label=xgb_data_train[target])\n",
    "\n",
    "xgb_data_test1 = dctr_v1\n",
    "df_xgb_test1 = xgb.DMatrix(xgb_data_test1[dense_feature],\n",
    "                            label=xgb_data_test1[target])\n",
    "\n",
    "params = {'objective': 'binary:logistic',\n",
    "          'eval_metric': ['auc', 'logloss'],\n",
    "          'learning_rate': 0.06,\n",
    "          'num_leaves':256,\n",
    "          'max_depth':7,\n",
    "          'max_bin':64}\n",
    "\n",
    "evallist = [(df_xgb_test1, 'eval'), (df_xgb_train, 'train')]\n",
    "num_boost_round = 130\n",
    "xgb = xgb.train(params,\n",
    "                df_xgb_train,\n",
    "                num_boost_round,\n",
    "                evallist) \n",
    "\n",
    "xgb_pred_v1 = xgb.predict(df_xgb_test1)\n",
    "xgb_label_v1 = xgb_data_test1[target]\n",
    "auc_t1 = roc_auc_score(xgb_label_v1, xgb_pred_v1)\n",
    "logloss_t1 = log_loss(xgb_label_v1, xgb_pred_v1)\n",
    "res = {'eval_auc':auc_t1, \"eval_logloss\":logloss_t1}\n",
    "\n",
    "results[model_name] = xgb, res, xgb_pred_v1, xgb_label_v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN\n",
    "The Deep Neural Network is used as the first baseline taking both dense features and embedding of sparse id features into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Train on 46361 samples, validate on 11690 samples, 155 steps per epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 81.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2s - loss:  0.5488 - auc:  0.5271 - logloss:  0.4858 - val_auc:  0.6116 - val_logloss:  0.4491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 85.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "1s - loss:  0.4811 - auc:  0.6419 - logloss:  0.4246 - val_auc:  0.6728 - val_logloss:  0.4150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 88.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "1s - loss:  0.4637 - auc:  0.6827 - logloss:  0.4128 - val_auc:  0.6972 - val_logloss:  0.4080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 74.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "2s - loss:  0.4517 - auc:  0.7040 - logloss:  0.4064 - val_auc:  0.7118 - val_logloss:  0.4023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 87.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "1s - loss:  0.4413 - auc:  0.7180 - logloss:  0.4007 - val_auc:  0.7235 - val_logloss:  0.3973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 89.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "1s - loss:  0.4318 - auc:  0.7298 - logloss:  0.3957 - val_auc:  0.7322 - val_logloss:  0.3930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 81.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "2s - loss:  0.4239 - auc:  0.7387 - logloss:  0.3916 - val_auc:  0.7388 - val_logloss:  0.3893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 85.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "1s - loss:  0.4177 - auc:  0.7436 - logloss:  0.3888 - val_auc:  0.7435 - val_logloss:  0.3874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 85.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n",
      "1s - loss:  0.4126 - auc:  0.7472 - logloss:  0.3868 - val_auc:  0.7467 - val_logloss:  0.3855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 83.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n",
      "1s - loss:  0.4086 - auc:  0.7503 - logloss:  0.3856 - val_auc:  0.7489 - val_logloss:  0.3842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 81.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "2s - loss:  0.4049 - auc:  0.7530 - logloss:  0.3839 - val_auc:  0.7517 - val_logloss:  0.3839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 81.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "1s - loss:  0.4018 - auc:  0.7546 - logloss:  0.3830 - val_auc:  0.7527 - val_logloss:  0.3832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 83.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "1s - loss:  0.3992 - auc:  0.7560 - logloss:  0.3822 - val_auc:  0.7541 - val_logloss:  0.3817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 79.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n",
      "2s - loss:  0.3969 - auc:  0.7572 - logloss:  0.3814 - val_auc:  0.7559 - val_logloss:  0.3811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 81.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20\n",
      "2s - loss:  0.3948 - auc:  0.7590 - logloss:  0.3807 - val_auc:  0.7569 - val_logloss:  0.3801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 80.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "2s - loss:  0.3928 - auc:  0.7602 - logloss:  0.3800 - val_auc:  0.7581 - val_logloss:  0.3801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 79.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n",
      "2s - loss:  0.3914 - auc:  0.7608 - logloss:  0.3798 - val_auc:  0.7591 - val_logloss:  0.3789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 82.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20\n",
      "1s - loss:  0.3896 - auc:  0.7625 - logloss:  0.3790 - val_auc:  0.7604 - val_logloss:  0.3784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 79.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n",
      "2s - loss:  0.3882 - auc:  0.7612 - logloss:  0.3785 - val_auc:  0.7619 - val_logloss:  0.3775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 82.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "1s - loss:  0.3868 - auc:  0.7637 - logloss:  0.3781 - val_auc:  0.7628 - val_logloss:  0.3785\n"
     ]
    }
   ],
   "source": [
    "model_name = 'DNN'\n",
    "epoch = 20\n",
    "batch_size = 300\n",
    "\n",
    "model = WDL(linear_feature_columns=[], \n",
    "            dnn_feature_columns=dnn_feature_columns, \n",
    "            dnn_use_bn=True,\n",
    "            l2_reg_dnn=0.1, \n",
    "            l2_reg_embedding = 0.0001, \n",
    "            dnn_hidden_units=(128,64), \n",
    "            init_std=1, \n",
    "            dnn_dropout=0.5, \n",
    "            task='binary', \n",
    "            dnn_activation='relu', \n",
    "            device=device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.1, amsgrad=True)\n",
    "model.compile(optimizer, 'binary_crossentropy',metrics=['auc','logloss'])\n",
    "model.fit(train_model_input,  train_label.values.astype(int), batch_size=batch_size, epochs=epoch, validation_data=(test_model_input1,test_label1),verbose=1)\n",
    "res = model.evaluate(test_model_input1,test_label1)\n",
    "pred1 = model.predict(test_model_input1)\n",
    "results[model_name] = model, res, pred1, test_label1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WDL\n",
    "Wide and Deep model [3] is widely accepted in real industrial applications. Compared with DNN, it has an additional linear model besides the deep model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Train on 46361 samples, validate on 11690 samples, 155 steps per epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 62.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2s - loss:  0.5583 - auc:  0.5602 - logloss:  0.4944 - val_auc:  0.6638 - val_logloss:  0.4338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 60.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "2s - loss:  0.4688 - auc:  0.6965 - logloss:  0.4106 - val_auc:  0.6995 - val_logloss:  0.4060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 64.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "2s - loss:  0.4518 - auc:  0.7289 - logloss:  0.3993 - val_auc:  0.7177 - val_logloss:  0.4002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 64.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "2s - loss:  0.4399 - auc:  0.7461 - logloss:  0.3923 - val_auc:  0.7281 - val_logloss:  0.3958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 65.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "2s - loss:  0.4301 - auc:  0.7569 - logloss:  0.3869 - val_auc:  0.7358 - val_logloss:  0.3923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 65.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "2s - loss:  0.4217 - auc:  0.7639 - logloss:  0.3832 - val_auc:  0.7424 - val_logloss:  0.3892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 65.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "2s - loss:  0.4145 - auc:  0.7709 - logloss:  0.3802 - val_auc:  0.7461 - val_logloss:  0.3867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 64.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "2s - loss:  0.4082 - auc:  0.7736 - logloss:  0.3773 - val_auc:  0.7495 - val_logloss:  0.3851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 59.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n",
      "2s - loss:  0.4029 - auc:  0.7777 - logloss:  0.3750 - val_auc:  0.7518 - val_logloss:  0.3835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 53.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n",
      "3s - loss:  0.3980 - auc:  0.7801 - logloss:  0.3728 - val_auc:  0.7545 - val_logloss:  0.3820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 51.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "3s - loss:  0.3941 - auc:  0.7831 - logloss:  0.3718 - val_auc:  0.7550 - val_logloss:  0.3815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 55.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "2s - loss:  0.3905 - auc:  0.7844 - logloss:  0.3702 - val_auc:  0.7569 - val_logloss:  0.3804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 55.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "2s - loss:  0.3875 - auc:  0.7861 - logloss:  0.3692 - val_auc:  0.7586 - val_logloss:  0.3793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 55.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n",
      "2s - loss:  0.3846 - auc:  0.7873 - logloss:  0.3679 - val_auc:  0.7596 - val_logloss:  0.3785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 55.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20\n",
      "2s - loss:  0.3821 - auc:  0.7896 - logloss:  0.3672 - val_auc:  0.7608 - val_logloss:  0.3779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 55.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "2s - loss:  0.3795 - auc:  0.7911 - logloss:  0.3658 - val_auc:  0.7626 - val_logloss:  0.3770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 56.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n",
      "2s - loss:  0.3775 - auc:  0.7934 - logloss:  0.3652 - val_auc:  0.7634 - val_logloss:  0.3762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 55.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20\n",
      "2s - loss:  0.3754 - auc:  0.7949 - logloss:  0.3638 - val_auc:  0.7653 - val_logloss:  0.3754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 55.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n",
      "2s - loss:  0.3735 - auc:  0.7964 - logloss:  0.3629 - val_auc:  0.7661 - val_logloss:  0.3747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 55.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "2s - loss:  0.3718 - auc:  0.7980 - logloss:  0.3619 - val_auc:  0.7678 - val_logloss:  0.3740\n"
     ]
    }
   ],
   "source": [
    "model_name = 'WDL'\n",
    "epoch = 20\n",
    "batch_size = 300\n",
    "\n",
    "model = WDL(linear_feature_columns=linear_feature_columns, \n",
    "            dnn_feature_columns=dnn_feature_columns, \n",
    "            dnn_use_bn=True,\n",
    "            l2_reg_dnn=0.1, \n",
    "            l2_reg_embedding = 0.0001, \n",
    "            dnn_hidden_units=(128,64), \n",
    "            init_std=1, \n",
    "            dnn_dropout=0.5, \n",
    "            task='binary', \n",
    "            dnn_activation='relu', \n",
    "            device=device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.05, amsgrad=True)\n",
    "model.compile(optimizer, 'binary_crossentropy',metrics=['auc','logloss'])\n",
    "model.fit(train_model_input,  train_label.values.astype(int), batch_size=batch_size, epochs=epoch, validation_data=(test_model_input1,test_label1),verbose=1)\n",
    "\n",
    "res = model.evaluate(test_model_input1,test_label1)\n",
    "pred1 = model.predict(test_model_input1)\n",
    "\n",
    "results[model_name] = model, res, pred1, test_label1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIN\n",
    "Deep Interest Network [4] is an attention-based model in recommendation systems that has been proven successful in Alibaba. We use this as our second baseline, replacing the user’s historical item sequences with user’s historical voucher sequences to adapt to the VRR prediction task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start generating x y data\n",
      "['session_id', 'user_gender', 'user_age_level', 'user_purchase_level', 'promotion_id', 'hist_promotion_id', 'voucher_min_spend', 'voucher_discount', 'user_trd__orders_cnt_hist', 'user_trd__actual_gmv_usd_hist', 'user_trd__orders_cnt_platform_discount_hist', 'user_trd__max_gmv_usd_hist', 'user_trd__avg_gmv_usd_hist', 'user_trd__min_gmv_usd_hist', 'keys_length']\n",
      "handling hist_list_features Feature: hist_promotion_id\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46361/46361 [00:00<00:00, 103278.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoderExt transforming...\n",
      "start generating x y data\n",
      "['session_id', 'user_gender', 'user_age_level', 'user_purchase_level', 'promotion_id', 'hist_promotion_id', 'voucher_min_spend', 'voucher_discount', 'user_trd__orders_cnt_hist', 'user_trd__actual_gmv_usd_hist', 'user_trd__orders_cnt_platform_discount_hist', 'user_trd__max_gmv_usd_hist', 'user_trd__avg_gmv_usd_hist', 'user_trd__min_gmv_usd_hist', 'keys_length']\n",
      "handling hist_list_features Feature: hist_promotion_id\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11690/11690 [00:00<00:00, 77285.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoderExt transforming...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "def get_xy_fd(dataset):\n",
    "    print (\"start generating x y data\")\n",
    "    \n",
    "    dnn_feature_columns = []\n",
    "    dnn_feature_columns += [SparseFeat(feat, len(label_encoder[feat]), embedding_dim = 16) \n",
    "                            for feat in ['session_id','user_gender','user_age_level','user_purchase_level', 'promotion_id']]\n",
    "    \n",
    "    dnn_feature_columns += [VarLenSparseFeat(SparseFeat('hist_promotion_id', len(label_encoder[\"promotion_id\"]), embedding_dim=16), sequence_size)]\n",
    "    \n",
    "    dnn_feature_columns += [DenseFeat(feat, 1, )  for feat in dense_feature]\n",
    "    dnn_feature_columns += [DenseFeat(feat, 1, )  for feat in ['keys_length']]\n",
    "\n",
    "    feature_names = get_feature_names(dnn_feature_columns)\n",
    "    print (feature_names)\n",
    "    \n",
    "    behavior_feature_list = ['promotion_id']\n",
    "\n",
    "    y, x = gen_dmbgn_input_data(feature_names, dataset, target, label_encoder, 6, sparse_feature, hist_list_features)\n",
    "    return x, y, dnn_feature_columns, behavior_feature_list\n",
    "\n",
    "sequence_size = 6\n",
    "embedding_dim1 = 16\n",
    "\n",
    "x, y, dnn_feature_columns, behavior_feature_list = get_xy_fd(dctr_train)\n",
    "test_model_input1, test_label1, _, _ = get_xy_fd(dctr_v1)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DIN(\n",
       "  (embedding_dict): ModuleDict(\n",
       "    (hist_promotion_id): Embedding(462, 16)\n",
       "    (promotion_id): Embedding(462, 16)\n",
       "    (session_id): Embedding(58052, 16)\n",
       "    (user_age_level): Embedding(10, 16)\n",
       "    (user_gender): Embedding(4, 16)\n",
       "    (user_purchase_level): Embedding(12, 16)\n",
       "  )\n",
       "  (linear_model): Linear(\n",
       "    (embedding_dict): ModuleDict()\n",
       "  )\n",
       "  (out): PredictionLayer()\n",
       "  (attention): HistAttentionSeqPoolingLayer(\n",
       "    (local_att): AttentionUnit(\n",
       "      (dnn): DNN(\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (linears): ModuleList(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (activation_layers): ModuleList(\n",
       "          (0): PReLU(num_parameters=1)\n",
       "        )\n",
       "      )\n",
       "      (dense): Linear(in_features=64, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (dnn): DNN(\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (linears): ModuleList(\n",
       "      (0): Linear(in_features=104, out_features=128, bias=True)\n",
       "      (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "    )\n",
       "    (bn): ModuleList(\n",
       "      (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (activation_layers): ModuleList(\n",
       "      (0): ReLU(inplace=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (dnn_linear): Linear(in_features=64, out_features=1, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'DIN'\n",
    "\n",
    "model = DIN(dnn_feature_columns, \n",
    "            behavior_feature_list, \n",
    "            # target_emb_dim_aft=0, \n",
    "            device=device, \n",
    "            att_activation='prelu', \n",
    "            att_weight_normalization=False, \n",
    "            dnn_activation='relu', \n",
    "            l2_reg_dnn=0.1, \n",
    "            l2_reg_embedding = 0.0001, \n",
    "            dnn_hidden_units=(128,64), \n",
    "            att_hidden_size=(64,), \n",
    "            init_std=1, \n",
    "            dnn_dropout=0.5, \n",
    "            dnn_use_bn=True)\n",
    "\n",
    "\n",
    "model.embedding_dict['promotion_id'].requires_grad = True\n",
    "model.embedding_dict['promotion_id'].weight.requires_grad = True\n",
    "\n",
    "model.embedding_dict['hist_promotion_id'].requires_grad = True\n",
    "model.embedding_dict['hist_promotion_id'].weight.requires_grad = True\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.05, amsgrad=True)\n",
    "model.compile(optimizer, 'binary_crossentropy', metrics=['auc', 'logloss'])\n",
    "\n",
    "loss_func = model.loss_func\n",
    "optim = model.optim\n",
    "metrics = model.metrics\n",
    "feature_index = model.feature_index\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_ids = [i for i in range(torch.cuda.device_count())]\n",
    "device_count = len(device_ids)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model = torch.nn.DataParallel(model, device_ids)\n",
    "    \n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 46361 samples, validate on 11690 samples, 155 steps per epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 53.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.4623 - auc:  0.6160 - logloss:  0.4618 - val_auc:  0.6995 - val_logloss:  0.4034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 56.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "Epoch Time : 2\n",
      "2s - loss:  0.3950 - auc:  0.7273 - logloss:  0.3946 - val_auc:  0.7415 - val_logloss:  0.3870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 56.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "Epoch Time : 2\n",
      "2s - loss:  0.3828 - auc:  0.7554 - logloss:  0.3826 - val_auc:  0.7531 - val_logloss:  0.3809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 56.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "Epoch Time : 2\n",
      "2s - loss:  0.3766 - auc:  0.7657 - logloss:  0.3765 - val_auc:  0.7643 - val_logloss:  0.3756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 54.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.3700 - auc:  0.7780 - logloss:  0.3699 - val_auc:  0.7701 - val_logloss:  0.3736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 56.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "Epoch Time : 2\n",
      "2s - loss:  0.3660 - auc:  0.7860 - logloss:  0.3659 - val_auc:  0.7690 - val_logloss:  0.3787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 55.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "Epoch Time : 2\n",
      "2s - loss:  0.3616 - auc:  0.7929 - logloss:  0.3614 - val_auc:  0.7762 - val_logloss:  0.3682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 56.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "Epoch Time : 2\n",
      "2s - loss:  0.3583 - auc:  0.7979 - logloss:  0.3580 - val_auc:  0.7756 - val_logloss:  0.3682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 54.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n",
      "Epoch Time : 2\n",
      "2s - loss:  0.3539 - auc:  0.8038 - logloss:  0.3538 - val_auc:  0.7761 - val_logloss:  0.3684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 55.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.3505 - auc:  0.8095 - logloss:  0.3504 - val_auc:  0.7791 - val_logloss:  0.3682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 51.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.3473 - auc:  0.8148 - logloss:  0.3473 - val_auc:  0.7809 - val_logloss:  0.3677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 53.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.3435 - auc:  0.8212 - logloss:  0.3433 - val_auc:  0.7752 - val_logloss:  0.3727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 54.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.3376 - auc:  0.8279 - logloss:  0.3377 - val_auc:  0.7780 - val_logloss:  0.3700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 53.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.3293 - auc:  0.8392 - logloss:  0.3291 - val_auc:  0.7757 - val_logloss:  0.3738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 54.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.3181 - auc:  0.8540 - logloss:  0.3181 - val_auc:  0.7635 - val_logloss:  0.3889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 53.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.2952 - auc:  0.8789 - logloss:  0.2950 - val_auc:  0.7596 - val_logloss:  0.4034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 53.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.2491 - auc:  0.9180 - logloss:  0.2491 - val_auc:  0.7335 - val_logloss:  0.4638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 54.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.1727 - auc:  0.9620 - logloss:  0.1727 - val_auc:  0.7222 - val_logloss:  0.5476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 53.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.0934 - auc:  0.9872 - logloss:  0.0933 - val_auc:  0.6983 - val_logloss:  0.7064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 51.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.0447 - auc:  0.9965 - logloss:  0.0433 - val_auc:  0.7193 - val_logloss:  inf\n"
     ]
    }
   ],
   "source": [
    "epoch = 20\n",
    "batch_size = 300\n",
    "res, pred1 = fit(model, feature_index, optim, metrics, loss_func, x, y, batch_size=batch_size, epochs=epoch, validation_data=(test_model_input1,test_label1),verbose=1, device=device, device_count=device_count)\n",
    "\n",
    "results[model_name] = model, res, pred1, test_label1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Method: DMBGN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DMBGN-AvgPooling\n",
    "Instead of using Higher-order Graph Neural Networks to model user-voucher-item relationships, it directly takes an average of pre-trained item embeddings from user behavior happening both before and after voucher collection. For target UVG, it only takes an average of pre-collection item embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "286735it [00:16, 17578.66it/s]\n"
     ]
    }
   ],
   "source": [
    "def process_pretrain_emb(emb, emb_size = 16, spliter = \" \"):\n",
    "    return np.zeros(emb_size, dtype=np.float32) if emb == 'nan' else np.array(emb.split(spliter), dtype=np.float32)\n",
    "\n",
    "item_df[['atc_emb', 'ord_emb']] = item_df[['atc_emb', 'ord_emb']].astype('str')\n",
    "item_emb_dict = {}\n",
    "for index, row in tqdm(item_df.iterrows()):\n",
    "    item_emb_dict[row['item_id']] = process_pretrain_emb(row['atc_emb']), process_pretrain_emb(row['ord_emb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoderExt transforming...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1118593it [00:53, 20772.87it/s]\n",
      "100%|██████████| 58052/58052 [00:00<00:00, 177866.67it/s]\n",
      "100%|██████████| 58052/58052 [00:00<00:00, 398946.36it/s]\n"
     ]
    }
   ],
   "source": [
    "emb_size = 16\n",
    "sid_emb_dict_tmp = {}\n",
    "\n",
    "session_df['sid_enc'] = label_encoder['session_id'].transform(session_df['session_id'])\n",
    "\n",
    "for index, row in tqdm(session_df.iterrows()):\n",
    "    sid = row['sid_enc']\n",
    "    if sid not in sid_emb_dict_tmp:\n",
    "        sid_emb_dict_tmp[row['sid_enc']] = np.zeros(emb_size, dtype=np.float32), np.zeros(emb_size, dtype=np.float32), 0, 0\n",
    "    \n",
    "    if row['rk'] > 6:\n",
    "        continue\n",
    "    \n",
    "    emb_bef, emb_aft, cnt_bef, cnt_aft = sid_emb_dict_tmp.get(sid)\n",
    "    item_atc_emb, item_ord_emb = item_emb_dict.get(row['item_id'])\n",
    "    if row['type'] == 'bef':\n",
    "        emb_bef += item_atc_emb if row['action_type'] == 'cart' else item_ord_emb\n",
    "        cnt_bef += 1\n",
    "    else:\n",
    "        emb_aft += item_atc_emb if row['action_type'] == 'cart' else item_ord_emb\n",
    "        cnt_aft += 1\n",
    "    sid_emb_dict_tmp[sid] = emb_bef, emb_aft, cnt_bef, cnt_aft\n",
    "\n",
    "sid_emb_dict = {}\n",
    "for sid, value in tqdm(sid_emb_dict_tmp.items()):\n",
    "    emb_bef, emb_aft, cnt_bef, cnt_aft = value\n",
    "    sid_emb_dict[sid] = np.concatenate((emb_bef/(1.0*cnt_bef), emb_aft/(1.0*cnt_aft)), axis=0)\n",
    "\n",
    "sid_emb_dict_bef = {}\n",
    "for sid, value in tqdm(sid_emb_dict_tmp.items()):\n",
    "    emb_bef, emb_aft, cnt_bef, cnt_aft = value\n",
    "    sid_emb_dict_bef[sid] = emb_bef/(1.0*cnt_bef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_emb_ts(emb_dic, requires_grad = False, emb_size = 16, lbe = None):\n",
    "    if lbe is None:\n",
    "        raise Exception(\"Encoder is empty\")\n",
    "        \n",
    "    indices = lbe.transform([str(val) for val in emb_dic.keys()])\n",
    "    session_size = int(len(lbe))\n",
    "    \n",
    "    ts_emb = torch.rand(session_size, emb_size, dtype = torch.float)\n",
    "    for i, (key, emb) in tqdm(enumerate(emb_dic.items())):\n",
    "        ts_emb[indices[i]] = torch.FloatTensor(emb)\n",
    "    emb_ts = torch.nn.Embedding.from_pretrained(ts_emb)\n",
    "    emb_ts.weight.requires_grad = requires_grad\n",
    "    return emb_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoderExt transforming...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "58052it [00:00, 105467.03it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(58052, 32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sid_emb_ts = init_emb_ts(sid_emb_dict, emb_size = 32, lbe=label_encoder['session_id'])\n",
    "sid_emb_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xy_fd(dataset):\n",
    "    print (\"start generating x y data\")\n",
    "    \n",
    "    dnn_feature_columns = []\n",
    "    dnn_feature_columns += [SparseFeat(feat, len(label_encoder[feat]), embedding_dim = embedding_dim1) for feat in ['user_gender','user_age_level','user_purchase_level']]\n",
    "    dnn_feature_columns += [SparseFeat(feat, len(label_encoder['promotion_id']), embedding_dim = embedding_dim2) for feat in ['session_id']]\n",
    "    dnn_feature_columns += [SparseFeat(feat, len(label_encoder[feat]), embedding_dim = embedding_dim2) for feat in ['promotion_id']]\n",
    "    dnn_feature_columns += [SparseFeat(feat, len(label_encoder['session_id']), embedding_dim = embedding_dim1) for feat in ['sid']]\n",
    "    \n",
    "    dnn_feature_columns += [VarLenSparseFeat(SparseFeat('hist_promotion_id', len(label_encoder[\"promotion_id\"]), embedding_dim=embedding_dim2), sequence_size)]\n",
    "    dnn_feature_columns += [VarLenSparseFeat(SparseFeat('hist_session_id', len(label_encoder[\"session_id\"]), embedding_dim=embedding_dim2), sequence_size)]\n",
    "\n",
    "    dnn_feature_columns += [DenseFeat(feat, 1, )  for feat in dense_feature]\n",
    "    dnn_feature_columns += [DenseFeat(feat, 1, )  for feat in ['keys_length']]\n",
    "\n",
    "    feature_names = get_feature_names(dnn_feature_columns)\n",
    "    print (\"feature_names:\", feature_names)\n",
    "    \n",
    "    behavior_feature_list = ['promotion_id', 'session_id']\n",
    "    dataset['sid'] = dataset['session_id']\n",
    "    y, x = gen_dmbgn_input_data(feature_names, dataset, target, label_encoder, 6, sparse_feature, hist_list_features)\n",
    "    x['session_id'] = x['promotion_id']\n",
    "    return x, y, dnn_feature_columns, behavior_feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "start generating x y data\n",
      "feature_names: ['user_gender', 'user_age_level', 'user_purchase_level', 'session_id', 'promotion_id', 'sid', 'hist_promotion_id', 'hist_session_id', 'voucher_min_spend', 'voucher_discount', 'user_trd__orders_cnt_hist', 'user_trd__actual_gmv_usd_hist', 'user_trd__orders_cnt_platform_discount_hist', 'user_trd__max_gmv_usd_hist', 'user_trd__avg_gmv_usd_hist', 'user_trd__min_gmv_usd_hist', 'keys_length']\n",
      "handling hist_list_features Feature: hist_promotion_id\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46361/46361 [00:00<00:00, 97797.25it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoderExt transforming...\n",
      "handling hist_list_features Feature: hist_session_id\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46361/46361 [00:00<00:00, 110254.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoderExt transforming...\n",
      "start generating x y data\n",
      "feature_names: ['user_gender', 'user_age_level', 'user_purchase_level', 'session_id', 'promotion_id', 'sid', 'hist_promotion_id', 'hist_session_id', 'voucher_min_spend', 'voucher_discount', 'user_trd__orders_cnt_hist', 'user_trd__actual_gmv_usd_hist', 'user_trd__orders_cnt_platform_discount_hist', 'user_trd__max_gmv_usd_hist', 'user_trd__avg_gmv_usd_hist', 'user_trd__min_gmv_usd_hist', 'keys_length']\n",
      "handling hist_list_features Feature: hist_promotion_id\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11690/11690 [00:00<00:00, 72674.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoderExt transforming...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "handling hist_list_features Feature: hist_session_id\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11690/11690 [00:00<00:00, 96327.20it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoderExt transforming...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "sequence_size = 6\n",
    "embedding_dim1 = 16 # pid\n",
    "embedding_dim2 = sid_emb_ts.weight.shape[1] #sid\n",
    "print(embedding_dim2)\n",
    "\n",
    "x, y, dnn_feature_columns, behavior_feature_list = get_xy_fd(dctr_train)\n",
    "test_model_input1, test_label1, _, _ = get_xy_fd(dctr_v1)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DMBGN(\n",
       "  (embedding_dict): ModuleDict(\n",
       "    (hist_promotion_id): Embedding(462, 32)\n",
       "    (hist_session_id): Embedding(58052, 32)\n",
       "    (promotion_id): Embedding(462, 32)\n",
       "    (session_id): Embedding(462, 32)\n",
       "    (sid): Embedding(58052, 16)\n",
       "    (user_age_level): Embedding(10, 16)\n",
       "    (user_gender): Embedding(4, 16)\n",
       "    (user_purchase_level): Embedding(12, 16)\n",
       "  )\n",
       "  (linear_model): Linear(\n",
       "    (embedding_dict): ModuleDict()\n",
       "  )\n",
       "  (out): PredictionLayer()\n",
       "  (attention): HistAttentionSeqPoolingLayer(\n",
       "    (local_att): AttentionUnit(\n",
       "      (dnn): DNN(\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (linears): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=64, bias=True)\n",
       "        )\n",
       "        (activation_layers): ModuleList(\n",
       "          (0): PReLU(num_parameters=1)\n",
       "        )\n",
       "      )\n",
       "      (dense): Linear(in_features=64, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (dnn): DNN(\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (linears): ModuleList(\n",
       "      (0): Linear(in_features=209, out_features=128, bias=True)\n",
       "      (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "    )\n",
       "    (bn): ModuleList(\n",
       "      (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (activation_layers): ModuleList(\n",
       "      (0): ReLU(inplace=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (dnn_linear): Linear(in_features=64, out_features=1, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'DMBGN_AvgPooling'\n",
    "\n",
    "model = DMBGN(dnn_feature_columns, \n",
    "            behavior_feature_list, \n",
    "            target_emb_dim_aft=0, \n",
    "            sequence_size=6,\n",
    "            device=device, \n",
    "            att_activation='prelu', \n",
    "            att_weight_normalization=False, \n",
    "            dnn_activation='relu', \n",
    "            l2_reg_dnn=0.1, \n",
    "            l2_reg_embedding = 0.0001, \n",
    "            dnn_hidden_units=(128,64), \n",
    "            att_hidden_size=(64,), \n",
    "            init_std=1, \n",
    "            dnn_dropout=0.5, \n",
    "            dnn_use_bn=True)\n",
    "\n",
    "model.embedding_dict['hist_session_id'] = sid_emb_ts\n",
    "model.embedding_dict['hist_session_id'].requires_grad = False\n",
    "model.embedding_dict['hist_session_id'].weight.requires_grad = False\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.05, amsgrad=True)\n",
    "model.compile(optimizer, 'binary_crossentropy', metrics=['auc', 'logloss'])\n",
    "\n",
    "\n",
    "loss_func = model.loss_func\n",
    "optim = model.optim\n",
    "metrics = model.metrics\n",
    "feature_index = model.feature_index\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_ids = [i for i in range(torch.cuda.device_count())]\n",
    "device_count = len(device_ids)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Use\", device_count, \"GPUs!\")\n",
    "    model = torch.nn.DataParallel(model, device_ids)\n",
    "    \n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 46361 samples, validate on 11690 samples, 155 steps per epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 43.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.5413 - auc:  0.6270 - logloss:  0.4760 - val_auc:  0.7177 - val_logloss:  0.4016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 43.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.4444 - auc:  0.7403 - logloss:  0.3893 - val_auc:  0.7491 - val_logloss:  0.3831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 43.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.4252 - auc:  0.7598 - logloss:  0.3788 - val_auc:  0.7525 - val_logloss:  0.3831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 40.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "Epoch Time : 4\n",
      "4s - loss:  0.4147 - auc:  0.7713 - logloss:  0.3735 - val_auc:  0.7616 - val_logloss:  0.3786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 45.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.4074 - auc:  0.7797 - logloss:  0.3690 - val_auc:  0.7660 - val_logloss:  0.3775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 43.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.4015 - auc:  0.7877 - logloss:  0.3642 - val_auc:  0.7697 - val_logloss:  0.3747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 44.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.3983 - auc:  0.7934 - logloss:  0.3616 - val_auc:  0.7778 - val_logloss:  0.3689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 42.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.3939 - auc:  0.7978 - logloss:  0.3576 - val_auc:  0.7778 - val_logloss:  0.3684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 45.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.3901 - auc:  0.8043 - logloss:  0.3543 - val_auc:  0.7757 - val_logloss:  0.3730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 42.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.3869 - auc:  0.8086 - logloss:  0.3514 - val_auc:  0.7758 - val_logloss:  0.3706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 41.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.3837 - auc:  0.8123 - logloss:  0.3485 - val_auc:  0.7787 - val_logloss:  0.3697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 41.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "Epoch Time : 4\n",
      "4s - loss:  0.3815 - auc:  0.8160 - logloss:  0.3461 - val_auc:  0.7796 - val_logloss:  0.3701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 42.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.3764 - auc:  0.8231 - logloss:  0.3413 - val_auc:  0.7702 - val_logloss:  0.3711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 42.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.3721 - auc:  0.8289 - logloss:  0.3371 - val_auc:  0.7730 - val_logloss:  0.3735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 42.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.3663 - auc:  0.8366 - logloss:  0.3313 - val_auc:  0.7760 - val_logloss:  0.3727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 41.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "Epoch Time : 4\n",
      "4s - loss:  0.3556 - auc:  0.8503 - logloss:  0.3208 - val_auc:  0.7661 - val_logloss:  0.3925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 42.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.3369 - auc:  0.8721 - logloss:  0.3022 - val_auc:  0.7589 - val_logloss:  0.3998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 42.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.3003 - auc:  0.9088 - logloss:  0.2654 - val_auc:  0.7398 - val_logloss:  0.4565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 39.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n",
      "Epoch Time : 4\n",
      "4s - loss:  0.2313 - auc:  0.9534 - logloss:  0.1965 - val_auc:  0.7298 - val_logloss:  0.5436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 41.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.1424 - auc:  0.9843 - logloss:  0.1078 - val_auc:  0.7065 - val_logloss:  0.7073\n"
     ]
    }
   ],
   "source": [
    "epoch = 20\n",
    "batch_size = 300\n",
    "res, pred1 = fit(model, feature_index, optim, metrics, loss_func, x, y, batch_size=batch_size, epochs=epoch, validation_data=(test_model_input1,test_label1),verbose=1, device=device, device_count=device_count)\n",
    "\n",
    "results[model_name] = model, res, pred1, test_label1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DMBGN-Pretrained\n",
    "It uses the same weight parameters of Higher-order GNN learned during the voucher embedding pre-training as mentioned in Section 3.3. The values of weight parameters are not further updated during the main task training for DMBGN-Pretrained variant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoderExt fitting...\n",
      "LabelEncoderExt transforming...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>session_id</th>\n",
       "      <th>promotion_id</th>\n",
       "      <th>voucher_min_spend</th>\n",
       "      <th>voucher_discount_amount</th>\n",
       "      <th>voucher_collect_time</th>\n",
       "      <th>item_id</th>\n",
       "      <th>action_type</th>\n",
       "      <th>type</th>\n",
       "      <th>rk</th>\n",
       "      <th>action_time</th>\n",
       "      <th>item_category_id</th>\n",
       "      <th>item_brand_id</th>\n",
       "      <th>item_price_level</th>\n",
       "      <th>sid_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9180</td>\n",
       "      <td>20</td>\n",
       "      <td>4999</td>\n",
       "      <td>600</td>\n",
       "      <td>10999</td>\n",
       "      <td>85356</td>\n",
       "      <td>cart</td>\n",
       "      <td>bef</td>\n",
       "      <td>12</td>\n",
       "      <td>6874</td>\n",
       "      <td>9567</td>\n",
       "      <td>106903</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>9180</td>\n",
       "      <td>20</td>\n",
       "      <td>4999</td>\n",
       "      <td>600</td>\n",
       "      <td>10999</td>\n",
       "      <td>85352</td>\n",
       "      <td>cart</td>\n",
       "      <td>bef</td>\n",
       "      <td>11</td>\n",
       "      <td>6850</td>\n",
       "      <td>9567</td>\n",
       "      <td>106903</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>9180</td>\n",
       "      <td>20</td>\n",
       "      <td>4999</td>\n",
       "      <td>600</td>\n",
       "      <td>10999</td>\n",
       "      <td>85351</td>\n",
       "      <td>cart</td>\n",
       "      <td>bef</td>\n",
       "      <td>10</td>\n",
       "      <td>6838</td>\n",
       "      <td>9567</td>\n",
       "      <td>106903</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>9180</td>\n",
       "      <td>20</td>\n",
       "      <td>4999</td>\n",
       "      <td>600</td>\n",
       "      <td>10999</td>\n",
       "      <td>92250</td>\n",
       "      <td>cart</td>\n",
       "      <td>bef</td>\n",
       "      <td>9</td>\n",
       "      <td>6871</td>\n",
       "      <td>9567</td>\n",
       "      <td>106903</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>9180</td>\n",
       "      <td>20</td>\n",
       "      <td>4999</td>\n",
       "      <td>600</td>\n",
       "      <td>10999</td>\n",
       "      <td>88965</td>\n",
       "      <td>cart</td>\n",
       "      <td>bef</td>\n",
       "      <td>8</td>\n",
       "      <td>6838</td>\n",
       "      <td>2272</td>\n",
       "      <td>106903</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118588</th>\n",
       "      <td>0</td>\n",
       "      <td>17339</td>\n",
       "      <td>310</td>\n",
       "      <td>349</td>\n",
       "      <td>30</td>\n",
       "      <td>119218</td>\n",
       "      <td>19882</td>\n",
       "      <td>order</td>\n",
       "      <td>aft</td>\n",
       "      <td>3</td>\n",
       "      <td>129021</td>\n",
       "      <td>12057</td>\n",
       "      <td>56645</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118589</th>\n",
       "      <td>0</td>\n",
       "      <td>17339</td>\n",
       "      <td>310</td>\n",
       "      <td>349</td>\n",
       "      <td>30</td>\n",
       "      <td>119218</td>\n",
       "      <td>1333</td>\n",
       "      <td>order</td>\n",
       "      <td>aft</td>\n",
       "      <td>4</td>\n",
       "      <td>129021</td>\n",
       "      <td>13895</td>\n",
       "      <td>56645</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118590</th>\n",
       "      <td>0</td>\n",
       "      <td>17339</td>\n",
       "      <td>310</td>\n",
       "      <td>349</td>\n",
       "      <td>30</td>\n",
       "      <td>119218</td>\n",
       "      <td>65011</td>\n",
       "      <td>order</td>\n",
       "      <td>aft</td>\n",
       "      <td>5</td>\n",
       "      <td>129021</td>\n",
       "      <td>12141</td>\n",
       "      <td>56645</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118591</th>\n",
       "      <td>0</td>\n",
       "      <td>17339</td>\n",
       "      <td>310</td>\n",
       "      <td>349</td>\n",
       "      <td>30</td>\n",
       "      <td>119218</td>\n",
       "      <td>18048</td>\n",
       "      <td>order</td>\n",
       "      <td>aft</td>\n",
       "      <td>6</td>\n",
       "      <td>129021</td>\n",
       "      <td>13895</td>\n",
       "      <td>56645</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118592</th>\n",
       "      <td>0</td>\n",
       "      <td>17339</td>\n",
       "      <td>310</td>\n",
       "      <td>349</td>\n",
       "      <td>30</td>\n",
       "      <td>119218</td>\n",
       "      <td>8252</td>\n",
       "      <td>order</td>\n",
       "      <td>aft</td>\n",
       "      <td>7</td>\n",
       "      <td>129021</td>\n",
       "      <td>6505</td>\n",
       "      <td>56645</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1118593 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         label  session_id promotion_id  voucher_min_spend  \\\n",
       "0            0        9180           20               4999   \n",
       "1            0        9180           20               4999   \n",
       "2            0        9180           20               4999   \n",
       "3            0        9180           20               4999   \n",
       "4            0        9180           20               4999   \n",
       "...        ...         ...          ...                ...   \n",
       "1118588      0       17339          310                349   \n",
       "1118589      0       17339          310                349   \n",
       "1118590      0       17339          310                349   \n",
       "1118591      0       17339          310                349   \n",
       "1118592      0       17339          310                349   \n",
       "\n",
       "         voucher_discount_amount voucher_collect_time item_id action_type  \\\n",
       "0                            600                10999   85356        cart   \n",
       "1                            600                10999   85352        cart   \n",
       "2                            600                10999   85351        cart   \n",
       "3                            600                10999   92250        cart   \n",
       "4                            600                10999   88965        cart   \n",
       "...                          ...                  ...     ...         ...   \n",
       "1118588                       30               119218   19882       order   \n",
       "1118589                       30               119218    1333       order   \n",
       "1118590                       30               119218   65011       order   \n",
       "1118591                       30               119218   18048       order   \n",
       "1118592                       30               119218    8252       order   \n",
       "\n",
       "        type  rk action_time  item_category_id  item_brand_id  \\\n",
       "0        bef  12        6874              9567         106903   \n",
       "1        bef  11        6850              9567         106903   \n",
       "2        bef  10        6838              9567         106903   \n",
       "3        bef   9        6871              9567         106903   \n",
       "4        bef   8        6838              2272         106903   \n",
       "...      ...  ..         ...               ...            ...   \n",
       "1118588  aft   3      129021             12057          56645   \n",
       "1118589  aft   4      129021             13895          56645   \n",
       "1118590  aft   5      129021             12141          56645   \n",
       "1118591  aft   6      129021             13895          56645   \n",
       "1118592  aft   7      129021              6505          56645   \n",
       "\n",
       "         item_price_level  sid_enc  \n",
       "0                     7.0     8998  \n",
       "1                     7.0     8998  \n",
       "2                     7.0     8998  \n",
       "3                     7.0     8998  \n",
       "4                     5.0     8998  \n",
       "...                   ...      ...  \n",
       "1118588               1.0    16986  \n",
       "1118589               2.0    16986  \n",
       "1118590               2.0    16986  \n",
       "1118591               1.0    16986  \n",
       "1118592               3.0    16986  \n",
       "\n",
       "[1118593 rows x 15 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnn_session_df = session_df.copy()\n",
    "sid_lbe = LabelEncoderExt()\n",
    "gnn_session_df['session_id'] = sid_lbe.fit_transform(gnn_session_df['session_id'])\n",
    "gnn_session_df = gnn_session_df.fillna(0)\n",
    "gnn_session_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UVG Graphs\n",
    "load the related UVG network into the InMemoryDataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "/home/jupyter/github/DMBGN-fork/venv/lib/python3.7/site-packages/torch_sparse/_convert.so: undefined symbol: _ZN3c104impl23ExcludeDispatchKeyGuardC1ENS_14DispatchKeySetE",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12129/637835905.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgeometric_data_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./data/voucher_geometric/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprocessed_file_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'graph_cache'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/DMBGN-fork/venv/lib/python3.7/site-packages/torch_geometric/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_debug_enabled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_debug\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/DMBGN-fork/venv/lib/python3.7/site-packages/torch_geometric/nn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmeta\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMetaLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdata_parallel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataParallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mReshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/DMBGN-fork/venv/lib/python3.7/site-packages/torch_geometric/nn/data_parallel.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/DMBGN-fork/venv/lib/python3.7/site-packages/torch_geometric/data/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0min_memory_dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInMemoryDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataListLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDenseDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/DMBGN-fork/venv/lib/python3.7/site-packages/torch_geometric/data/data.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_sparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcoalesce\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSparseTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m from torch_geometric.utils import (contains_isolated_nodes,\n\u001b[1;32m     10\u001b[0m                                    contains_self_loops, is_undirected)\n",
      "\u001b[0;32m~/github/DMBGN-fork/venv/lib/python3.7/site-packages/torch_sparse/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m ]:\n\u001b[1;32m     12\u001b[0m     torch.ops.load_library(importlib.machinery.PathFinder().find_spec(\n\u001b[0;32m---> 13\u001b[0;31m         library, [osp.dirname(__file__)]).origin)\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/DMBGN-fork/venv/lib/python3.7/site-packages/torch/_ops.py\u001b[0m in \u001b[0;36mload_library\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;31m# static (global) initialization code in order to register custom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0;31m# operators with the JIT.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloaded_libraries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/ctypes/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: /home/jupyter/github/DMBGN-fork/venv/lib/python3.7/site-packages/torch_sparse/_convert.so: undefined symbol: _ZN3c104impl23ExcludeDispatchKeyGuardC1ENS_14DispatchKeySetE"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "batch_size= 512\n",
    "\n",
    "geometric_data_path = './data/voucher_geometric/'\n",
    "processed_file_name = 'graph_cache'\n",
    "gnn_dat = VoucherGraphDataset(root=geometric_data_path, processed_file_name=processed_file_name, gnn_session_df=gnn_session_df)\n",
    "\n",
    "data_loader = DataLoader(gnn_dat, batch_size=batch_size)\n",
    "data_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GNN Networks\n",
    "In this section, we first define the User-behavior Voucher Graph (UVG) network with VoucherGraphNet, training the network with loaded dataset data_loader with VoucherGraphDataset and output the generated UVG embedding $e_{UVG}$ with UVG score $s_{UVG}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Pretrained Item Embeddings\n",
    "load the pretrinaed embedding results for atc/ord item into the embedding tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_size = int(len(item_df) * 1.2)\n",
    "emb_size = 16\n",
    "atc_emb_ts = torch.zeros(item_size, emb_size, dtype = torch.double)\n",
    "ord_emb_ts = torch.zeros(item_size, emb_size, dtype = torch.double)\n",
    "\n",
    "for i in tqdm(range(len(item_df))):\n",
    "    item_id = int(item_df['item_id'][i])\n",
    "    idx = hash_func(item_id, item_size)\n",
    "    \n",
    "    if pd.isna(item_df['atc_emb'][i]) is False and len(item_df['atc_emb'][i].split(' ')) > 3:\n",
    "        atc_emb = [float(val) for val in item_df['atc_emb'][i].split(' ')]\n",
    "        atc_emb_ts[idx] = torch.FloatTensor(atc_emb)\n",
    "    \n",
    "    if pd.isna(item_df['ord_emb'][i]) is False and len(item_df['ord_emb'][i].split(' ')) > 3:\n",
    "        ord_emb = [float(val) for val in item_df['ord_emb'][i].split(' ')]\n",
    "        ord_emb_ts[idx] = torch.FloatTensor(ord_emb) \n",
    "        \n",
    "atc_emb_ts = torch.nn.Embedding.from_pretrained(atc_emb_ts)\n",
    "atc_emb_ts.weight.requires_grad = False\n",
    "ord_emb_ts = torch.nn.Embedding.from_pretrained(ord_emb_ts) \n",
    "ord_emb_ts.weight.requires_grad = False\n",
    "\n",
    "atc_emb_ts, ord_emb_ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train GNN\n",
    "train the UVG Graph with Higher-order GNN, the AUC output here repesents the AUC performance using only GNN network, which can be considered as another ablation study. The trained GNN is saved in the ./data/gnet.pretrained_{epochs}.bin file to be loaded for fine-tune later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_features = ['item_id', 'item_category_id', 'item_brand_id', 'item_price_level']\n",
    "promotion_features = ['promotion_id', 'session_id', 'voucher_min_spend', 'voucher_discount_amount']\n",
    "all_features = item_features + promotion_features + ['action_type', 'label']\n",
    "\n",
    "after_prefix = 'a_'\n",
    "before_prefix = 'b_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type(torch.FloatTensor)\n",
    "\n",
    "emb_info = {\n",
    "    'item_category_id': (6000, 1),\n",
    "    'item_price_level': (300, 1),\n",
    "    'promotion_id': (600, int(atc_emb_ts.weight.shape[1])),\n",
    "    'voucher_min_spend': (500, 1),\n",
    "    'voucher_discount_amount': (500, 1),\n",
    "}\n",
    "\n",
    "emb_dict = {\n",
    "    'atc': atc_emb_ts,\n",
    "    'ord': ord_emb_ts,\n",
    "}\n",
    "\n",
    "gnet = VoucherGraphNet(item_features, promotion_features, emb_info, emb_dict, \n",
    "                       gprefix = [before_prefix, after_prefix], gactions = ['atc', 'ord'],\n",
    "                       device=device)\n",
    "gnet = gnet.float().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(gnet.parameters(), lr=0.001)\n",
    "crit = torch.nn.BCELoss()\n",
    "\n",
    "epochs = 3\n",
    "gnn_file = './data/gnet.pretrained_{epochs}.bin'.format(epochs=epochs)\n",
    "\n",
    "train_ready = True if os.path.exists(gnn_file) else False\n",
    "\n",
    "if train_ready is False:\n",
    "    gstep = 0\n",
    "    gnet.train()\n",
    "    loader_cnt = 0\n",
    "    for epoch in range(epochs):\n",
    "        print(\"# Epoch - {epoch}\".format(epoch=epoch))\n",
    "        try:\n",
    "            for dat in tqdm(data_loader):\n",
    "                optimizer.zero_grad()\n",
    "                graph_dicts = dat.graph_dict\n",
    "                out = None\n",
    "                valid_list = []\n",
    "                gstep += 1\n",
    "                for graph_dict in graph_dicts:\n",
    "                    res, promotion_id, emb_promotion, session_id, emb_session_id = gnet(graph_dict)\n",
    "                    if res is None or torch.isnan(res):\n",
    "                        valid_list.append(False)\n",
    "                        continue\n",
    "                    valid_list.append(True)\n",
    "                    out = res if out is None else torch.cat([out, res], dim=0)\n",
    "\n",
    "                pred = out.cpu()\n",
    "                lbe = dat.label.cpu()[valid_list]\n",
    "                loss = crit(pred, lbe)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                if gstep % 25 == 0:\n",
    "                    auc = roc_auc_score(lbe.detach().numpy().ravel(), pred.detach().numpy().ravel())\n",
    "                    print('GNN[{gstep}] - auc {auc}; loss {loss}'.format(auc=auc ,gstep=gstep ,loss=loss))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    torch.save(gnet.state_dict(), gnn_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pretrained GNN network parameter\n",
    "gnet = VoucherGraphNet(item_features, promotion_features, emb_info, emb_dict, \n",
    "                       gprefix = [before_prefix, after_prefix], gactions = ['atc', 'ord'], \n",
    "                       device=device)\n",
    "gnet.load_state_dict(torch.load(gnn_file))\n",
    "gnet = gnet.float().to(device)\n",
    "\n",
    "\n",
    "# Use Before UVG Only\n",
    "gnet_before = VoucherGraphNet(item_features, promotion_features, emb_info, emb_dict, device=device)\n",
    "gnet_before.load_state_dict(torch.load(gnn_file))\n",
    "gnet_before = gnet_before.float().to(device)\n",
    "gnet_before.gprefix = [before_prefix, 'unknown'] \n",
    "\n",
    "gnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Pretrained UVG Embeddings\n",
    "generate pretrained embeddings from UVG network for each UVG. Note here we have gnet and gnet_before which represents UVG including both 'bef' and 'aft' user behaviors and including 'bef' user behaviors only. From the AUC performance output we see that gnet has better performance than gnet_before, which indicates the importance of taking 'aft' user behaviors into consideration. This can be considered as another ablation study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle_protocol = 4\n",
    "\n",
    "gnet.eval()\n",
    "gnet_before.eval()\n",
    "gstep = 0\n",
    "\n",
    "\n",
    "raw_sid_uvg_graphs_dic = {}\n",
    "\n",
    "promotion_emb_dic = {}\n",
    "session_emb_raw_dic = {}\n",
    "session_emb_raw_dic_before = {}\n",
    "\n",
    "gnn_pretrained_emb_file = 'data/gnet.pretrained.{epochs}.emb.pkl'.format(epochs=epochs)\n",
    "\n",
    "gnn_emb_ready = True if os.path.exists(gnn_pretrained_emb_file) else False\n",
    "\n",
    "def hash_func(ts, item_size):\n",
    "    return ts % item_size\n",
    "\n",
    "if gnn_emb_ready is False:\n",
    "    session_emb_dic = {}\n",
    "    sid_uvg_graphs_dic = {}\n",
    "    session_emb_dic_before = {}\n",
    "    for dat in DataLoader(gnn_dat, batch_size=batch_size * 30):\n",
    "        graph_dicts = dat.graph_dict\n",
    "        out = None\n",
    "        out2 = None\n",
    "        valid_list = []\n",
    "        valid_list2 = []\n",
    "        gstep += 1\n",
    "        for graph_dict in graph_dicts :\n",
    "            res, promotion_id, emb_promotion, session_id, emb_session_id = gnet(graph_dict)\n",
    "            res_before, _, _, _, emb_session_id_before = gnet_before(graph_dict)\n",
    "            if res is None or torch.isnan(res):\n",
    "                valid_list.append(False)\n",
    "                continue\n",
    "\n",
    "            valid_list.append(True)\n",
    "            out = res if out is None else torch.cat([out, res], dim=0)\n",
    "\n",
    "            promotion_emb_dic[promotion_id.unsqueeze(0).cpu().detach().numpy()[0]] = emb_promotion.cpu().detach().numpy()\n",
    "            session_emb_dic[session_id.unsqueeze(0).cpu().detach().numpy()[0]] = emb_session_id.cpu().detach().numpy()\n",
    "            sid_uvg_graphs_dic[session_id.unsqueeze(0).cpu().detach().numpy()[0]] = graph_dict\n",
    "            \n",
    "            if res_before is not None or torch.isnan(res) is False:\n",
    "                session_emb_dic_before[session_id.unsqueeze(0).cpu().detach().numpy()[0]] = emb_session_id_before.cpu().detach().numpy()\n",
    "                out2 = res_before if out2 is None else torch.cat([out2, res_before], dim=0)\n",
    "                valid_list2.append(True)\n",
    "            else :\n",
    "                valid_list2.append(False)\n",
    "\n",
    "        try:\n",
    "            lbe = dat.label.cpu()[valid_list]\n",
    "            lbe2 = dat.label.cpu()[valid_list2]\n",
    "            pred = out.cpu()\n",
    "            pred2 = out2.cpu()\n",
    "            loss = crit(pred, lbe)\n",
    "            loss2 = crit(pred2, lbe2)\n",
    "            auc = roc_auc_score(lbe.detach().numpy().ravel(), pred.detach().numpy().ravel())\n",
    "            auc2 = roc_auc_score(lbe2.detach().numpy().ravel(), pred2.detach().numpy().ravel())\n",
    "            print(\"gstep = {gstep}; auc = {auc}; loss = {loss}; auc_before = {auc2} {loss2}\".format(gstep=gstep,\n",
    "                                                                                                    auc=auc, \n",
    "                                                                                                    loss2=loss2,\n",
    "                                                                                                    auc2 =auc2,\n",
    "                                                                                                    loss=loss))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    for key, emb in tqdm(session_emb_dic.items()):\n",
    "        session_emb_raw_dic[sid_lbe.label_encoder.classes_[key]] = emb\n",
    "\n",
    "    # session_emb_raw_dic_before use for target session id with no after behaviors know beforehand\n",
    "    for key, emb in tqdm(session_emb_dic_before.items()):\n",
    "        session_emb_raw_dic_before[sid_lbe.label_encoder.classes_[key]] = emb\n",
    "\n",
    "    for key, uvg in tqdm(sid_uvg_graphs_dic.items()):\n",
    "         raw_sid_uvg_graphs_dic[sid_lbe.label_encoder.classes_[key]] = uvg\n",
    "        \n",
    "    with open(gnn_pretrained_emb_file, 'wb') as f:\n",
    "        pickle.dump(promotion_emb_dic, f, pickle_protocol)\n",
    "        pickle.dump(session_emb_raw_dic, f, pickle_protocol)\n",
    "        pickle.dump(session_emb_raw_dic_before, f, pickle_protocol)\n",
    "        pickle.dump(raw_sid_uvg_graphs_dic, f, pickle_protocol)\n",
    "\n",
    "else :\n",
    "    print('loading existing trained embeddings...')\n",
    "    with open(gnn_pretrained_emb_file, \"rb\") as f:\n",
    "        promotion_emb_dic = pickle.load(f)\n",
    "        session_emb_raw_dic = pickle.load(f)\n",
    "        session_emb_raw_dic_before = pickle.load(f)\n",
    "        raw_sid_uvg_graphs_dic = pickle.load(f)\n",
    "        \n",
    "len(promotion_emb_dic), len(session_emb_raw_dic), len(session_emb_raw_dic_before), len(raw_sid_uvg_graphs_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "labels = []\n",
    "scores = []\n",
    "\n",
    "labels_before = []\n",
    "scores_before = [] \n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "for iii in tqdm(range(len(session_df))):\n",
    "    sid = session_df['session_id'].values[iii]\n",
    "    promotion_id = int(session_df['promotion_id'].values[iii])\n",
    "    label = session_df['label'].values[iii]\n",
    "    \n",
    "    if sid not in session_emb_raw_dic:\n",
    "        continue\n",
    "    \n",
    "    session_emb = session_emb_raw_dic[sid]\n",
    "    promotion_emb = promotion_emb_dic[promotion_id]\n",
    "            \n",
    "    labels.append(label)\n",
    "    score = sigmoid(np.matmul(session_emb, promotion_emb))\n",
    "    scores.append(score)\n",
    "    \n",
    "    if sid in session_emb_raw_dic_before:\n",
    "        session_emb_before = session_emb_raw_dic_before[sid]\n",
    "        score_before = sigmoid(np.matmul(session_emb_before, promotion_emb))\n",
    "        scores_before.append(score_before)\n",
    "        labels_before.append(label)\n",
    "            \n",
    "auc = roc_auc_score(labels, scores)\n",
    "auc_before = roc_auc_score(labels_before, scores_before)\n",
    "len(scores), auc, auc_before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DMBGN Log Processing\n",
    "log processing for DMBGN training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = user_voucher_log.copy()\n",
    "df = df.take(np.random.permutation(len(df)))\n",
    "df['hist_sid'] = df['hist_session_id']\n",
    "\n",
    "sparse_feature = ['promotion_id','session_id','user_gender','user_age_level','user_purchase_level'] #['promotion_id','voucher_min_spend','voucher_discount_amount']\n",
    "\n",
    "hist_list_features = ['hist_promotion_id','hist_sid','keys_length']\n",
    "\n",
    "ignore_features=['hist_session_id', 'dtype','venture','ds','user_id','label','voucher_collect_time','voucher_redeem_time','campaign_name','rk']\n",
    "\n",
    "dense_feature = []\n",
    "train_features = []\n",
    "\n",
    "for feat in df.columns:\n",
    "    if feat in ignore_features:\n",
    "        continue\n",
    "    if feat not in hist_list_features:\n",
    "        train_features.append(feat)\n",
    "    if feat not in hist_list_features and feat not in sparse_feature:\n",
    "        dense_feature.append(feat)\n",
    "\n",
    "target = 'label'\n",
    "df[['session_id','promotion_id','user_gender','user_age_level','user_purchase_level']]=df[['session_id','promotion_id','user_gender','user_age_level','user_purchase_level']].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = {}\n",
    "for feat in sparse_feature:\n",
    "    df[feat] = df[feat].fillna(0)\n",
    "    print(\"lbe {}\".format(feat))\n",
    "    lbe = LabelEncoderExt()\n",
    "    lbe.fit(df[feat])\n",
    "    df[feat] = lbe.transform(df[feat])\n",
    "    label_encoder[feat] = lbe\n",
    "    logging.warn('LabelEncoder encoding ' + feat + \" len \" + str(len(lbe)))\n",
    "    \n",
    "label_encoder['sid'] = label_encoder['session_id']\n",
    "df['sid'] = df['promotion_id']\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_kv = {}\n",
    "std_kv = {}\n",
    "for feat in dense_feature:\n",
    "    print(feat)\n",
    "    mean_kv[feat] = df[feat].mean()\n",
    "    std_kv[feat] = df[feat].std()\n",
    "    df[feat] = (df[feat] - mean_kv[feat]) / std_kv[feat]\n",
    "\n",
    "deep_ctr_df = df \n",
    "dctr_train = deep_ctr_df[deep_ctr_df.dtype == 'train']\n",
    "dctr_v1 = deep_ctr_df[deep_ctr_df.dtype == 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xy_fd(dataset):\n",
    "    print (\"start generating x y data\")\n",
    "    \n",
    "    dnn_feature_columns = []\n",
    "    dnn_feature_columns += [SparseFeat(feat, len(label_encoder[feat]), embedding_dim = embedding_dim1) for feat in ['promotion_id', 'user_gender','user_age_level','user_purchase_level']]\n",
    "    dnn_feature_columns += [SparseFeat(feat, len(label_encoder['promotion_id']), embedding_dim = embedding_dim2) for feat in ['sid']]\n",
    "    \n",
    "    dnn_feature_columns += [VarLenSparseFeat(SparseFeat('hist_promotion_id', len(label_encoder[\"promotion_id\"]), embedding_dim=embedding_dim1), sequence_size)]\n",
    "    dnn_feature_columns += [VarLenSparseFeat(SparseFeat('hist_sid', len(label_encoder[\"sid\"]), embedding_dim=embedding_dim2), sequence_size)]\n",
    "    \n",
    "    dnn_feature_columns += [DenseFeat(feat, 1, )  for feat in dense_feature]\n",
    "    dnn_feature_columns += [DenseFeat(feat, 1, )  for feat in ['keys_length']]\n",
    "\n",
    "    feature_names = get_feature_names(dnn_feature_columns)\n",
    "    print (\"feature_names:\", feature_names)\n",
    "    \n",
    "    behavior_feature_list = ['promotion_id', 'sid']\n",
    "\n",
    "    y, x = gen_dmbgn_input_data(feature_names, dataset, target, label_encoder, 6, sparse_feature, hist_list_features)\n",
    " \n",
    "    return x, y, dnn_feature_columns, behavior_feature_list\n",
    "\n",
    "sequence_size = 6\n",
    "embedding_dim1 = 16 # pid\n",
    "embedding_dim2 = 16 # sid\n",
    "print(embedding_dim2)\n",
    "\n",
    "x, y, dnn_feature_columns, behavior_feature_list = get_xy_fd(dctr_train)\n",
    "test_model_input1, test_label1, _, _ = get_xy_fd(dctr_v1)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_emb_bef_aft_16 = init_emb_ts(session_emb_raw_dic, requires_grad = False, lbe = label_encoder['session_id'])\n",
    "promotion_emb_bef_aft_16 = init_emb_ts(promotion_emb_dic, requires_grad = True, lbe = label_encoder['promotion_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'DMBGN_Pretrained'\n",
    "\n",
    "model = DMBGN(dnn_feature_columns, \n",
    "            behavior_feature_list,\n",
    "            target_emb_dim_aft=0, \n",
    "            sequence_size=6,\n",
    "            device=device, \n",
    "            att_activation='prelu', \n",
    "            att_weight_normalization=False, \n",
    "            dnn_activation='relu', \n",
    "            l2_reg_dnn=0.1, \n",
    "            l2_reg_embedding = 0.0001, \n",
    "            dnn_hidden_units=(128,64), \n",
    "            att_hidden_size=(64,), \n",
    "            init_std=1, \n",
    "            dnn_dropout=0.5, \n",
    "            dnn_use_bn=True)\n",
    "\n",
    "\n",
    "gnn_fine_tune = False\n",
    "model.embedding_dict['hist_promotion_id'] = promotion_emb_bef_aft_16 \n",
    "model.embedding_dict['hist_promotion_id'].requires_grad = gnn_fine_tune\n",
    "model.embedding_dict['hist_promotion_id'].weight.requires_grad = gnn_fine_tune\n",
    "\n",
    "model.embedding_dict['hist_sid'] = session_emb_bef_aft_16\n",
    "model.embedding_dict['hist_sid'].requires_grad = gnn_fine_tune\n",
    "model.embedding_dict['hist_sid'].weight.requires_grad = gnn_fine_tune\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.05, amsgrad=True)\n",
    "model.compile(optimizer, 'binary_crossentropy', metrics=['auc', 'logloss'])\n",
    "\n",
    "\n",
    "loss_func = model.loss_func\n",
    "optim = model.optim\n",
    "metrics = model.metrics\n",
    "feature_index = model.feature_index\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_ids = [i for i in range(torch.cuda.device_count())]\n",
    "device_count = len(device_ids)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Use\", device_count, \"GPUs!\")\n",
    "    model = torch.nn.DataParallel(model, device_ids)\n",
    "    \n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 20\n",
    "batch_size = 300\n",
    "res, pred1 = fit(model, feature_index, optim, metrics, loss_func, x, y, batch_size=batch_size, epochs=epoch, validation_data=(test_model_input1,test_label1),verbose=1, device=device, device_count=device_count)\n",
    "\n",
    "results[model_name] = model, res, pred1, test_label1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DMBGN\n",
    "The proposed model in this work, which loads the pre-trained GNN network including the item and voucher node embeddings. The GNN network parameters are further fine-tuned according to the final training loss. \\\n",
    "Note that it might takes a longer time to train DMBGN as it involves the training of GNN network. In our work, we used multiple GPUs to accerlate the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xy_fd(dataset):\n",
    "    print (\"start generating x y data\")\n",
    "    \n",
    "    dnn_feature_columns = []\n",
    "    dnn_feature_columns += [SparseFeat(feat, len(label_encoder[feat]), embedding_dim = embedding_dim1) for feat in ['promotion_id', 'user_gender','user_age_level','user_purchase_level']]\n",
    "    dnn_feature_columns += [SparseFeat(feat, len(label_encoder['promotion_id']), embedding_dim = embedding_dim2) for feat in ['sid']]\n",
    "    dnn_feature_columns += [SparseFeat(feat, len(label_encoder[feat]), embedding_dim = 1) for feat in ['session_id']]\n",
    "    \n",
    "    dnn_feature_columns += [VarLenSparseFeat(SparseFeat('hist_promotion_id', len(label_encoder[\"promotion_id\"]), embedding_dim=embedding_dim1), sequence_size)]\n",
    "    dnn_feature_columns += [VarLenSparseFeat(SparseFeat('hist_sid', len(label_encoder[\"sid\"]), embedding_dim=embedding_dim2), sequence_size)]\n",
    "    \n",
    "    dnn_feature_columns += [DenseFeat(feat, 1, )  for feat in dense_feature]\n",
    "    dnn_feature_columns += [DenseFeat(feat, 1, )  for feat in ['keys_length']]\n",
    "\n",
    "    feature_names = get_feature_names(dnn_feature_columns)\n",
    "    print (\"feature_names:\", feature_names)\n",
    "    \n",
    "    behavior_feature_list = ['promotion_id', 'sid']\n",
    "\n",
    "    y, x = gen_dmbgn_input_data(feature_names, dataset, target, label_encoder, 6, sparse_feature, hist_list_features)\n",
    " \n",
    "    return x, y, dnn_feature_columns, behavior_feature_list\n",
    "\n",
    "sequence_size = 6\n",
    "embedding_dim1 = 16 # pid\n",
    "embedding_dim2 = 16 # sid\n",
    "print(embedding_dim2)\n",
    "\n",
    "x, y, dnn_feature_columns, behavior_feature_list = get_xy_fd(dctr_train)\n",
    "test_model_input1, test_label1, _, _ = get_xy_fd(dctr_v1)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_emb_bef_aft_16 = init_emb_ts(session_emb_raw_dic, requires_grad = False, lbe = label_encoder['session_id'])\n",
    "promotion_emb_bef_aft_16 = init_emb_ts(promotion_emb_dic, requires_grad = True, lbe = label_encoder['promotion_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_sid_uvg_graphs_dic = {}\n",
    "hash_sids = label_encoder['session_id'].transform([str(val) for val in raw_sid_uvg_graphs_dic.keys()])\n",
    "for i, (key, uvgs) in tqdm(enumerate(raw_sid_uvg_graphs_dic.items())):\n",
    "    hash_sid_uvg_graphs_dic[hash_sids[i]] = uvgs\n",
    "\n",
    "len(hash_sid_uvg_graphs_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'DMBGN'\n",
    "\n",
    "model = DMBGN(dnn_feature_columns, \n",
    "              behavior_feature_list,\n",
    "              target_emb_dim_aft=0, \n",
    "              sequence_size=6,\n",
    "              device=device, \n",
    "              att_activation='prelu', \n",
    "              att_weight_normalization=False, \n",
    "              dnn_activation='relu', \n",
    "              l2_reg_dnn=0.1, \n",
    "              l2_reg_embedding = 0.0001, \n",
    "              dnn_hidden_units=(128,64), \n",
    "              att_hidden_size=(64,), \n",
    "              init_std=1, \n",
    "              dnn_dropout=0.5, \n",
    "              dnn_use_bn=True,\n",
    "              gnet_tune=True,\n",
    "              hist_gnn_dropout=0.6, \n",
    "              gnet=gnet, \n",
    "              gnet_before=gnet_before,\n",
    "              hash_sid_uvg_graphs_dic=hash_sid_uvg_graphs_dic)\n",
    "\n",
    "\n",
    "zeros = torch.zeros(len(label_encoder['session_id']), 1, dtype = torch.float)\n",
    "model.embedding_dict['session_id'] = torch.nn.Embedding.from_pretrained(zeros)\n",
    "model.embedding_dict['session_id'].requires_grad = False\n",
    "model.embedding_dict['session_id'].weight.requires_grad = False\n",
    "\n",
    "model.embedding_dict['hist_promotion_id'] = promotion_emb_bef_aft_16\n",
    "model.embedding_dict['hist_promotion_id'].requires_grad = False\n",
    "model.embedding_dict['hist_promotion_id'].weight.requires_grad = False\n",
    "\n",
    "model.embedding_dict['hist_sid'] = session_emb_bef_aft_16\n",
    "model.embedding_dict['hist_sid'].requires_grad = False\n",
    "model.embedding_dict['hist_sid'].weight.requires_grad = False\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.05, amsgrad=True)\n",
    "model.compile(optimizer, 'binary_crossentropy', metrics=['auc', 'logloss'])\n",
    "\n",
    "\n",
    "loss_func = model.loss_func\n",
    "optim = model.optim\n",
    "metrics = model.metrics\n",
    "feature_index = model.feature_index\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_ids = [i for i in range(torch.cuda.device_count())]\n",
    "device_count = len(device_ids)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model = torch.nn.DataParallel(model, device_ids)\n",
    "    \n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 20\n",
    "batch_size = 300\n",
    "res, pred1 = fit(model, feature_index, optim, metrics, loss_func, x, y, batch_size=batch_size, epochs=epoch, validation_data=(test_model_input1,test_label1),verbose=1, device=device, device_count=device_count)\n",
    "\n",
    "results[model_name] = model, res, pred1, test_label1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "i = 0\n",
    "lw = 1\n",
    "\n",
    "colors = [\"cornflowerblue\", \"darkorange\", \"red\", \"blue\", \"green\", \"violet\", \"black\", \"purple\", \"olive\", \"cyan\"]\n",
    "\n",
    "\n",
    "for model_name, (model, res, pred1, test_label1) in results.items():\n",
    "    fpr[i], tpr[i], _ = roc_curve(test_label1.astype(int),  pred1)\n",
    "    roc_auc = auc(fpr[i], tpr[i])\n",
    "    plt.plot(fpr[i], tpr[i], color=colors[i], lw=lw, label = model_name + ' ROC curve (area = ' + str(round(roc_auc, 4)) + ')')\n",
    "\n",
    "    i += 1\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    \n",
    "plt.title('User-Voucher Redemption Dataset ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relaImpr(a, b):\n",
    "    x = ((a-0.5)/(b-0.5) - 1.0)*100.0\n",
    "    return str(\"%.2f\" % x) + '%'\n",
    "\n",
    "dnn_auc = results['DNN'][1]['eval_auc']\n",
    "din_auc = results['DIN'][1]['eval_auc']\n",
    "\n",
    "table = PrettyTable(['Model','AUC','RelaImpr(DNN)','RelaImpr(DIN)', 'Logloss'], digits = 4, rounds=True)\n",
    "for model_name, (model, res, pred1, test_label1) in results.items():\n",
    "    table.add_row([model_name, \"%.4f\" % res['eval_auc'], relaImpr(res['eval_auc'], dnn_auc), relaImpr(res['eval_auc'], din_auc), \"%.4f\" % res['eval_logloss']])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that xgBoost has a higher AUC compared to DNN and WDL, mainly due to the small sample size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [1] H Brendan McMahan, Gary Holt, David Sculley, Michael Young, Dietmar Ebner,Julian Grady, Lan Nie, Todd Phillips, Eugene Davydov, Daniel Golovin, et al.2013.  Ad click prediction: a view from the trenches. InProceedings of the 19thACM SIGKDD international conference on Knowledge discovery and data mining.1222–1230.\n",
    "- [2] Guolin Ke, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma,Qiwei Ye, and Tie-Yan Liu. 2017. Lightgbm: A highly efficient gradient boostingdecision tree.Advances in neural information processing systems30 (2017), 3146–3154.\n",
    "- [3] Heng-Tze Cheng, Levent Koc, Jeremiah Harmsen, Tal Shaked, Tushar Chandra,Hrishi Aradhye, Glen Anderson, Greg Corrado, Wei Chai, Mustafa Ispir, RohanAnil, Zakaria Haque, Lichan Hong, Vihan Jain, Xiaobing Liu, and Hemal Shah.2016. Wide & Deep Learning for Recommender Systems.CoRRabs/1606.07792(2016). arXiv:1606.07792  http://arxiv.org/abs/1606.07792 .\n",
    "- [4] Guorui Zhou, Xiaoqiang Zhu, Chenru Song, Ying Fan, Han Zhu, Xiao Ma, YanghuiYan, Junqi Jin, Han Li, and Kun Gai. 2018. Deep interest network for click-throughrate prediction. InProceedings of the 24th ACM SIGKDD International Conferenceon Knowledge Discovery & Data Mining. 1059–1068."
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "dmbgn",
   "name": "pytorch-gpu.1-11.m94",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-11:m94"
  },
  "kernelspec": {
   "display_name": "dmbgn",
   "language": "python",
   "name": "dmbgn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "304.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
