{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Public code for submitted paper \"DMBGN: Deep Multi-Behavior Graph Networks for Voucher Redemption Rate Prediction\" for SIGKDD 2021. This code covers the experimental results in Chapter 5 in the submitted paper. Note that the following experiments are conducted on a randomly desensitized sampled dataset from original dataset (Region C) mentioned in the paper, all related id features are hashed for public use.\n",
    "\n",
    "This notebook is organized into 5 parts:\n",
    "1. Data Processing: generate the training data from the original log table (for log description, please refer to README.md file under ./data directory\n",
    "2. Baseline Models: corresponding to 5 baseline models compared in the submitted paper, including LR, GBDT, DNN, WDL and DIN model.\n",
    "3. Proposed Method: DMBGN: our proposed model, which includes experiment 2 variants of DMBGN (AvgPooling and Pretrained) with our final model DMBGN\n",
    "4. Summary: a summary of experiment results\n",
    "5. Reference\n",
    "\n",
    "The content of this notebook is as:\n",
    "- 1 Data Processing\n",
    "  - 1.1 Logs Processing\n",
    "  - 1.2 Label Encoding and Normalization\n",
    "- 2 Baseline Models\n",
    "  - 2.1 LR\n",
    "  - 2.2 GBDT\n",
    "  - 2.3 DNN\n",
    "  - 2.4 WDL\n",
    "  - 2.5 DIN\n",
    "- 3 Proposed Method: DMBGN\n",
    "  - 3.1 DMBGN-AvgPooling\n",
    "  - 3.2 DMBGN-Pretrained\n",
    "    - 3.2.1 UVG Graphs\n",
    "    - 3.2.2 GNN Networks\n",
    "      - 3.2.2.1 Get Pretrained Item Embedding\n",
    "      - 3.2.2.2 Train GNN\n",
    "      - 3.2.2.3 Generate Pretrained UVG Embedding\n",
    "      - 3.2.2.4 GMBDN Log Processing\n",
    "  - 3.3 DMBGN\n",
    "- 4 Summary\n",
    "- 5 Reference\n",
    "\n",
    "\n",
    "Note that you can run all codes directly for all the results. For DMBGN it might takes a longer time and we used 8 GPUs for accerlation purpose.\n",
    "\n",
    "\n",
    "Author: \\\n",
    "    Lin Li (boolean.ll@alibaba-inc.com) \\\n",
    "    Fengtong Xiao (fengtong.xiao@alibaba-inc.com) \\\n",
    "    Weinan Xu (stella.xu@lazada.com)\n",
    "\n",
    "References: \\\n",
    "    DMBGN: Deep Multi-Behavior Graph Networks for Voucher Redemption Rate Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:70% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:70% !important; }</style>\"))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandasql as ps\n",
    "\n",
    "import warnings\n",
    "import logging\n",
    "import sys\n",
    "import pickle\n",
    "import csv\n",
    "import os\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "import torch\n",
    "from deepctr_torch.inputs import SparseFeat, DenseFeat,VarLenSparseFeat, get_feature_names\n",
    "from deepctr_torch.models import *\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.setrecursionlimit(9000000) \n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s]: %(message)s')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from models.util import *\n",
    "from models import LabelEncoderExt\n",
    "from models.din import DIN\n",
    "from models.DMBGN import DMBGN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "# def get_device(idx=0):\n",
    "#     if torch.cuda.is_available():\n",
    "#         device = torch.device('cuda')\n",
    "#     else:\n",
    "#         device = torch.device('cpu')\n",
    "#     return device\n",
    "# device_count = torch.cuda.device_count()\n",
    "# device = get_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-20 13:00:20,431 [WARNING]: \n",
      "DeepCTR-PyTorch version 0.2.9 detected. Your version is 0.2.3.\n",
      "Use `pip install -U deepctr-torch` to upgrade.Changelog: https://github.com/shenweichen/DeepCTR-Torch/releases/tag/v0.2.9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((62068, 19), (1118593, 14), (286735, 6))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the pickle file, note you might need to unzip the kdd_data.pkl.zip to recover the pkl file\n",
    "# To unzip, use the following linux commands:\n",
    "# $ cd ./data\n",
    "# $ unzip kdd_data.pkl.zip\n",
    "\n",
    "file_path = './data/kdd_data.pkl'\n",
    "with open(file_path, \"rb\") as f:\n",
    "    log_df = pickle.load(f)\n",
    "    session_df = pickle.load(f)\n",
    "    item_df = pickle.load(f)\n",
    "log_df.shape, session_df.shape, item_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Logs Processing\n",
    "construct the historical UVG sequence following the chronological order \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>label</th>\n",
       "      <th>user_id</th>\n",
       "      <th>promotion_id</th>\n",
       "      <th>voucher_min_spend</th>\n",
       "      <th>voucher_discount</th>\n",
       "      <th>voucher_collect_time</th>\n",
       "      <th>voucher_redeem_time</th>\n",
       "      <th>campaign_name</th>\n",
       "      <th>user_age_level</th>\n",
       "      <th>user_gender</th>\n",
       "      <th>user_purchase_level</th>\n",
       "      <th>user_trd__orders_cnt_hist</th>\n",
       "      <th>user_trd__actual_gmv_usd_hist</th>\n",
       "      <th>user_trd__orders_cnt_platform_discount_hist</th>\n",
       "      <th>user_trd__max_gmv_usd_hist</th>\n",
       "      <th>user_trd__avg_gmv_usd_hist</th>\n",
       "      <th>user_trd__min_gmv_usd_hist</th>\n",
       "      <th>dtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12130_38</td>\n",
       "      <td>1</td>\n",
       "      <td>12130</td>\n",
       "      <td>38</td>\n",
       "      <td>888</td>\n",
       "      <td>80</td>\n",
       "      <td>14363</td>\n",
       "      <td>28292</td>\n",
       "      <td>C3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>706.648652</td>\n",
       "      <td>4.0</td>\n",
       "      <td>79.950388</td>\n",
       "      <td>11.584404</td>\n",
       "      <td>0.827519</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12130_85</td>\n",
       "      <td>0</td>\n",
       "      <td>12130</td>\n",
       "      <td>85</td>\n",
       "      <td>4999</td>\n",
       "      <td>500</td>\n",
       "      <td>49983</td>\n",
       "      <td>49983</td>\n",
       "      <td>C2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>822.218764</td>\n",
       "      <td>9.0</td>\n",
       "      <td>60.165341</td>\n",
       "      <td>8.747008</td>\n",
       "      <td>0.601405</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12156_64</td>\n",
       "      <td>0</td>\n",
       "      <td>12156</td>\n",
       "      <td>64</td>\n",
       "      <td>7799</td>\n",
       "      <td>700</td>\n",
       "      <td>21441</td>\n",
       "      <td>21441</td>\n",
       "      <td>C3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>349.797257</td>\n",
       "      <td>4.0</td>\n",
       "      <td>118.703723</td>\n",
       "      <td>8.531640</td>\n",
       "      <td>0.928380</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12156_91</td>\n",
       "      <td>1</td>\n",
       "      <td>12156</td>\n",
       "      <td>91</td>\n",
       "      <td>799</td>\n",
       "      <td>80</td>\n",
       "      <td>46418</td>\n",
       "      <td>52254</td>\n",
       "      <td>C2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>793.370613</td>\n",
       "      <td>7.0</td>\n",
       "      <td>215.294128</td>\n",
       "      <td>7.778143</td>\n",
       "      <td>0.517295</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12156_310</td>\n",
       "      <td>1</td>\n",
       "      <td>12156</td>\n",
       "      <td>310</td>\n",
       "      <td>349</td>\n",
       "      <td>30</td>\n",
       "      <td>121387</td>\n",
       "      <td>131549</td>\n",
       "      <td>C1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>842.410759</td>\n",
       "      <td>8.0</td>\n",
       "      <td>215.294128</td>\n",
       "      <td>7.589286</td>\n",
       "      <td>0.517295</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62063</th>\n",
       "      <td>11873_319</td>\n",
       "      <td>0</td>\n",
       "      <td>11873</td>\n",
       "      <td>319</td>\n",
       "      <td>1999</td>\n",
       "      <td>200</td>\n",
       "      <td>120575</td>\n",
       "      <td>120575</td>\n",
       "      <td>C1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>884.002906</td>\n",
       "      <td>16.0</td>\n",
       "      <td>260.133633</td>\n",
       "      <td>21.047688</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62064</th>\n",
       "      <td>11873_305</td>\n",
       "      <td>1</td>\n",
       "      <td>11873</td>\n",
       "      <td>305</td>\n",
       "      <td>4999</td>\n",
       "      <td>500</td>\n",
       "      <td>120576</td>\n",
       "      <td>131797</td>\n",
       "      <td>C1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>884.002906</td>\n",
       "      <td>16.0</td>\n",
       "      <td>260.133633</td>\n",
       "      <td>21.047688</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62065</th>\n",
       "      <td>11879_159</td>\n",
       "      <td>0</td>\n",
       "      <td>11879</td>\n",
       "      <td>159</td>\n",
       "      <td>799</td>\n",
       "      <td>70</td>\n",
       "      <td>72071</td>\n",
       "      <td>72071</td>\n",
       "      <td>C0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>340.424720</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.094769</td>\n",
       "      <td>28.368727</td>\n",
       "      <td>3.595659</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62066</th>\n",
       "      <td>11880_38</td>\n",
       "      <td>0</td>\n",
       "      <td>11880</td>\n",
       "      <td>38</td>\n",
       "      <td>888</td>\n",
       "      <td>80</td>\n",
       "      <td>3867</td>\n",
       "      <td>4451</td>\n",
       "      <td>C3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>5085.468023</td>\n",
       "      <td>24.0</td>\n",
       "      <td>501.537557</td>\n",
       "      <td>14.009554</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62067</th>\n",
       "      <td>11880_454</td>\n",
       "      <td>0</td>\n",
       "      <td>11880</td>\n",
       "      <td>454</td>\n",
       "      <td>799</td>\n",
       "      <td>70</td>\n",
       "      <td>125362</td>\n",
       "      <td>125362</td>\n",
       "      <td>C1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>7470.998268</td>\n",
       "      <td>34.0</td>\n",
       "      <td>501.537557</td>\n",
       "      <td>14.852879</td>\n",
       "      <td>0.094030</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62068 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      session_id  label user_id promotion_id  voucher_min_spend  \\\n",
       "0       12130_38      1   12130           38                888   \n",
       "1       12130_85      0   12130           85               4999   \n",
       "2       12156_64      0   12156           64               7799   \n",
       "3       12156_91      1   12156           91                799   \n",
       "4      12156_310      1   12156          310                349   \n",
       "...          ...    ...     ...          ...                ...   \n",
       "62063  11873_319      0   11873          319               1999   \n",
       "62064  11873_305      1   11873          305               4999   \n",
       "62065  11879_159      0   11879          159                799   \n",
       "62066   11880_38      0   11880           38                888   \n",
       "62067  11880_454      0   11880          454                799   \n",
       "\n",
       "       voucher_discount voucher_collect_time voucher_redeem_time  \\\n",
       "0                    80                14363               28292   \n",
       "1                   500                49983               49983   \n",
       "2                   700                21441               21441   \n",
       "3                    80                46418               52254   \n",
       "4                    30               121387              131549   \n",
       "...                 ...                  ...                 ...   \n",
       "62063               200               120575              120575   \n",
       "62064               500               120576              131797   \n",
       "62065                70                72071               72071   \n",
       "62066                80                 3867                4451   \n",
       "62067                70               125362              125362   \n",
       "\n",
       "      campaign_name  user_age_level user_gender  user_purchase_level  \\\n",
       "0                C3             5.0           1                  8.0   \n",
       "1                C2             5.0           1                  8.0   \n",
       "2                C3             4.0           0                  9.0   \n",
       "3                C2             4.0           0                  9.0   \n",
       "4                C1             4.0           0                  9.0   \n",
       "...             ...             ...         ...                  ...   \n",
       "62063            C1             2.0           1                  9.0   \n",
       "62064            C1             2.0           1                  9.0   \n",
       "62065            C0             4.0           0                  8.0   \n",
       "62066            C3             2.0           1                  9.0   \n",
       "62067            C1             2.0           1                  9.0   \n",
       "\n",
       "       user_trd__orders_cnt_hist  user_trd__actual_gmv_usd_hist  \\\n",
       "0                           52.0                     706.648652   \n",
       "1                           69.0                     822.218764   \n",
       "2                           26.0                     349.797257   \n",
       "3                           61.0                     793.370613   \n",
       "4                           65.0                     842.410759   \n",
       "...                          ...                            ...   \n",
       "62063                       18.0                     884.002906   \n",
       "62064                       18.0                     884.002906   \n",
       "62065                       10.0                     340.424720   \n",
       "62066                      169.0                    5085.468023   \n",
       "62067                      214.0                    7470.998268   \n",
       "\n",
       "       user_trd__orders_cnt_platform_discount_hist  \\\n",
       "0                                              4.0   \n",
       "1                                              9.0   \n",
       "2                                              4.0   \n",
       "3                                              7.0   \n",
       "4                                              8.0   \n",
       "...                                            ...   \n",
       "62063                                         16.0   \n",
       "62064                                         16.0   \n",
       "62065                                          1.0   \n",
       "62066                                         24.0   \n",
       "62067                                         34.0   \n",
       "\n",
       "       user_trd__max_gmv_usd_hist  user_trd__avg_gmv_usd_hist  \\\n",
       "0                       79.950388                   11.584404   \n",
       "1                       60.165341                    8.747008   \n",
       "2                      118.703723                    8.531640   \n",
       "3                      215.294128                    7.778143   \n",
       "4                      215.294128                    7.589286   \n",
       "...                           ...                         ...   \n",
       "62063                  260.133633                   21.047688   \n",
       "62064                  260.133633                   21.047688   \n",
       "62065                   53.094769                   28.368727   \n",
       "62066                  501.537557                   14.009554   \n",
       "62067                  501.537557                   14.852879   \n",
       "\n",
       "       user_trd__min_gmv_usd_hist  dtype  \n",
       "0                        0.827519  train  \n",
       "1                        0.601405   test  \n",
       "2                        0.928380   test  \n",
       "3                        0.517295   test  \n",
       "4                        0.517295  train  \n",
       "...                           ...    ...  \n",
       "62063                    0.000000  train  \n",
       "62064                    0.000000  train  \n",
       "62065                    3.595659   test  \n",
       "62066                    0.000000  train  \n",
       "62067                    0.094030   test  \n",
       "\n",
       "[62068 rows x 19 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = \"select *, ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY CAST(voucher_collect_time AS BIGINT) ASC) as rk from {logdf}\".format(logdf=\"log_df\")\n",
    "log_df = ps.sqldf(q1, locals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>label</th>\n",
       "      <th>user_id</th>\n",
       "      <th>promotion_id</th>\n",
       "      <th>voucher_min_spend</th>\n",
       "      <th>voucher_discount</th>\n",
       "      <th>voucher_collect_time</th>\n",
       "      <th>voucher_redeem_time</th>\n",
       "      <th>campaign_name</th>\n",
       "      <th>user_age_level</th>\n",
       "      <th>...</th>\n",
       "      <th>user_trd__orders_cnt_platform_discount_hist</th>\n",
       "      <th>user_trd__max_gmv_usd_hist</th>\n",
       "      <th>user_trd__avg_gmv_usd_hist</th>\n",
       "      <th>user_trd__min_gmv_usd_hist</th>\n",
       "      <th>dtype</th>\n",
       "      <th>rk</th>\n",
       "      <th>hist_session_id</th>\n",
       "      <th>hist_promotion_id</th>\n",
       "      <th>hist_rk</th>\n",
       "      <th>hist_voucher_collect_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>299</td>\n",
       "      <td>30</td>\n",
       "      <td>45451</td>\n",
       "      <td>45521</td>\n",
       "      <td>C2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.376755</td>\n",
       "      <td>3.917888</td>\n",
       "      <td>2.518198</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_425</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>425</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>100489</td>\n",
       "      <td>132869</td>\n",
       "      <td>C1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.976711</td>\n",
       "      <td>8.408431</td>\n",
       "      <td>0.739039</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10_82</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>82</td>\n",
       "      <td>299</td>\n",
       "      <td>30</td>\n",
       "      <td>46827</td>\n",
       "      <td>48182</td>\n",
       "      <td>C2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.972645</td>\n",
       "      <td>3.039102</td>\n",
       "      <td>1.498169</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100_82</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>82</td>\n",
       "      <td>299</td>\n",
       "      <td>30</td>\n",
       "      <td>46227</td>\n",
       "      <td>46227</td>\n",
       "      <td>C2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>34.0</td>\n",
       "      <td>397.755770</td>\n",
       "      <td>17.843147</td>\n",
       "      <td>0.003525</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000_386</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>386</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>96836</td>\n",
       "      <td>96836</td>\n",
       "      <td>C1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83457</th>\n",
       "      <td>6777_391</td>\n",
       "      <td>0</td>\n",
       "      <td>6777</td>\n",
       "      <td>391</td>\n",
       "      <td>199</td>\n",
       "      <td>30</td>\n",
       "      <td>128346</td>\n",
       "      <td>128346</td>\n",
       "      <td>C1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>93.471440</td>\n",
       "      <td>7.419820</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>train</td>\n",
       "      <td>102</td>\n",
       "      <td>6777_248</td>\n",
       "      <td>248</td>\n",
       "      <td>39</td>\n",
       "      <td>74788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83458</th>\n",
       "      <td>6777_383</td>\n",
       "      <td>0</td>\n",
       "      <td>6777</td>\n",
       "      <td>383</td>\n",
       "      <td>500</td>\n",
       "      <td>50</td>\n",
       "      <td>128346</td>\n",
       "      <td>128346</td>\n",
       "      <td>C1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>93.471440</td>\n",
       "      <td>7.419820</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>train</td>\n",
       "      <td>103</td>\n",
       "      <td>6777_138</td>\n",
       "      <td>138</td>\n",
       "      <td>2</td>\n",
       "      <td>39379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83459</th>\n",
       "      <td>6777_383</td>\n",
       "      <td>0</td>\n",
       "      <td>6777</td>\n",
       "      <td>383</td>\n",
       "      <td>500</td>\n",
       "      <td>50</td>\n",
       "      <td>128346</td>\n",
       "      <td>128346</td>\n",
       "      <td>C1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>93.471440</td>\n",
       "      <td>7.419820</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>train</td>\n",
       "      <td>103</td>\n",
       "      <td>6777_206</td>\n",
       "      <td>206</td>\n",
       "      <td>17</td>\n",
       "      <td>59004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83460</th>\n",
       "      <td>6777_383</td>\n",
       "      <td>0</td>\n",
       "      <td>6777</td>\n",
       "      <td>383</td>\n",
       "      <td>500</td>\n",
       "      <td>50</td>\n",
       "      <td>128346</td>\n",
       "      <td>128346</td>\n",
       "      <td>C1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>93.471440</td>\n",
       "      <td>7.419820</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>train</td>\n",
       "      <td>103</td>\n",
       "      <td>6777_215</td>\n",
       "      <td>215</td>\n",
       "      <td>27</td>\n",
       "      <td>64992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83461</th>\n",
       "      <td>6777_383</td>\n",
       "      <td>0</td>\n",
       "      <td>6777</td>\n",
       "      <td>383</td>\n",
       "      <td>500</td>\n",
       "      <td>50</td>\n",
       "      <td>128346</td>\n",
       "      <td>128346</td>\n",
       "      <td>C1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>93.471440</td>\n",
       "      <td>7.419820</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>train</td>\n",
       "      <td>103</td>\n",
       "      <td>6777_248</td>\n",
       "      <td>248</td>\n",
       "      <td>39</td>\n",
       "      <td>74788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83462 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      session_id  label user_id promotion_id  voucher_min_spend  \\\n",
       "0           0_82      0       0           82                299   \n",
       "1          1_425      0       1          425                 40   \n",
       "2          10_82      0      10           82                299   \n",
       "3         100_82      0     100           82                299   \n",
       "4       1000_386      0    1000          386                  0   \n",
       "...          ...    ...     ...          ...                ...   \n",
       "83457   6777_391      0    6777          391                199   \n",
       "83458   6777_383      0    6777          383                500   \n",
       "83459   6777_383      0    6777          383                500   \n",
       "83460   6777_383      0    6777          383                500   \n",
       "83461   6777_383      0    6777          383                500   \n",
       "\n",
       "       voucher_discount voucher_collect_time voucher_redeem_time  \\\n",
       "0                    30                45451               45521   \n",
       "1                     4               100489              132869   \n",
       "2                    30                46827               48182   \n",
       "3                    30                46227               46227   \n",
       "4                    60                96836               96836   \n",
       "...                 ...                  ...                 ...   \n",
       "83457                30               128346              128346   \n",
       "83458                50               128346              128346   \n",
       "83459                50               128346              128346   \n",
       "83460                50               128346              128346   \n",
       "83461                50               128346              128346   \n",
       "\n",
       "      campaign_name  user_age_level  ...  \\\n",
       "0                C2             4.0  ...   \n",
       "1                C1             0.0  ...   \n",
       "2                C2             NaN  ...   \n",
       "3                C2             3.0  ...   \n",
       "4                C1             3.0  ...   \n",
       "...             ...             ...  ...   \n",
       "83457            C1             4.0  ...   \n",
       "83458            C1             4.0  ...   \n",
       "83459            C1             4.0  ...   \n",
       "83460            C1             4.0  ...   \n",
       "83461            C1             4.0  ...   \n",
       "\n",
       "      user_trd__orders_cnt_platform_discount_hist  user_trd__max_gmv_usd_hist  \\\n",
       "0                                             0.0                    6.376755   \n",
       "1                                             1.0                   27.976711   \n",
       "2                                             0.0                    4.972645   \n",
       "3                                            34.0                  397.755770   \n",
       "4                                             0.0                    0.000000   \n",
       "...                                           ...                         ...   \n",
       "83457                                        50.0                   93.471440   \n",
       "83458                                        50.0                   93.471440   \n",
       "83459                                        50.0                   93.471440   \n",
       "83460                                        50.0                   93.471440   \n",
       "83461                                        50.0                   93.471440   \n",
       "\n",
       "       user_trd__avg_gmv_usd_hist  user_trd__min_gmv_usd_hist  dtype   rk  \\\n",
       "0                        3.917888                    2.518198  train    1   \n",
       "1                        8.408431                    0.739039  train    1   \n",
       "2                        3.039102                    1.498169  train    1   \n",
       "3                       17.843147                    0.003525  train    1   \n",
       "4                        0.000000                    0.000000  train    1   \n",
       "...                           ...                         ...    ...  ...   \n",
       "83457                    7.419820                    0.000000  train  102   \n",
       "83458                    7.419820                    0.000000  train  103   \n",
       "83459                    7.419820                    0.000000  train  103   \n",
       "83460                    7.419820                    0.000000  train  103   \n",
       "83461                    7.419820                    0.000000  train  103   \n",
       "\n",
       "       hist_session_id  hist_promotion_id hist_rk  hist_voucher_collect_time  \n",
       "0                                                                       None  \n",
       "1                                                                       None  \n",
       "2                                                                       None  \n",
       "3                                                                       None  \n",
       "4                                                                       None  \n",
       "...                ...                ...     ...                        ...  \n",
       "83457         6777_248                248      39                      74788  \n",
       "83458         6777_138                138       2                      39379  \n",
       "83459         6777_206                206      17                      59004  \n",
       "83460         6777_215                215      27                      64992  \n",
       "83461         6777_248                248      39                      74788  \n",
       "\n",
       "[83462 rows x 24 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = \" SELECT L.* \\\n",
    "            , coalesce(R.session_id, '') AS hist_session_id \\\n",
    "            , coalesce(R.promotion_id, '') AS hist_promotion_id \\\n",
    "            , coalesce(R.rk, '') AS hist_rk \\\n",
    "            , R.voucher_collect_time AS hist_voucher_collect_time \\\n",
    "        FROM {df} L \\\n",
    "        LEFT JOIN {df} R \\\n",
    "        ON L.user_id = R.user_id \\\n",
    "        AND L.session_id != R.session_id \\\n",
    "        AND L.campaign_name != R.campaign_name \\\n",
    "        AND R.label = 1 \\\n",
    "        AND L.rk > R.rk \\\n",
    "        ORDER BY L.rk ASC, R.rk ASC\".format(df='log_df')\n",
    "log_df_tmp = ps.sqldf(sql, locals())\n",
    "log_df_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_voucher_log = log_df_tmp.groupby([ 'session_id', 'label', 'user_id', 'promotion_id', 'voucher_min_spend', \n",
    "                       'voucher_discount', 'voucher_collect_time', 'voucher_redeem_time',\n",
    "                       'user_age_level', 'user_gender', 'user_purchase_level',\n",
    "                       'user_trd__orders_cnt_hist', 'user_trd__actual_gmv_usd_hist',\n",
    "                       'user_trd__orders_cnt_platform_discount_hist',\n",
    "                       'user_trd__max_gmv_usd_hist', 'user_trd__avg_gmv_usd_hist',\n",
    "                       'user_trd__min_gmv_usd_hist', 'dtype']) \\\n",
    "                .agg({'hist_session_id': lambda x: \"%s\" % ','.join(x),\n",
    "                      'hist_promotion_id': lambda x: \"%s\" % ','.join(x),\n",
    "                      'hist_rk': lambda x: list(x),\n",
    "                      'hist_voucher_collect_time': \"count\"}).reset_index()\n",
    "\n",
    "user_voucher_log['keys_length'] = user_voucher_log['hist_voucher_collect_time']\n",
    "user_voucher_log = user_voucher_log.drop(columns=['hist_rk', 'hist_voucher_collect_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>label</th>\n",
       "      <th>user_id</th>\n",
       "      <th>promotion_id</th>\n",
       "      <th>voucher_min_spend</th>\n",
       "      <th>voucher_discount</th>\n",
       "      <th>voucher_collect_time</th>\n",
       "      <th>voucher_redeem_time</th>\n",
       "      <th>user_age_level</th>\n",
       "      <th>user_gender</th>\n",
       "      <th>...</th>\n",
       "      <th>user_trd__orders_cnt_hist</th>\n",
       "      <th>user_trd__actual_gmv_usd_hist</th>\n",
       "      <th>user_trd__orders_cnt_platform_discount_hist</th>\n",
       "      <th>user_trd__max_gmv_usd_hist</th>\n",
       "      <th>user_trd__avg_gmv_usd_hist</th>\n",
       "      <th>user_trd__min_gmv_usd_hist</th>\n",
       "      <th>dtype</th>\n",
       "      <th>hist_session_id</th>\n",
       "      <th>hist_promotion_id</th>\n",
       "      <th>keys_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>299</td>\n",
       "      <td>30</td>\n",
       "      <td>45451</td>\n",
       "      <td>45521</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>23.507327</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.376755</td>\n",
       "      <td>3.917888</td>\n",
       "      <td>2.518198</td>\n",
       "      <td>train</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000_38</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>38</td>\n",
       "      <td>888</td>\n",
       "      <td>80</td>\n",
       "      <td>13253</td>\n",
       "      <td>13254</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>218.105824</td>\n",
       "      <td>9.0</td>\n",
       "      <td>42.643151</td>\n",
       "      <td>12.116990</td>\n",
       "      <td>3.581674</td>\n",
       "      <td>train</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10001_159</td>\n",
       "      <td>1</td>\n",
       "      <td>10001</td>\n",
       "      <td>159</td>\n",
       "      <td>799</td>\n",
       "      <td>70</td>\n",
       "      <td>80001</td>\n",
       "      <td>89306</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>39.0</td>\n",
       "      <td>373.530611</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.090705</td>\n",
       "      <td>6.225510</td>\n",
       "      <td>0.561611</td>\n",
       "      <td>train</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10001_319</td>\n",
       "      <td>0</td>\n",
       "      <td>10001</td>\n",
       "      <td>319</td>\n",
       "      <td>1999</td>\n",
       "      <td>200</td>\n",
       "      <td>115663</td>\n",
       "      <td>115663</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>42.0</td>\n",
       "      <td>381.810513</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.090705</td>\n",
       "      <td>5.614860</td>\n",
       "      <td>0.487420</td>\n",
       "      <td>train</td>\n",
       "      <td>10001_159</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10001_38</td>\n",
       "      <td>0</td>\n",
       "      <td>10001</td>\n",
       "      <td>38</td>\n",
       "      <td>888</td>\n",
       "      <td>80</td>\n",
       "      <td>12867</td>\n",
       "      <td>19625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>133.172685</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.419591</td>\n",
       "      <td>11.097724</td>\n",
       "      <td>1.811817</td>\n",
       "      <td>train</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58046</th>\n",
       "      <td>99_82</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>82</td>\n",
       "      <td>299</td>\n",
       "      <td>30</td>\n",
       "      <td>46577</td>\n",
       "      <td>46577</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2462.818244</td>\n",
       "      <td>50.0</td>\n",
       "      <td>329.698604</td>\n",
       "      <td>18.944756</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>train</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58047</th>\n",
       "      <td>99_83</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>83</td>\n",
       "      <td>1999</td>\n",
       "      <td>200</td>\n",
       "      <td>35523</td>\n",
       "      <td>53242</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2397.249462</td>\n",
       "      <td>46.0</td>\n",
       "      <td>329.698604</td>\n",
       "      <td>19.025789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>test</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58048</th>\n",
       "      <td>99_91</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>91</td>\n",
       "      <td>799</td>\n",
       "      <td>80</td>\n",
       "      <td>35523</td>\n",
       "      <td>46578</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2397.249462</td>\n",
       "      <td>46.0</td>\n",
       "      <td>329.698604</td>\n",
       "      <td>19.025789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>train</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58049</th>\n",
       "      <td>9_61</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>61</td>\n",
       "      <td>2999</td>\n",
       "      <td>300</td>\n",
       "      <td>24981</td>\n",
       "      <td>28017</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>715.893947</td>\n",
       "      <td>23.0</td>\n",
       "      <td>150.129713</td>\n",
       "      <td>9.419657</td>\n",
       "      <td>1.116494</td>\n",
       "      <td>train</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58050</th>\n",
       "      <td>9_69</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>69</td>\n",
       "      <td>888</td>\n",
       "      <td>80</td>\n",
       "      <td>24983</td>\n",
       "      <td>24983</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>715.893947</td>\n",
       "      <td>23.0</td>\n",
       "      <td>150.129713</td>\n",
       "      <td>9.419657</td>\n",
       "      <td>1.116494</td>\n",
       "      <td>train</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58051 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      session_id  label user_id promotion_id  voucher_min_spend  \\\n",
       "0           0_82      0       0           82                299   \n",
       "1       10000_38      0   10000           38                888   \n",
       "2      10001_159      1   10001          159                799   \n",
       "3      10001_319      0   10001          319               1999   \n",
       "4       10001_38      0   10001           38                888   \n",
       "...          ...    ...     ...          ...                ...   \n",
       "58046      99_82      0      99           82                299   \n",
       "58047      99_83      1      99           83               1999   \n",
       "58048      99_91      0      99           91                799   \n",
       "58049       9_61      1       9           61               2999   \n",
       "58050       9_69      0       9           69                888   \n",
       "\n",
       "       voucher_discount voucher_collect_time voucher_redeem_time  \\\n",
       "0                    30                45451               45521   \n",
       "1                    80                13253               13254   \n",
       "2                    70                80001               89306   \n",
       "3                   200               115663              115663   \n",
       "4                    80                12867               19625   \n",
       "...                 ...                  ...                 ...   \n",
       "58046                30                46577               46577   \n",
       "58047               200                35523               53242   \n",
       "58048                80                35523               46578   \n",
       "58049               300                24981               28017   \n",
       "58050                80                24983               24983   \n",
       "\n",
       "       user_age_level user_gender  ...  user_trd__orders_cnt_hist  \\\n",
       "0                 4.0           0  ...                        4.0   \n",
       "1                 3.0           0  ...                        6.0   \n",
       "2                 0.0           0  ...                       39.0   \n",
       "3                 0.0           0  ...                       42.0   \n",
       "4                 0.0           0  ...                       11.0   \n",
       "...               ...         ...  ...                        ...   \n",
       "58046             3.0           0  ...                       44.0   \n",
       "58047             3.0           0  ...                       43.0   \n",
       "58048             3.0           0  ...                       43.0   \n",
       "58049             3.0           1  ...                       22.0   \n",
       "58050             3.0           1  ...                       22.0   \n",
       "\n",
       "       user_trd__actual_gmv_usd_hist  \\\n",
       "0                          23.507327   \n",
       "1                         218.105824   \n",
       "2                         373.530611   \n",
       "3                         381.810513   \n",
       "4                         133.172685   \n",
       "...                              ...   \n",
       "58046                    2462.818244   \n",
       "58047                    2397.249462   \n",
       "58048                    2397.249462   \n",
       "58049                     715.893947   \n",
       "58050                     715.893947   \n",
       "\n",
       "       user_trd__orders_cnt_platform_discount_hist  \\\n",
       "0                                              0.0   \n",
       "1                                              9.0   \n",
       "2                                              3.0   \n",
       "3                                              3.0   \n",
       "4                                              0.0   \n",
       "...                                            ...   \n",
       "58046                                         50.0   \n",
       "58047                                         46.0   \n",
       "58048                                         46.0   \n",
       "58049                                         23.0   \n",
       "58050                                         23.0   \n",
       "\n",
       "       user_trd__max_gmv_usd_hist  user_trd__avg_gmv_usd_hist  \\\n",
       "0                        6.376755                    3.917888   \n",
       "1                       42.643151                   12.116990   \n",
       "2                       32.090705                    6.225510   \n",
       "3                       32.090705                    5.614860   \n",
       "4                       26.419591                   11.097724   \n",
       "...                           ...                         ...   \n",
       "58046                  329.698604                   18.944756   \n",
       "58047                  329.698604                   19.025789   \n",
       "58048                  329.698604                   19.025789   \n",
       "58049                  150.129713                    9.419657   \n",
       "58050                  150.129713                    9.419657   \n",
       "\n",
       "       user_trd__min_gmv_usd_hist  dtype hist_session_id hist_promotion_id  \\\n",
       "0                        2.518198  train                                     \n",
       "1                        3.581674  train                                     \n",
       "2                        0.561611  train                                     \n",
       "3                        0.487420  train       10001_159               159   \n",
       "4                        1.811817  train                                     \n",
       "...                           ...    ...             ...               ...   \n",
       "58046                    0.000000  train                                     \n",
       "58047                    0.000000   test                                     \n",
       "58048                    0.000000  train                                     \n",
       "58049                    1.116494  train                                     \n",
       "58050                    1.116494  train                                     \n",
       "\n",
       "      keys_length  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               1  \n",
       "4               0  \n",
       "...           ...  \n",
       "58046           0  \n",
       "58047           0  \n",
       "58048           0  \n",
       "58049           0  \n",
       "58050           0  \n",
       "\n",
       "[58051 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_voucher_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keys_length</th>\n",
       "      <th>session_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>39908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    keys_length  session_id\n",
       "0             0       39908\n",
       "1             1        8720\n",
       "2             2        4236\n",
       "3             3        2326\n",
       "4             4        1325\n",
       "5             5         721\n",
       "6             6         267\n",
       "7             7         218\n",
       "8             8         115\n",
       "9             9          72\n",
       "10           10          44\n",
       "11           11          45\n",
       "12           12          10\n",
       "13           13          13\n",
       "14           14          12\n",
       "15           18          19"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a statistics of historical UVG sequence distribution\n",
    "user_voucher_log.groupby(['keys_length']).agg({'session_id': \"count\"}).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoding and Normalization\n",
    "Label encoding for sparse features and normlaization for dense features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = user_voucher_log.copy()\n",
    "df = df.take(np.random.permutation(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_feature = ['promotion_id','session_id','user_gender','user_age_level','user_purchase_level'] #['promotion_id','voucher_min_spend','voucher_discount_amount']\n",
    "\n",
    "hist_list_features = ['hist_promotion_id','hist_session_id','keys_length']\n",
    "\n",
    "ignore_features=['dtype','venture','ds','user_id','label','voucher_collect_time','voucher_redeem_time','campaign_name','rk']\n",
    "ignore_features_key_words = ['out', 'emb']\n",
    "\n",
    "dense_feature = []\n",
    "train_features = []\n",
    "\n",
    "for feat in df.columns:\n",
    "    flag = True \n",
    "    for key in ignore_features_key_words:\n",
    "        if key in feat:\n",
    "            flag = False\n",
    "            break\n",
    "    if feat not in ignore_features and flag is True:\n",
    "        if feat not in hist_list_features:\n",
    "            train_features.append(feat)\n",
    "        if feat not in sparse_feature and feat not in hist_list_features:\n",
    "            dense_feature.append(feat)\n",
    "\n",
    "target = 'label'\n",
    "df[['session_id','promotion_id','user_gender','user_age_level','user_purchase_level']]=df[['session_id','promotion_id','user_gender','user_age_level','user_purchase_level']].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-20 13:00:28,626 [WARNING]: LabelEncoder encoding promotion_id len 462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lbe promotion_id\n",
      "LabelEncoderExt fitting...\n",
      "LabelEncoderExt transforming...\n",
      "lbe session_id\n",
      "LabelEncoderExt fitting...\n",
      "LabelEncoderExt transforming...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-20 13:00:28,823 [WARNING]: LabelEncoder encoding session_id len 58052\n",
      "2023-02-20 13:00:28,883 [WARNING]: LabelEncoder encoding user_gender len 4\n",
      "2023-02-20 13:00:28,943 [WARNING]: LabelEncoder encoding user_age_level len 10\n",
      "2023-02-20 13:00:29,003 [WARNING]: LabelEncoder encoding user_purchase_level len 12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lbe user_gender\n",
      "LabelEncoderExt fitting...\n",
      "LabelEncoderExt transforming...\n",
      "lbe user_age_level\n",
      "LabelEncoderExt fitting...\n",
      "LabelEncoderExt transforming...\n",
      "lbe user_purchase_level\n",
      "LabelEncoderExt fitting...\n",
      "LabelEncoderExt transforming...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "label_encoder = {}\n",
    "for feat in sparse_feature:\n",
    "    df[feat] = df[feat].fillna(0)\n",
    "    print(\"lbe {}\".format(feat))\n",
    "    \n",
    "    lbe = LabelEncoderExt()\n",
    "    lbe.fit(df[feat])\n",
    "        \n",
    "    df[feat] = lbe.transform(df[feat])\n",
    "    label_encoder[feat] = lbe\n",
    "    logging.warn('LabelEncoder encoding ' + feat + \" len \" + str(len(lbe)))\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voucher_min_spend\n",
      "voucher_discount\n",
      "user_trd__orders_cnt_hist\n",
      "user_trd__actual_gmv_usd_hist\n",
      "user_trd__orders_cnt_platform_discount_hist\n",
      "user_trd__max_gmv_usd_hist\n",
      "user_trd__avg_gmv_usd_hist\n",
      "user_trd__min_gmv_usd_hist\n"
     ]
    }
   ],
   "source": [
    "mean_kv = {}\n",
    "std_kv = {}\n",
    "for feat in dense_feature:\n",
    "    print(feat)\n",
    "    mean_kv[feat] = df[feat].mean()\n",
    "    std_kv[feat] = df[feat].std()\n",
    "    df[feat] = (df[feat] - mean_kv[feat]) / std_kv[feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_ctr_df = df \n",
    "\n",
    "dctr_train = deep_ctr_df[deep_ctr_df.dtype == 'train']\n",
    "dctr_v1 = deep_ctr_df[deep_ctr_df.dtype == 'test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "results={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 16\n",
    "sparse_feature_columns = [SparseFeat(feat, len(label_encoder[feat].classes_), embedding_dim = embedding_dim) for feat in sparse_feature]\n",
    "dense_feature_columns = [DenseFeat(feat, 1, ) for feat in dense_feature]\n",
    "\n",
    "dnn_feature_columns = sparse_feature_columns + dense_feature_columns\n",
    "linear_feature_columns = sparse_feature_columns + dense_feature_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR\n",
    "LR: Logistic Regression [1] is a shallow model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_model_input_data(feature_names, raw_features, target):\n",
    "    model_input = {}\n",
    "    for name in feature_names:\n",
    "        if name in sparse_feature:\n",
    "            model_input[name] = raw_features[name]\n",
    "        else:\n",
    "            model_input[name] = raw_features[name].fillna(0).astype(np.float32)\n",
    "    return raw_features[target], model_input\n",
    "\n",
    "feature_names = get_feature_names(dense_feature_columns + sparse_feature_columns)\n",
    "train_label, train_model_input = gen_model_input_data(feature_names, dctr_train, target)\n",
    "test_label1, test_model_input1 = gen_model_input_data(feature_names, dctr_v1, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Train on 46361 samples, validate on 11690 samples, 155 steps per epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 70.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2s - loss:  0.5892 - auc:  0.6761 - logloss:  0.5889 - val_auc:  0.6808 - val_logloss:  0.5127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 101.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50\n",
      "1s - loss:  0.4733 - auc:  0.7048 - logloss:  0.4732 - val_auc:  0.6906 - val_logloss:  0.4478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 101.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50\n",
      "1s - loss:  0.4313 - auc:  0.7231 - logloss:  0.4311 - val_auc:  0.7018 - val_logloss:  0.4242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 102.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50\n",
      "1s - loss:  0.4148 - auc:  0.7346 - logloss:  0.4148 - val_auc:  0.7109 - val_logloss:  0.4142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 102.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50\n",
      "1s - loss:  0.4068 - auc:  0.7434 - logloss:  0.4068 - val_auc:  0.7177 - val_logloss:  0.4087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 101.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50\n",
      "1s - loss:  0.4018 - auc:  0.7484 - logloss:  0.4017 - val_auc:  0.7228 - val_logloss:  0.4050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 101.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50\n",
      "1s - loss:  0.3982 - auc:  0.7526 - logloss:  0.3983 - val_auc:  0.7270 - val_logloss:  0.4022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 102.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50\n",
      "1s - loss:  0.3954 - auc:  0.7560 - logloss:  0.3954 - val_auc:  0.7307 - val_logloss:  0.3998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 92.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50\n",
      "1s - loss:  0.3930 - auc:  0.7572 - logloss:  0.3932 - val_auc:  0.7333 - val_logloss:  0.3979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 84.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50\n",
      "1s - loss:  0.3911 - auc:  0.7604 - logloss:  0.3911 - val_auc:  0.7356 - val_logloss:  0.3962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 83.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50\n",
      "1s - loss:  0.3895 - auc:  0.7610 - logloss:  0.3895 - val_auc:  0.7372 - val_logloss:  0.3949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 78.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50\n",
      "2s - loss:  0.3881 - auc:  0.7628 - logloss:  0.3880 - val_auc:  0.7387 - val_logloss:  0.3937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 85.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50\n",
      "1s - loss:  0.3869 - auc:  0.7635 - logloss:  0.3870 - val_auc:  0.7398 - val_logloss:  0.3927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 85.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50\n",
      "1s - loss:  0.3859 - auc:  0.7647 - logloss:  0.3859 - val_auc:  0.7410 - val_logloss:  0.3919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 83.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50\n",
      "1s - loss:  0.3851 - auc:  0.7644 - logloss:  0.3852 - val_auc:  0.7419 - val_logloss:  0.3910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 85.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50\n",
      "1s - loss:  0.3844 - auc:  0.7652 - logloss:  0.3842 - val_auc:  0.7428 - val_logloss:  0.3904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 86.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50\n",
      "1s - loss:  0.3837 - auc:  0.7660 - logloss:  0.3839 - val_auc:  0.7437 - val_logloss:  0.3898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 78.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50\n",
      "2s - loss:  0.3832 - auc:  0.7662 - logloss:  0.3831 - val_auc:  0.7439 - val_logloss:  0.3892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 83.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50\n",
      "1s - loss:  0.3827 - auc:  0.7664 - logloss:  0.3828 - val_auc:  0.7438 - val_logloss:  0.3889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 79.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50\n",
      "2s - loss:  0.3823 - auc:  0.7664 - logloss:  0.3823 - val_auc:  0.7448 - val_logloss:  0.3884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 86.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50\n",
      "1s - loss:  0.3819 - auc:  0.7667 - logloss:  0.3818 - val_auc:  0.7450 - val_logloss:  0.3881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 86.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50\n",
      "1s - loss:  0.3816 - auc:  0.7666 - logloss:  0.3814 - val_auc:  0.7452 - val_logloss:  0.3878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 87.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50\n",
      "1s - loss:  0.3813 - auc:  0.7669 - logloss:  0.3814 - val_auc:  0.7455 - val_logloss:  0.3875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 86.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50\n",
      "1s - loss:  0.3811 - auc:  0.7668 - logloss:  0.3811 - val_auc:  0.7459 - val_logloss:  0.3872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 86.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50\n",
      "1s - loss:  0.3808 - auc:  0.7676 - logloss:  0.3808 - val_auc:  0.7462 - val_logloss:  0.3870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 86.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50\n",
      "1s - loss:  0.3806 - auc:  0.7680 - logloss:  0.3806 - val_auc:  0.7464 - val_logloss:  0.3868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 85.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50\n",
      "1s - loss:  0.3804 - auc:  0.7673 - logloss:  0.3805 - val_auc:  0.7462 - val_logloss:  0.3867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 80.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50\n",
      "2s - loss:  0.3803 - auc:  0.7673 - logloss:  0.3802 - val_auc:  0.7468 - val_logloss:  0.3865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 85.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50\n",
      "1s - loss:  0.3801 - auc:  0.7667 - logloss:  0.3801 - val_auc:  0.7468 - val_logloss:  0.3864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 85.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50\n",
      "1s - loss:  0.3800 - auc:  0.7674 - logloss:  0.3800 - val_auc:  0.7470 - val_logloss:  0.3862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 85.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50\n",
      "1s - loss:  0.3799 - auc:  0.7679 - logloss:  0.3799 - val_auc:  0.7470 - val_logloss:  0.3861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 87.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50\n",
      "1s - loss:  0.3798 - auc:  0.7671 - logloss:  0.3796 - val_auc:  0.7472 - val_logloss:  0.3860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 87.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50\n",
      "1s - loss:  0.3797 - auc:  0.7674 - logloss:  0.3800 - val_auc:  0.7472 - val_logloss:  0.3859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 86.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50\n",
      "1s - loss:  0.3796 - auc:  0.7673 - logloss:  0.3798 - val_auc:  0.7476 - val_logloss:  0.3857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 87.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50\n",
      "1s - loss:  0.3795 - auc:  0.7677 - logloss:  0.3793 - val_auc:  0.7475 - val_logloss:  0.3858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 80.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50\n",
      "2s - loss:  0.3794 - auc:  0.7681 - logloss:  0.3794 - val_auc:  0.7475 - val_logloss:  0.3857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 86.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50\n",
      "1s - loss:  0.3793 - auc:  0.7676 - logloss:  0.3795 - val_auc:  0.7474 - val_logloss:  0.3856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 85.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50\n",
      "1s - loss:  0.3793 - auc:  0.7676 - logloss:  0.3792 - val_auc:  0.7478 - val_logloss:  0.3855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 86.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50\n",
      "1s - loss:  0.3792 - auc:  0.7673 - logloss:  0.3792 - val_auc:  0.7480 - val_logloss:  0.3855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 87.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50\n",
      "1s - loss:  0.3792 - auc:  0.7677 - logloss:  0.3790 - val_auc:  0.7479 - val_logloss:  0.3855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 86.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50\n",
      "1s - loss:  0.3791 - auc:  0.7676 - logloss:  0.3792 - val_auc:  0.7480 - val_logloss:  0.3854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 86.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50\n",
      "1s - loss:  0.3790 - auc:  0.7687 - logloss:  0.3789 - val_auc:  0.7482 - val_logloss:  0.3853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 84.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50\n",
      "1s - loss:  0.3790 - auc:  0.7683 - logloss:  0.3790 - val_auc:  0.7480 - val_logloss:  0.3853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 79.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50\n",
      "2s - loss:  0.3790 - auc:  0.7683 - logloss:  0.3789 - val_auc:  0.7476 - val_logloss:  0.3853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 83.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50\n",
      "1s - loss:  0.3789 - auc:  0.7677 - logloss:  0.3789 - val_auc:  0.7478 - val_logloss:  0.3853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 84.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50\n",
      "1s - loss:  0.3789 - auc:  0.7677 - logloss:  0.3791 - val_auc:  0.7481 - val_logloss:  0.3852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 85.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50\n",
      "1s - loss:  0.3789 - auc:  0.7681 - logloss:  0.3786 - val_auc:  0.7482 - val_logloss:  0.3851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 85.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50\n",
      "1s - loss:  0.3788 - auc:  0.7687 - logloss:  0.3791 - val_auc:  0.7483 - val_logloss:  0.3851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 85.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50\n",
      "1s - loss:  0.3788 - auc:  0.7686 - logloss:  0.3787 - val_auc:  0.7484 - val_logloss:  0.3851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 73.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50\n",
      "2s - loss:  0.3788 - auc:  0.7683 - logloss:  0.3786 - val_auc:  0.7481 - val_logloss:  0.3852\n"
     ]
    }
   ],
   "source": [
    "model_name = 'LR'\n",
    "epoch = 50\n",
    "batch_size = 300\n",
    "\n",
    "model = WDL(linear_feature_columns=dnn_feature_columns,\n",
    "            dnn_feature_columns=[], \n",
    "            dnn_use_bn=True,\n",
    "            l2_reg_dnn=0.1, \n",
    "            l2_reg_embedding = 0.0001, \n",
    "            dnn_hidden_units=(128,64), \n",
    "            init_std=1, \n",
    "            dnn_dropout=0.5, \n",
    "            task='binary', \n",
    "            dnn_activation='relu', \n",
    "            device=device)\n",
    "\n",
    "model\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.1, amsgrad=True)\n",
    "model.compile(optimizer, 'binary_crossentropy',metrics=['auc','logloss'])\n",
    "model.fit(train_model_input,  train_label.values.astype(int), batch_size=batch_size, epochs=epoch, validation_data=(test_model_input1,test_label1),verbose=1)\n",
    "res = model.evaluate(test_model_input1,test_label1)\n",
    "pred1 = model.predict(test_model_input1)\n",
    "results[model_name] = model, res, pred1, test_label1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBDT\n",
    "GBDT: Gradient Boosting Decision Tree [2] is used to assess the performance of non deep-learning algorithms. Only dense features are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:02:03] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\teval-auc:0.74426\teval-logloss:0.66234\ttrain-auc:0.75173\ttrain-logloss:0.66225\n",
      "[1]\teval-auc:0.74628\teval-logloss:0.63497\ttrain-auc:0.75559\ttrain-logloss:0.63484\n",
      "[2]\teval-auc:0.74539\teval-logloss:0.61074\ttrain-auc:0.75743\ttrain-logloss:0.61042\n",
      "[3]\teval-auc:0.74809\teval-logloss:0.58899\ttrain-auc:0.76167\ttrain-logloss:0.58850\n",
      "[4]\teval-auc:0.74831\teval-logloss:0.56951\ttrain-auc:0.76250\ttrain-logloss:0.56880\n",
      "[5]\teval-auc:0.74857\teval-logloss:0.55195\ttrain-auc:0.76321\ttrain-logloss:0.55111\n",
      "[6]\teval-auc:0.74915\teval-logloss:0.53605\ttrain-auc:0.76352\ttrain-logloss:0.53515\n",
      "[7]\teval-auc:0.74995\teval-logloss:0.52171\ttrain-auc:0.76406\ttrain-logloss:0.52070\n",
      "[8]\teval-auc:0.75152\teval-logloss:0.50867\ttrain-auc:0.76670\ttrain-logloss:0.50752\n",
      "[9]\teval-auc:0.75175\teval-logloss:0.49694\ttrain-auc:0.76707\ttrain-logloss:0.49556\n",
      "[10]\teval-auc:0.75225\teval-logloss:0.48625\ttrain-auc:0.76788\ttrain-logloss:0.48474\n",
      "[11]\teval-auc:0.75309\teval-logloss:0.47645\ttrain-auc:0.76881\ttrain-logloss:0.47479\n",
      "[12]\teval-auc:0.75355\teval-logloss:0.46760\ttrain-auc:0.76983\ttrain-logloss:0.46575\n",
      "[13]\teval-auc:0.75421\teval-logloss:0.45951\ttrain-auc:0.77044\ttrain-logloss:0.45751\n",
      "[14]\teval-auc:0.75502\teval-logloss:0.45212\ttrain-auc:0.77164\ttrain-logloss:0.44999\n",
      "[15]\teval-auc:0.75644\teval-logloss:0.44535\ttrain-auc:0.77403\ttrain-logloss:0.44303\n",
      "[16]\teval-auc:0.75662\teval-logloss:0.43920\ttrain-auc:0.77462\ttrain-logloss:0.43668\n",
      "[17]\teval-auc:0.75641\teval-logloss:0.43364\ttrain-auc:0.77521\ttrain-logloss:0.43089\n",
      "[18]\teval-auc:0.75678\teval-logloss:0.42851\ttrain-auc:0.77555\ttrain-logloss:0.42560\n",
      "[19]\teval-auc:0.75750\teval-logloss:0.42374\ttrain-auc:0.77684\ttrain-logloss:0.42059\n",
      "[20]\teval-auc:0.75767\teval-logloss:0.41939\ttrain-auc:0.77741\ttrain-logloss:0.41597\n",
      "[21]\teval-auc:0.75785\teval-logloss:0.41544\ttrain-auc:0.77776\ttrain-logloss:0.41180\n",
      "[22]\teval-auc:0.75787\teval-logloss:0.41177\ttrain-auc:0.77826\ttrain-logloss:0.40788\n",
      "[23]\teval-auc:0.75886\teval-logloss:0.40837\ttrain-auc:0.77969\ttrain-logloss:0.40425\n",
      "[24]\teval-auc:0.75993\teval-logloss:0.40512\ttrain-auc:0.78142\ttrain-logloss:0.40073\n",
      "[25]\teval-auc:0.76011\teval-logloss:0.40227\ttrain-auc:0.78184\ttrain-logloss:0.39764\n",
      "[26]\teval-auc:0.76183\teval-logloss:0.39934\ttrain-auc:0.78374\ttrain-logloss:0.39452\n",
      "[27]\teval-auc:0.76191\teval-logloss:0.39694\ttrain-auc:0.78409\ttrain-logloss:0.39187\n",
      "[28]\teval-auc:0.76292\teval-logloss:0.39448\ttrain-auc:0.78579\ttrain-logloss:0.38916\n",
      "[29]\teval-auc:0.76343\teval-logloss:0.39242\ttrain-auc:0.78652\ttrain-logloss:0.38687\n",
      "[30]\teval-auc:0.76346\teval-logloss:0.39054\ttrain-auc:0.78683\ttrain-logloss:0.38477\n",
      "[31]\teval-auc:0.76377\teval-logloss:0.38880\ttrain-auc:0.78757\ttrain-logloss:0.38277\n",
      "[32]\teval-auc:0.76405\teval-logloss:0.38716\ttrain-auc:0.78776\ttrain-logloss:0.38093\n",
      "[33]\teval-auc:0.76430\teval-logloss:0.38567\ttrain-auc:0.78831\ttrain-logloss:0.37923\n",
      "[34]\teval-auc:0.76505\teval-logloss:0.38410\ttrain-auc:0.78952\ttrain-logloss:0.37740\n",
      "[35]\teval-auc:0.76545\teval-logloss:0.38287\ttrain-auc:0.79021\ttrain-logloss:0.37595\n",
      "[36]\teval-auc:0.76622\teval-logloss:0.38148\ttrain-auc:0.79155\ttrain-logloss:0.37431\n",
      "[37]\teval-auc:0.76628\teval-logloss:0.38045\ttrain-auc:0.79214\ttrain-logloss:0.37298\n",
      "[38]\teval-auc:0.76661\teval-logloss:0.37938\ttrain-auc:0.79245\ttrain-logloss:0.37174\n",
      "[39]\teval-auc:0.76773\teval-logloss:0.37825\ttrain-auc:0.79411\ttrain-logloss:0.37027\n",
      "[40]\teval-auc:0.76803\teval-logloss:0.37737\ttrain-auc:0.79428\ttrain-logloss:0.36922\n",
      "[41]\teval-auc:0.76837\teval-logloss:0.37658\ttrain-auc:0.79505\ttrain-logloss:0.36812\n",
      "[42]\teval-auc:0.76888\teval-logloss:0.37572\ttrain-auc:0.79580\ttrain-logloss:0.36698\n",
      "[43]\teval-auc:0.76896\teval-logloss:0.37509\ttrain-auc:0.79647\ttrain-logloss:0.36600\n",
      "[44]\teval-auc:0.76906\teval-logloss:0.37447\ttrain-auc:0.79715\ttrain-logloss:0.36508\n",
      "[45]\teval-auc:0.76935\teval-logloss:0.37385\ttrain-auc:0.79800\ttrain-logloss:0.36412\n",
      "[46]\teval-auc:0.76971\teval-logloss:0.37324\ttrain-auc:0.79879\ttrain-logloss:0.36323\n",
      "[47]\teval-auc:0.77003\teval-logloss:0.37264\ttrain-auc:0.79968\ttrain-logloss:0.36233\n",
      "[48]\teval-auc:0.77020\teval-logloss:0.37216\ttrain-auc:0.80019\ttrain-logloss:0.36160\n",
      "[49]\teval-auc:0.77071\teval-logloss:0.37160\ttrain-auc:0.80125\ttrain-logloss:0.36070\n",
      "[50]\teval-auc:0.77096\teval-logloss:0.37112\ttrain-auc:0.80188\ttrain-logloss:0.36001\n",
      "[51]\teval-auc:0.77107\teval-logloss:0.37070\ttrain-auc:0.80229\ttrain-logloss:0.35932\n",
      "[52]\teval-auc:0.77138\teval-logloss:0.37028\ttrain-auc:0.80319\ttrain-logloss:0.35855\n",
      "[53]\teval-auc:0.77144\teval-logloss:0.36993\ttrain-auc:0.80353\ttrain-logloss:0.35798\n",
      "[54]\teval-auc:0.77178\teval-logloss:0.36954\ttrain-auc:0.80439\ttrain-logloss:0.35729\n",
      "[55]\teval-auc:0.77178\teval-logloss:0.36930\ttrain-auc:0.80521\ttrain-logloss:0.35665\n",
      "[56]\teval-auc:0.77187\teval-logloss:0.36904\ttrain-auc:0.80581\ttrain-logloss:0.35608\n",
      "[57]\teval-auc:0.77202\teval-logloss:0.36877\ttrain-auc:0.80689\ttrain-logloss:0.35540\n",
      "[58]\teval-auc:0.77216\teval-logloss:0.36853\ttrain-auc:0.80736\ttrain-logloss:0.35483\n",
      "[59]\teval-auc:0.77214\teval-logloss:0.36835\ttrain-auc:0.80795\ttrain-logloss:0.35433\n",
      "[60]\teval-auc:0.77260\teval-logloss:0.36806\ttrain-auc:0.80875\ttrain-logloss:0.35378\n",
      "[61]\teval-auc:0.77280\teval-logloss:0.36786\ttrain-auc:0.80911\ttrain-logloss:0.35335\n",
      "[62]\teval-auc:0.77297\teval-logloss:0.36762\ttrain-auc:0.80992\ttrain-logloss:0.35282\n",
      "[63]\teval-auc:0.77302\teval-logloss:0.36744\ttrain-auc:0.81052\ttrain-logloss:0.35235\n",
      "[64]\teval-auc:0.77307\teval-logloss:0.36731\ttrain-auc:0.81174\ttrain-logloss:0.35179\n",
      "[65]\teval-auc:0.77307\teval-logloss:0.36719\ttrain-auc:0.81231\ttrain-logloss:0.35133\n",
      "[66]\teval-auc:0.77315\teval-logloss:0.36706\ttrain-auc:0.81261\ttrain-logloss:0.35095\n",
      "[67]\teval-auc:0.77349\teval-logloss:0.36683\ttrain-auc:0.81419\ttrain-logloss:0.35027\n",
      "[68]\teval-auc:0.77338\teval-logloss:0.36674\ttrain-auc:0.81524\ttrain-logloss:0.34968\n",
      "[69]\teval-auc:0.77355\teval-logloss:0.36658\ttrain-auc:0.81586\ttrain-logloss:0.34922\n",
      "[70]\teval-auc:0.77355\teval-logloss:0.36652\ttrain-auc:0.81619\ttrain-logloss:0.34889\n",
      "[71]\teval-auc:0.77383\teval-logloss:0.36634\ttrain-auc:0.81701\ttrain-logloss:0.34839\n",
      "[72]\teval-auc:0.77409\teval-logloss:0.36613\ttrain-auc:0.81787\ttrain-logloss:0.34787\n",
      "[73]\teval-auc:0.77436\teval-logloss:0.36599\ttrain-auc:0.81878\ttrain-logloss:0.34735\n",
      "[74]\teval-auc:0.77428\teval-logloss:0.36592\ttrain-auc:0.81960\ttrain-logloss:0.34686\n",
      "[75]\teval-auc:0.77443\teval-logloss:0.36580\ttrain-auc:0.82050\ttrain-logloss:0.34632\n",
      "[76]\teval-auc:0.77456\teval-logloss:0.36566\ttrain-auc:0.82090\ttrain-logloss:0.34594\n",
      "[77]\teval-auc:0.77480\teval-logloss:0.36553\ttrain-auc:0.82142\ttrain-logloss:0.34559\n",
      "[78]\teval-auc:0.77486\teval-logloss:0.36548\ttrain-auc:0.82180\ttrain-logloss:0.34527\n",
      "[79]\teval-auc:0.77484\teval-logloss:0.36540\ttrain-auc:0.82228\ttrain-logloss:0.34489\n",
      "[80]\teval-auc:0.77501\teval-logloss:0.36525\ttrain-auc:0.82292\ttrain-logloss:0.34445\n",
      "[81]\teval-auc:0.77515\teval-logloss:0.36518\ttrain-auc:0.82339\ttrain-logloss:0.34415\n",
      "[82]\teval-auc:0.77533\teval-logloss:0.36508\ttrain-auc:0.82409\ttrain-logloss:0.34381\n",
      "[83]\teval-auc:0.77534\teval-logloss:0.36500\ttrain-auc:0.82465\ttrain-logloss:0.34340\n",
      "[84]\teval-auc:0.77549\teval-logloss:0.36490\ttrain-auc:0.82509\ttrain-logloss:0.34309\n",
      "[85]\teval-auc:0.77540\teval-logloss:0.36490\ttrain-auc:0.82568\ttrain-logloss:0.34274\n",
      "[86]\teval-auc:0.77538\teval-logloss:0.36485\ttrain-auc:0.82571\ttrain-logloss:0.34260\n",
      "[87]\teval-auc:0.77535\teval-logloss:0.36486\ttrain-auc:0.82620\ttrain-logloss:0.34233\n",
      "[88]\teval-auc:0.77532\teval-logloss:0.36484\ttrain-auc:0.82652\ttrain-logloss:0.34203\n",
      "[89]\teval-auc:0.77534\teval-logloss:0.36478\ttrain-auc:0.82702\ttrain-logloss:0.34178\n",
      "[90]\teval-auc:0.77543\teval-logloss:0.36471\ttrain-auc:0.82736\ttrain-logloss:0.34150\n",
      "[91]\teval-auc:0.77545\teval-logloss:0.36466\ttrain-auc:0.82782\ttrain-logloss:0.34123\n",
      "[92]\teval-auc:0.77571\teval-logloss:0.36450\ttrain-auc:0.82843\ttrain-logloss:0.34080\n",
      "[93]\teval-auc:0.77577\teval-logloss:0.36448\ttrain-auc:0.82886\ttrain-logloss:0.34059\n",
      "[94]\teval-auc:0.77581\teval-logloss:0.36446\ttrain-auc:0.82913\ttrain-logloss:0.34035\n",
      "[95]\teval-auc:0.77584\teval-logloss:0.36447\ttrain-auc:0.82944\ttrain-logloss:0.34017\n",
      "[96]\teval-auc:0.77573\teval-logloss:0.36448\ttrain-auc:0.82984\ttrain-logloss:0.33989\n",
      "[97]\teval-auc:0.77586\teval-logloss:0.36442\ttrain-auc:0.83057\ttrain-logloss:0.33958\n",
      "[98]\teval-auc:0.77578\teval-logloss:0.36444\ttrain-auc:0.83085\ttrain-logloss:0.33938\n",
      "[99]\teval-auc:0.77582\teval-logloss:0.36445\ttrain-auc:0.83106\ttrain-logloss:0.33927\n",
      "[100]\teval-auc:0.77615\teval-logloss:0.36430\ttrain-auc:0.83159\ttrain-logloss:0.33888\n",
      "[101]\teval-auc:0.77622\teval-logloss:0.36426\ttrain-auc:0.83198\ttrain-logloss:0.33866\n",
      "[102]\teval-auc:0.77626\teval-logloss:0.36422\ttrain-auc:0.83243\ttrain-logloss:0.33840\n",
      "[103]\teval-auc:0.77624\teval-logloss:0.36424\ttrain-auc:0.83250\ttrain-logloss:0.33834\n",
      "[104]\teval-auc:0.77633\teval-logloss:0.36415\ttrain-auc:0.83272\ttrain-logloss:0.33811\n",
      "[105]\teval-auc:0.77618\teval-logloss:0.36415\ttrain-auc:0.83314\ttrain-logloss:0.33781\n",
      "[106]\teval-auc:0.77615\teval-logloss:0.36416\ttrain-auc:0.83333\ttrain-logloss:0.33771\n",
      "[107]\teval-auc:0.77643\teval-logloss:0.36406\ttrain-auc:0.83384\ttrain-logloss:0.33743\n",
      "[108]\teval-auc:0.77647\teval-logloss:0.36403\ttrain-auc:0.83423\ttrain-logloss:0.33722\n",
      "[109]\teval-auc:0.77641\teval-logloss:0.36399\ttrain-auc:0.83481\ttrain-logloss:0.33685\n",
      "[110]\teval-auc:0.77630\teval-logloss:0.36404\ttrain-auc:0.83517\ttrain-logloss:0.33667\n",
      "[111]\teval-auc:0.77626\teval-logloss:0.36403\ttrain-auc:0.83551\ttrain-logloss:0.33646\n",
      "[112]\teval-auc:0.77614\teval-logloss:0.36407\ttrain-auc:0.83582\ttrain-logloss:0.33625\n",
      "[113]\teval-auc:0.77611\teval-logloss:0.36409\ttrain-auc:0.83589\ttrain-logloss:0.33620\n",
      "[114]\teval-auc:0.77613\teval-logloss:0.36406\ttrain-auc:0.83636\ttrain-logloss:0.33599\n",
      "[115]\teval-auc:0.77602\teval-logloss:0.36407\ttrain-auc:0.83661\ttrain-logloss:0.33582\n",
      "[116]\teval-auc:0.77594\teval-logloss:0.36409\ttrain-auc:0.83718\ttrain-logloss:0.33556\n",
      "[117]\teval-auc:0.77599\teval-logloss:0.36408\ttrain-auc:0.83827\ttrain-logloss:0.33508\n",
      "[118]\teval-auc:0.77596\teval-logloss:0.36409\ttrain-auc:0.83839\ttrain-logloss:0.33500\n",
      "[119]\teval-auc:0.77594\teval-logloss:0.36408\ttrain-auc:0.83873\ttrain-logloss:0.33479\n",
      "[120]\teval-auc:0.77600\teval-logloss:0.36401\ttrain-auc:0.83901\ttrain-logloss:0.33457\n",
      "[121]\teval-auc:0.77602\teval-logloss:0.36402\ttrain-auc:0.83929\ttrain-logloss:0.33435\n",
      "[122]\teval-auc:0.77600\teval-logloss:0.36403\ttrain-auc:0.83981\ttrain-logloss:0.33407\n",
      "[123]\teval-auc:0.77598\teval-logloss:0.36398\ttrain-auc:0.84025\ttrain-logloss:0.33380\n",
      "[124]\teval-auc:0.77600\teval-logloss:0.36396\ttrain-auc:0.84039\ttrain-logloss:0.33371\n",
      "[125]\teval-auc:0.77597\teval-logloss:0.36396\ttrain-auc:0.84091\ttrain-logloss:0.33339\n",
      "[126]\teval-auc:0.77587\teval-logloss:0.36400\ttrain-auc:0.84114\ttrain-logloss:0.33324\n",
      "[127]\teval-auc:0.77600\teval-logloss:0.36395\ttrain-auc:0.84157\ttrain-logloss:0.33296\n",
      "[128]\teval-auc:0.77600\teval-logloss:0.36396\ttrain-auc:0.84160\ttrain-logloss:0.33293\n",
      "[129]\teval-auc:0.77593\teval-logloss:0.36400\ttrain-auc:0.84186\ttrain-logloss:0.33277\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "model_name = \"xgBoost\"\n",
    "xgb_data_train = dctr_train\n",
    "df_xgb_train =  xgb.DMatrix(xgb_data_train[dense_feature], \n",
    "                            label=xgb_data_train[target])\n",
    "\n",
    "xgb_data_test1 = dctr_v1\n",
    "df_xgb_test1 = xgb.DMatrix(xgb_data_test1[dense_feature],\n",
    "                            label=xgb_data_test1[target])\n",
    "\n",
    "params = {'objective': 'binary:logistic',\n",
    "          'eval_metric': ['auc', 'logloss'],\n",
    "          'learning_rate': 0.06,\n",
    "          'num_leaves':256,\n",
    "          'max_depth':7,\n",
    "          'max_bin':64}\n",
    "\n",
    "evallist = [(df_xgb_test1, 'eval'), (df_xgb_train, 'train')]\n",
    "num_boost_round = 130\n",
    "xgb = xgb.train(params,\n",
    "                df_xgb_train,\n",
    "                num_boost_round,\n",
    "                evallist) \n",
    "\n",
    "xgb_pred_v1 = xgb.predict(df_xgb_test1)\n",
    "xgb_label_v1 = xgb_data_test1[target]\n",
    "auc_t1 = roc_auc_score(xgb_label_v1, xgb_pred_v1)\n",
    "logloss_t1 = log_loss(xgb_label_v1, xgb_pred_v1)\n",
    "res = {'eval_auc':auc_t1, \"eval_logloss\":logloss_t1}\n",
    "\n",
    "results[model_name] = xgb, res, xgb_pred_v1, xgb_label_v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN\n",
    "The Deep Neural Network is used as the first baseline taking both dense features and embedding of sparse id features into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Train on 46361 samples, validate on 11690 samples, 155 steps per epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 33.92it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Output 0 of UnbindBackward is a view and its base or another view of its base has been modified inplace. This view is the output of a function that returns multiple views. Such functions do not allow the output views to be modified inplace. You should replace the inplace operation by an out-of-place one.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_29292/340309625.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-08\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'auc'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'logloss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_model_input\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mtrain_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_model_input1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_label1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_model_input1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_label1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mpred1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_model_input1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/DMBGN-fork/venv/lib/python3.7/site-packages/deepctr_torch/models/basemodel.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, initial_epoch, validation_split, validation_data, shuffle, callbacks)\u001b[0m\n\u001b[1;32m    226\u001b[0m                         \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m                         \u001b[0mreg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_regularization_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m                         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mreg_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maux_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/DMBGN-fork/venv/lib/python3.7/site-packages/deepctr_torch/models/basemodel.py\u001b[0m in \u001b[0;36mget_regularization_loss\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    380\u001b[0m                     \u001b[0ml2_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m                     \u001b[0ml2_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m                 \u001b[0mweight_reg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight_reg_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml2_reg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0mreg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight_decay\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mweight_reg_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/DMBGN-fork/venv/lib/python3.7/site-packages/torch/functional.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(input, p, dim, keepdim, out, dtype)\u001b[0m\n\u001b[1;32m   1291\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1292\u001b[0m             \u001b[0m_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# noqa: C416 TODO: rewrite as list(range(m))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1293\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdim\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m     \u001b[0;31m# TODO: when https://github.com/pytorch/pytorch/issues/33782 is fixed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Output 0 of UnbindBackward is a view and its base or another view of its base has been modified inplace. This view is the output of a function that returns multiple views. Such functions do not allow the output views to be modified inplace. You should replace the inplace operation by an out-of-place one."
     ]
    }
   ],
   "source": [
    "model_name = 'DNN'\n",
    "epoch = 20\n",
    "batch_size = 300\n",
    "\n",
    "model = WDL(linear_feature_columns=[], \n",
    "            dnn_feature_columns=dnn_feature_columns, \n",
    "            dnn_use_bn=True,\n",
    "            l2_reg_dnn=0.1, \n",
    "            l2_reg_embedding = 0.0001, \n",
    "            dnn_hidden_units=(128,64), \n",
    "            init_std=1, \n",
    "            dnn_dropout=0.5, \n",
    "            task='binary', \n",
    "            dnn_activation='relu', \n",
    "            device=device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.1, amsgrad=True)\n",
    "model.compile(optimizer, 'binary_crossentropy',metrics=['auc','logloss'])\n",
    "model.fit(train_model_input,  train_label.values.astype(int), batch_size=batch_size, epochs=epoch, validation_data=(test_model_input1,test_label1),verbose=1)\n",
    "res = model.evaluate(test_model_input1,test_label1)\n",
    "pred1 = model.predict(test_model_input1)\n",
    "results[model_name] = model, res, pred1, test_label1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WDL\n",
    "Wide and Deep model [3] is widely accepted in real industrial applications. Compared with DNN, it has an additional linear model besides the deep model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'WDL'\n",
    "epoch = 20\n",
    "batch_size = 300\n",
    "\n",
    "model = WDL(linear_feature_columns=linear_feature_columns, \n",
    "            dnn_feature_columns=dnn_feature_columns, \n",
    "            dnn_use_bn=True,\n",
    "            l2_reg_dnn=0.1, \n",
    "            l2_reg_embedding = 0.0001, \n",
    "            dnn_hidden_units=(128,64), \n",
    "            init_std=1, \n",
    "            dnn_dropout=0.5, \n",
    "            task='binary', \n",
    "            dnn_activation='relu', \n",
    "            device=device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.05, amsgrad=True)\n",
    "model.compile(optimizer, 'binary_crossentropy',metrics=['auc','logloss'])\n",
    "model.fit(train_model_input,  train_label.values.astype(int), batch_size=batch_size, epochs=epoch, validation_data=(test_model_input1,test_label1),verbose=1)\n",
    "\n",
    "res = model.evaluate(test_model_input1,test_label1)\n",
    "pred1 = model.predict(test_model_input1)\n",
    "\n",
    "results[model_name] = model, res, pred1, test_label1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIN\n",
    "Deep Interest Network [4] is an attention-based model in recommendation systems that has been proven successful in Alibaba. We use this as our second baseline, replacing the user’s historical item sequences with user’s historical voucher sequences to adapt to the VRR prediction task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start generating x y data\n",
      "['session_id', 'user_gender', 'user_age_level', 'user_purchase_level', 'promotion_id', 'hist_promotion_id', 'voucher_min_spend', 'voucher_discount', 'user_trd__orders_cnt_hist', 'user_trd__actual_gmv_usd_hist', 'user_trd__orders_cnt_platform_discount_hist', 'user_trd__max_gmv_usd_hist', 'user_trd__avg_gmv_usd_hist', 'user_trd__min_gmv_usd_hist', 'keys_length']\n",
      "handling hist_list_features Feature: hist_promotion_id\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46361/46361 [00:00<00:00, 90532.25it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoderExt transforming...\n",
      "start generating x y data\n",
      "['session_id', 'user_gender', 'user_age_level', 'user_purchase_level', 'promotion_id', 'hist_promotion_id', 'voucher_min_spend', 'voucher_discount', 'user_trd__orders_cnt_hist', 'user_trd__actual_gmv_usd_hist', 'user_trd__orders_cnt_platform_discount_hist', 'user_trd__max_gmv_usd_hist', 'user_trd__avg_gmv_usd_hist', 'user_trd__min_gmv_usd_hist', 'keys_length']\n",
      "handling hist_list_features Feature: hist_promotion_id\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11690/11690 [00:00<00:00, 110155.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoderExt transforming...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "def get_xy_fd(dataset):\n",
    "    print (\"start generating x y data\")\n",
    "    \n",
    "    dnn_feature_columns = []\n",
    "    dnn_feature_columns += [SparseFeat(feat, len(label_encoder[feat]), embedding_dim = 16) \n",
    "                            for feat in ['session_id','user_gender','user_age_level','user_purchase_level', 'promotion_id']]\n",
    "    \n",
    "    dnn_feature_columns += [VarLenSparseFeat(SparseFeat('hist_promotion_id', len(label_encoder[\"promotion_id\"]), embedding_dim=16), sequence_size)]\n",
    "    \n",
    "    dnn_feature_columns += [DenseFeat(feat, 1, )  for feat in dense_feature]\n",
    "    dnn_feature_columns += [DenseFeat(feat, 1, )  for feat in ['keys_length']]\n",
    "\n",
    "    feature_names = get_feature_names(dnn_feature_columns)\n",
    "    print (feature_names)\n",
    "    \n",
    "    behavior_feature_list = ['promotion_id']\n",
    "\n",
    "    y, x = gen_dmbgn_input_data(feature_names, dataset, target, label_encoder, 6, sparse_feature, hist_list_features)\n",
    "    return x, y, dnn_feature_columns, behavior_feature_list\n",
    "\n",
    "sequence_size = 6\n",
    "embedding_dim1 = 16\n",
    "\n",
    "x, y, dnn_feature_columns, behavior_feature_list = get_xy_fd(dctr_train)\n",
    "test_model_input1, test_label1, _, _ = get_xy_fd(dctr_v1)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DIN(\n",
       "  (embedding_dict): ModuleDict(\n",
       "    (session_id): Embedding(58052, 16)\n",
       "    (user_gender): Embedding(4, 16)\n",
       "    (user_age_level): Embedding(10, 16)\n",
       "    (user_purchase_level): Embedding(12, 16)\n",
       "    (promotion_id): Embedding(462, 16)\n",
       "    (hist_promotion_id): Embedding(462, 16)\n",
       "  )\n",
       "  (linear_model): Linear(\n",
       "    (embedding_dict): ModuleDict()\n",
       "  )\n",
       "  (out): PredictionLayer()\n",
       "  (attention): HistAttentionSeqPoolingLayer(\n",
       "    (local_att): AttentionUnit(\n",
       "      (dnn): DNN(\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (linears): ModuleList(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (activation_layers): ModuleList(\n",
       "          (0): PReLU(num_parameters=1)\n",
       "        )\n",
       "      )\n",
       "      (dense): Linear(in_features=64, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (dnn): DNN(\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (linears): ModuleList(\n",
       "      (0): Linear(in_features=104, out_features=128, bias=True)\n",
       "      (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "    )\n",
       "    (bn): ModuleList(\n",
       "      (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (activation_layers): ModuleList(\n",
       "      (0): ReLU(inplace=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (dnn_linear): Linear(in_features=64, out_features=1, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'DIN'\n",
    "\n",
    "model = DIN(dnn_feature_columns, \n",
    "            behavior_feature_list, \n",
    "            # target_emb_dim_aft=0, \n",
    "            device=device, \n",
    "            att_activation='prelu', \n",
    "            att_weight_normalization=False, \n",
    "            dnn_activation='relu', \n",
    "            l2_reg_dnn=0.1, \n",
    "            l2_reg_embedding = 0.0001, \n",
    "            dnn_hidden_units=(128,64), \n",
    "            att_hidden_size=(64,), \n",
    "            init_std=1, \n",
    "            dnn_dropout=0.5, \n",
    "            dnn_use_bn=True)\n",
    "\n",
    "\n",
    "model.embedding_dict['promotion_id'].requires_grad = True\n",
    "model.embedding_dict['promotion_id'].weight.requires_grad = True\n",
    "\n",
    "model.embedding_dict['hist_promotion_id'].requires_grad = True\n",
    "model.embedding_dict['hist_promotion_id'].weight.requires_grad = True\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.05, amsgrad=True)\n",
    "model.compile(optimizer, 'binary_crossentropy', metrics=['auc', 'logloss'])\n",
    "\n",
    "loss_func = model.loss_func\n",
    "optim = model.optim\n",
    "metrics = model.metrics\n",
    "feature_index = model.feature_index\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_ids = [i for i in range(torch.cuda.device_count())]\n",
    "device_count = len(device_ids)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model = torch.nn.DataParallel(model, device_ids)\n",
    "    \n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 46361 samples, validate on 11690 samples, 155 steps per epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 47.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.4593 - auc:  0.6290 - logloss:  0.4590 - val_auc:  0.7100 - val_logloss:  0.4010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 49.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.3933 - auc:  0.7319 - logloss:  0.3930 - val_auc:  0.7457 - val_logloss:  0.3845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 49.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.3807 - auc:  0.7584 - logloss:  0.3803 - val_auc:  0.7609 - val_logloss:  0.3768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 49.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.3731 - auc:  0.7730 - logloss:  0.3728 - val_auc:  0.7646 - val_logloss:  0.3752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 50.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.3682 - auc:  0.7818 - logloss:  0.3679 - val_auc:  0.7697 - val_logloss:  0.3737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 50.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.3644 - auc:  0.7867 - logloss:  0.3642 - val_auc:  0.7718 - val_logloss:  0.3719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 49.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.3600 - auc:  0.7948 - logloss:  0.3598 - val_auc:  0.7714 - val_logloss:  0.3707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 47.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.3566 - auc:  0.8003 - logloss:  0.3564 - val_auc:  0.7768 - val_logloss:  0.3684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 49.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.3533 - auc:  0.8058 - logloss:  0.3532 - val_auc:  0.7761 - val_logloss:  0.3687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 49.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.3490 - auc:  0.8110 - logloss:  0.3489 - val_auc:  0.7783 - val_logloss:  0.3704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 48.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.3460 - auc:  0.8164 - logloss:  0.3463 - val_auc:  0.7716 - val_logloss:  0.3717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 46.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.3415 - auc:  0.8246 - logloss:  0.3415 - val_auc:  0.7771 - val_logloss:  0.3708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 47.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.3337 - auc:  0.8329 - logloss:  0.3338 - val_auc:  0.7723 - val_logloss:  0.3738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 47.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.3238 - auc:  0.8484 - logloss:  0.3237 - val_auc:  0.7674 - val_logloss:  0.3868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 48.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.3064 - auc:  0.8688 - logloss:  0.3065 - val_auc:  0.7647 - val_logloss:  0.3901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 44.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.2729 - auc:  0.9015 - logloss:  0.2728 - val_auc:  0.7461 - val_logloss:  0.4346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 47.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.2097 - auc:  0.9439 - logloss:  0.2096 - val_auc:  0.7324 - val_logloss:  0.5094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 43.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.1313 - auc:  0.9755 - logloss:  0.1311 - val_auc:  0.7107 - val_logloss:  0.6225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 48.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.0694 - auc:  0.9913 - logloss:  0.0693 - val_auc:  0.7056 - val_logloss:  0.6991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 47.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "Epoch Time : 3\n",
      "3s - loss:  0.0341 - auc:  0.9972 - logloss:  0.0340 - val_auc:  0.7061 - val_logloss:  0.8405\n"
     ]
    }
   ],
   "source": [
    "epoch = 20\n",
    "batch_size = 300\n",
    "res, pred1 = fit(model, feature_index, optim, metrics, loss_func, x, y, batch_size=batch_size, epochs=epoch, validation_data=(test_model_input1,test_label1),verbose=1, device=device, device_count=device_count)\n",
    "\n",
    "results[model_name] = model, res, pred1, test_label1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Method: DMBGN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DMBGN-AvgPooling\n",
    "Instead of using Higher-order Graph Neural Networks to model user-voucher-item relationships, it directly takes an average of pre-trained item embeddings from user behavior happening both before and after voucher collection. For target UVG, it only takes an average of pre-collection item embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "286735it [00:15, 18552.69it/s]\n"
     ]
    }
   ],
   "source": [
    "def process_pretrain_emb(emb, emb_size = 16, spliter = \" \"):\n",
    "    return np.zeros(emb_size, dtype=np.float32) if emb == 'nan' else np.array(emb.split(spliter), dtype=np.float32)\n",
    "\n",
    "item_df[['atc_emb', 'ord_emb']] = item_df[['atc_emb', 'ord_emb']].astype('str')\n",
    "item_emb_dict = {}\n",
    "for index, row in tqdm(item_df.iterrows()):\n",
    "    item_emb_dict[row['item_id']] = process_pretrain_emb(row['atc_emb']), process_pretrain_emb(row['ord_emb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoderExt transforming...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1118593it [00:51, 21626.99it/s]\n",
      "100%|██████████| 58052/58052 [00:00<00:00, 183708.32it/s]\n",
      "100%|██████████| 58052/58052 [00:00<00:00, 421114.80it/s]\n"
     ]
    }
   ],
   "source": [
    "emb_size = 16\n",
    "sid_emb_dict_tmp = {}\n",
    "\n",
    "session_df['sid_enc'] = label_encoder['session_id'].transform(session_df['session_id'])\n",
    "\n",
    "for index, row in tqdm(session_df.iterrows()):\n",
    "    sid = row['sid_enc']\n",
    "    if sid not in sid_emb_dict_tmp:\n",
    "        sid_emb_dict_tmp[row['sid_enc']] = np.zeros(emb_size, dtype=np.float32), np.zeros(emb_size, dtype=np.float32), 0, 0\n",
    "    \n",
    "    if row['rk'] > 6:\n",
    "        continue\n",
    "    \n",
    "    emb_bef, emb_aft, cnt_bef, cnt_aft = sid_emb_dict_tmp.get(sid)\n",
    "    item_atc_emb, item_ord_emb = item_emb_dict.get(row['item_id'])\n",
    "    if row['type'] == 'bef':\n",
    "        emb_bef += item_atc_emb if row['action_type'] == 'cart' else item_ord_emb\n",
    "        cnt_bef += 1\n",
    "    else:\n",
    "        emb_aft += item_atc_emb if row['action_type'] == 'cart' else item_ord_emb\n",
    "        cnt_aft += 1\n",
    "    sid_emb_dict_tmp[sid] = emb_bef, emb_aft, cnt_bef, cnt_aft\n",
    "\n",
    "sid_emb_dict = {}\n",
    "for sid, value in tqdm(sid_emb_dict_tmp.items()):\n",
    "    emb_bef, emb_aft, cnt_bef, cnt_aft = value\n",
    "    sid_emb_dict[sid] = np.concatenate((emb_bef/(1.0*cnt_bef), emb_aft/(1.0*cnt_aft)), axis=0)\n",
    "\n",
    "sid_emb_dict_bef = {}\n",
    "for sid, value in tqdm(sid_emb_dict_tmp.items()):\n",
    "    emb_bef, emb_aft, cnt_bef, cnt_aft = value\n",
    "    sid_emb_dict_bef[sid] = emb_bef/(1.0*cnt_bef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_emb_ts(emb_dic, requires_grad = False, emb_size = 16, lbe = None):\n",
    "    if lbe is None:\n",
    "        raise Exception(\"Encoder is empty\")\n",
    "        \n",
    "    indices = lbe.transform([str(val) for val in emb_dic.keys()])\n",
    "    session_size = int(len(lbe))\n",
    "    \n",
    "    ts_emb = torch.rand(session_size, emb_size, dtype = torch.float)\n",
    "    for i, (key, emb) in tqdm(enumerate(emb_dic.items())):\n",
    "        ts_emb[indices[i]] = torch.FloatTensor(emb)\n",
    "    emb_ts = torch.nn.Embedding.from_pretrained(ts_emb)\n",
    "    emb_ts.weight.requires_grad = requires_grad\n",
    "    return emb_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoderExt transforming...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "58052it [00:00, 91819.28it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(58052, 32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sid_emb_ts = init_emb_ts(sid_emb_dict, emb_size = 32, lbe=label_encoder['session_id'])\n",
    "sid_emb_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xy_fd(dataset):\n",
    "    print (\"start generating x y data\")\n",
    "    \n",
    "    dnn_feature_columns = []\n",
    "    dnn_feature_columns += [SparseFeat(feat, len(label_encoder[feat]), embedding_dim = embedding_dim1) for feat in ['user_gender','user_age_level','user_purchase_level']]\n",
    "    dnn_feature_columns += [SparseFeat(feat, len(label_encoder['promotion_id']), embedding_dim = embedding_dim2) for feat in ['session_id']]\n",
    "    dnn_feature_columns += [SparseFeat(feat, len(label_encoder[feat]), embedding_dim = embedding_dim2) for feat in ['promotion_id']]\n",
    "    dnn_feature_columns += [SparseFeat(feat, len(label_encoder['session_id']), embedding_dim = embedding_dim1) for feat in ['sid']]\n",
    "    \n",
    "    dnn_feature_columns += [VarLenSparseFeat(SparseFeat('hist_promotion_id', len(label_encoder[\"promotion_id\"]), embedding_dim=embedding_dim2), sequence_size)]\n",
    "    dnn_feature_columns += [VarLenSparseFeat(SparseFeat('hist_session_id', len(label_encoder[\"session_id\"]), embedding_dim=embedding_dim2), sequence_size)]\n",
    "\n",
    "    dnn_feature_columns += [DenseFeat(feat, 1, )  for feat in dense_feature]\n",
    "    dnn_feature_columns += [DenseFeat(feat, 1, )  for feat in ['keys_length']]\n",
    "\n",
    "    feature_names = get_feature_names(dnn_feature_columns)\n",
    "    print (\"feature_names:\", feature_names)\n",
    "    \n",
    "    behavior_feature_list = ['promotion_id', 'session_id']\n",
    "    dataset['sid'] = dataset['session_id']\n",
    "    y, x = gen_dmbgn_input_data(feature_names, dataset, target, label_encoder, 6, sparse_feature, hist_list_features)\n",
    "    x['session_id'] = x['promotion_id']\n",
    "    return x, y, dnn_feature_columns, behavior_feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "start generating x y data\n",
      "feature_names: ['user_gender', 'user_age_level', 'user_purchase_level', 'session_id', 'promotion_id', 'sid', 'hist_promotion_id', 'hist_session_id', 'voucher_min_spend', 'voucher_discount', 'user_trd__orders_cnt_hist', 'user_trd__actual_gmv_usd_hist', 'user_trd__orders_cnt_platform_discount_hist', 'user_trd__max_gmv_usd_hist', 'user_trd__avg_gmv_usd_hist', 'user_trd__min_gmv_usd_hist', 'keys_length']\n",
      "handling hist_list_features Feature: hist_promotion_id\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46361/46361 [00:00<00:00, 92672.55it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoderExt transforming...\n",
      "handling hist_list_features Feature: hist_session_id\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46361/46361 [00:00<00:00, 96228.61it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoderExt transforming...\n",
      "start generating x y data\n",
      "feature_names: ['user_gender', 'user_age_level', 'user_purchase_level', 'session_id', 'promotion_id', 'sid', 'hist_promotion_id', 'hist_session_id', 'voucher_min_spend', 'voucher_discount', 'user_trd__orders_cnt_hist', 'user_trd__actual_gmv_usd_hist', 'user_trd__orders_cnt_platform_discount_hist', 'user_trd__max_gmv_usd_hist', 'user_trd__avg_gmv_usd_hist', 'user_trd__min_gmv_usd_hist', 'keys_length']\n",
      "handling hist_list_features Feature: hist_promotion_id\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11690/11690 [00:00<00:00, 82541.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoderExt transforming...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "handling hist_list_features Feature: hist_session_id\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11690/11690 [00:00<00:00, 91495.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoderExt transforming...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "sequence_size = 6\n",
    "embedding_dim1 = 16 # pid\n",
    "embedding_dim2 = sid_emb_ts.weight.shape[1] #sid\n",
    "print(embedding_dim2)\n",
    "\n",
    "x, y, dnn_feature_columns, behavior_feature_list = get_xy_fd(dctr_train)\n",
    "test_model_input1, test_label1, _, _ = get_xy_fd(dctr_v1)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DMBGN(\n",
       "  (embedding_dict): ModuleDict(\n",
       "    (user_gender): Embedding(4, 16)\n",
       "    (user_age_level): Embedding(10, 16)\n",
       "    (user_purchase_level): Embedding(12, 16)\n",
       "    (session_id): Embedding(462, 32)\n",
       "    (promotion_id): Embedding(462, 32)\n",
       "    (sid): Embedding(58052, 16)\n",
       "    (hist_promotion_id): Embedding(462, 32)\n",
       "    (hist_session_id): Embedding(58052, 32)\n",
       "  )\n",
       "  (linear_model): Linear(\n",
       "    (embedding_dict): ModuleDict()\n",
       "  )\n",
       "  (out): PredictionLayer()\n",
       "  (attention): HistAttentionSeqPoolingLayer(\n",
       "    (local_att): AttentionUnit(\n",
       "      (dnn): DNN(\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (linears): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=64, bias=True)\n",
       "        )\n",
       "        (activation_layers): ModuleList(\n",
       "          (0): PReLU(num_parameters=1)\n",
       "        )\n",
       "      )\n",
       "      (dense): Linear(in_features=64, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (dnn): DNN(\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (linears): ModuleList(\n",
       "      (0): Linear(in_features=209, out_features=128, bias=True)\n",
       "      (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "    )\n",
       "    (bn): ModuleList(\n",
       "      (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (activation_layers): ModuleList(\n",
       "      (0): ReLU(inplace=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (dnn_linear): Linear(in_features=64, out_features=1, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'DMBGN_AvgPooling'\n",
    "\n",
    "model = DMBGN(dnn_feature_columns, \n",
    "            behavior_feature_list, \n",
    "            target_emb_dim_aft=0, \n",
    "            sequence_size=6,\n",
    "            device=device, \n",
    "            att_activation='prelu', \n",
    "            att_weight_normalization=False, \n",
    "            dnn_activation='relu', \n",
    "            l2_reg_dnn=0.1, \n",
    "            l2_reg_embedding = 0.0001, \n",
    "            dnn_hidden_units=(128,64), \n",
    "            att_hidden_size=(64,), \n",
    "            init_std=1, \n",
    "            dnn_dropout=0.5, \n",
    "            dnn_use_bn=True)\n",
    "\n",
    "model.embedding_dict['hist_session_id'] = sid_emb_ts\n",
    "model.embedding_dict['hist_session_id'].requires_grad = False\n",
    "model.embedding_dict['hist_session_id'].weight.requires_grad = False\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.05, amsgrad=True)\n",
    "model.compile(optimizer, 'binary_crossentropy', metrics=['auc', 'logloss'])\n",
    "\n",
    "\n",
    "loss_func = model.loss_func\n",
    "optim = model.optim\n",
    "metrics = model.metrics\n",
    "feature_index = model.feature_index\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_ids = [i for i in range(torch.cuda.device_count())]\n",
    "device_count = len(device_ids)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Use\", device_count, \"GPUs!\")\n",
    "    model = torch.nn.DataParallel(model, device_ids)\n",
    "    \n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 46361 samples, validate on 11690 samples, 155 steps per epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:04, 38.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "Epoch Time : 4\n",
      "4s - loss:  0.5247 - auc:  0.6246 - logloss:  0.4686 - val_auc:  0.7161 - val_logloss:  0.3991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 39.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "Epoch Time : 4\n",
      "4s - loss:  0.4366 - auc:  0.7438 - logloss:  0.3874 - val_auc:  0.7542 - val_logloss:  0.3805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 39.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "Epoch Time : 4\n",
      "4s - loss:  0.4232 - auc:  0.7638 - logloss:  0.3775 - val_auc:  0.7642 - val_logloss:  0.3757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:04, 37.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "Epoch Time : 4\n",
      "4s - loss:  0.4152 - auc:  0.7749 - logloss:  0.3717 - val_auc:  0.7691 - val_logloss:  0.3725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 41.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "Epoch Time : 4\n",
      "4s - loss:  0.4085 - auc:  0.7825 - logloss:  0.3674 - val_auc:  0.7698 - val_logloss:  0.3737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 39.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "Epoch Time : 4\n",
      "4s - loss:  0.4037 - auc:  0.7881 - logloss:  0.3642 - val_auc:  0.7737 - val_logloss:  0.3706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 39.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "Epoch Time : 4\n",
      "4s - loss:  0.3990 - auc:  0.7945 - logloss:  0.3601 - val_auc:  0.7728 - val_logloss:  0.3809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 39.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "Epoch Time : 4\n",
      "4s - loss:  0.3953 - auc:  0.7997 - logloss:  0.3573 - val_auc:  0.7711 - val_logloss:  0.3744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:03, 39.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n",
      "Epoch Time : 4\n",
      "4s - loss:  0.3914 - auc:  0.8039 - logloss:  0.3545 - val_auc:  0.7729 - val_logloss:  0.3761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:04, 38.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n",
      "Epoch Time : 4\n",
      "4s - loss:  0.3878 - auc:  0.8091 - logloss:  0.3522 - val_auc:  0.7746 - val_logloss:  0.3703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:04, 37.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "Epoch Time : 4\n",
      "4s - loss:  0.3841 - auc:  0.8131 - logloss:  0.3487 - val_auc:  0.7730 - val_logloss:  0.3709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:04, 36.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "Epoch Time : 4\n",
      "4s - loss:  0.3818 - auc:  0.8166 - logloss:  0.3468 - val_auc:  0.7769 - val_logloss:  0.3723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:04, 38.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "Epoch Time : 4\n",
      "4s - loss:  0.3775 - auc:  0.8222 - logloss:  0.3425 - val_auc:  0.7721 - val_logloss:  0.3735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:04, 37.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n",
      "Epoch Time : 4\n",
      "4s - loss:  0.3720 - auc:  0.8295 - logloss:  0.3370 - val_auc:  0.7706 - val_logloss:  0.3791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:04, 37.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20\n",
      "Epoch Time : 4\n",
      "4s - loss:  0.3642 - auc:  0.8420 - logloss:  0.3295 - val_auc:  0.7629 - val_logloss:  0.3870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:04, 37.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "Epoch Time : 4\n",
      "4s - loss:  0.3466 - auc:  0.8627 - logloss:  0.3122 - val_auc:  0.7494 - val_logloss:  0.4106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:04, 37.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n",
      "Epoch Time : 4\n",
      "4s - loss:  0.3103 - auc:  0.9003 - logloss:  0.2756 - val_auc:  0.7308 - val_logloss:  0.4587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:04, 37.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20\n",
      "Epoch Time : 4\n",
      "4s - loss:  0.2410 - auc:  0.9494 - logloss:  0.2066 - val_auc:  0.7236 - val_logloss:  0.5424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:04, 36.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n",
      "Epoch Time : 4\n",
      "4s - loss:  0.1621 - auc:  0.9806 - logloss:  0.1273 - val_auc:  0.7061 - val_logloss:  0.7095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:04, 37.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "Epoch Time : 4\n",
      "4s - loss:  0.0978 - auc:  0.9942 - logloss:  0.0630 - val_auc:  0.6987 - val_logloss:  0.8358\n"
     ]
    }
   ],
   "source": [
    "epoch = 20\n",
    "batch_size = 300\n",
    "res, pred1 = fit(model, feature_index, optim, metrics, loss_func, x, y, batch_size=batch_size, epochs=epoch, validation_data=(test_model_input1,test_label1),verbose=1, device=device, device_count=device_count)\n",
    "\n",
    "results[model_name] = model, res, pred1, test_label1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DMBGN-Pretrained\n",
    "It uses the same weight parameters of Higher-order GNN learned during the voucher embedding pre-training as mentioned in Section 3.3. The values of weight parameters are not further updated during the main task training for DMBGN-Pretrained variant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn_session_df = session_df.copy()\n",
    "sid_lbe = LabelEncoderExt()\n",
    "gnn_session_df['session_id'] = sid_lbe.fit_transform(gnn_session_df['session_id'])\n",
    "gnn_session_df = gnn_session_df.fillna(0)\n",
    "gnn_session_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UVG Graphs\n",
    "load the related UVG network into the InMemoryDataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "batch_size= 512\n",
    "\n",
    "geometric_data_path = './data/voucher_geometric/'\n",
    "processed_file_name = 'graph_cache'\n",
    "gnn_dat = VoucherGraphDataset(root=geometric_data_path, processed_file_name=processed_file_name, gnn_session_df=gnn_session_df)\n",
    "\n",
    "data_loader = DataLoader(gnn_dat, batch_size=batch_size)\n",
    "data_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GNN Networks\n",
    "In this section, we first define the User-behavior Voucher Graph (UVG) network with VoucherGraphNet, training the network with loaded dataset data_loader with VoucherGraphDataset and output the generated UVG embedding $e_{UVG}$ with UVG score $s_{UVG}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Pretrained Item Embeddings\n",
    "load the pretrinaed embedding results for atc/ord item into the embedding tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_size = int(len(item_df) * 1.2)\n",
    "emb_size = 16\n",
    "atc_emb_ts = torch.zeros(item_size, emb_size, dtype = torch.double)\n",
    "ord_emb_ts = torch.zeros(item_size, emb_size, dtype = torch.double)\n",
    "\n",
    "for i in tqdm(range(len(item_df))):\n",
    "    item_id = int(item_df['item_id'][i])\n",
    "    idx = hash_func(item_id, item_size)\n",
    "    \n",
    "    if pd.isna(item_df['atc_emb'][i]) is False and len(item_df['atc_emb'][i].split(' ')) > 3:\n",
    "        atc_emb = [float(val) for val in item_df['atc_emb'][i].split(' ')]\n",
    "        atc_emb_ts[idx] = torch.FloatTensor(atc_emb)\n",
    "    \n",
    "    if pd.isna(item_df['ord_emb'][i]) is False and len(item_df['ord_emb'][i].split(' ')) > 3:\n",
    "        ord_emb = [float(val) for val in item_df['ord_emb'][i].split(' ')]\n",
    "        ord_emb_ts[idx] = torch.FloatTensor(ord_emb) \n",
    "        \n",
    "atc_emb_ts = torch.nn.Embedding.from_pretrained(atc_emb_ts)\n",
    "atc_emb_ts.weight.requires_grad = False\n",
    "ord_emb_ts = torch.nn.Embedding.from_pretrained(ord_emb_ts) \n",
    "ord_emb_ts.weight.requires_grad = False\n",
    "\n",
    "atc_emb_ts, ord_emb_ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train GNN\n",
    "train the UVG Graph with Higher-order GNN, the AUC output here repesents the AUC performance using only GNN network, which can be considered as another ablation study. The trained GNN is saved in the ./data/gnet.pretrained_{epochs}.bin file to be loaded for fine-tune later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_features = ['item_id', 'item_category_id', 'item_brand_id', 'item_price_level']\n",
    "promotion_features = ['promotion_id', 'session_id', 'voucher_min_spend', 'voucher_discount_amount']\n",
    "all_features = item_features + promotion_features + ['action_type', 'label']\n",
    "\n",
    "after_prefix = 'a_'\n",
    "before_prefix = 'b_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type(torch.FloatTensor)\n",
    "\n",
    "emb_info = {\n",
    "    'item_category_id': (6000, 1),\n",
    "    'item_price_level': (300, 1),\n",
    "    'promotion_id': (600, int(atc_emb_ts.weight.shape[1])),\n",
    "    'voucher_min_spend': (500, 1),\n",
    "    'voucher_discount_amount': (500, 1),\n",
    "}\n",
    "\n",
    "emb_dict = {\n",
    "    'atc': atc_emb_ts,\n",
    "    'ord': ord_emb_ts,\n",
    "}\n",
    "\n",
    "gnet = VoucherGraphNet(item_features, promotion_features, emb_info, emb_dict, \n",
    "                       gprefix = [before_prefix, after_prefix], gactions = ['atc', 'ord'],\n",
    "                       device=device)\n",
    "gnet = gnet.float().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(gnet.parameters(), lr=0.001)\n",
    "crit = torch.nn.BCELoss()\n",
    "\n",
    "epochs = 3\n",
    "gnn_file = './data/gnet.pretrained_{epochs}.bin'.format(epochs=epochs)\n",
    "\n",
    "train_ready = True if os.path.exists(gnn_file) else False\n",
    "\n",
    "if train_ready is False:\n",
    "    gstep = 0\n",
    "    gnet.train()\n",
    "    loader_cnt = 0\n",
    "    for epoch in range(epochs):\n",
    "        print(\"# Epoch - {epoch}\".format(epoch=epoch))\n",
    "        try:\n",
    "            for dat in tqdm(data_loader):\n",
    "                optimizer.zero_grad()\n",
    "                graph_dicts = dat.graph_dict\n",
    "                out = None\n",
    "                valid_list = []\n",
    "                gstep += 1\n",
    "                for graph_dict in graph_dicts:\n",
    "                    res, promotion_id, emb_promotion, session_id, emb_session_id = gnet(graph_dict)\n",
    "                    if res is None or torch.isnan(res):\n",
    "                        valid_list.append(False)\n",
    "                        continue\n",
    "                    valid_list.append(True)\n",
    "                    out = res if out is None else torch.cat([out, res], dim=0)\n",
    "\n",
    "                pred = out.cpu()\n",
    "                lbe = dat.label.cpu()[valid_list]\n",
    "                loss = crit(pred, lbe)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                if gstep % 25 == 0:\n",
    "                    auc = roc_auc_score(lbe.detach().numpy().ravel(), pred.detach().numpy().ravel())\n",
    "                    print('GNN[{gstep}] - auc {auc}; loss {loss}'.format(auc=auc ,gstep=gstep ,loss=loss))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    torch.save(gnet.state_dict(), gnn_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pretrained GNN network parameter\n",
    "gnet = VoucherGraphNet(item_features, promotion_features, emb_info, emb_dict, \n",
    "                       gprefix = [before_prefix, after_prefix], gactions = ['atc', 'ord'], \n",
    "                       device=device)\n",
    "gnet.load_state_dict(torch.load(gnn_file))\n",
    "gnet = gnet.float().to(device)\n",
    "\n",
    "\n",
    "# Use Before UVG Only\n",
    "gnet_before = VoucherGraphNet(item_features, promotion_features, emb_info, emb_dict, device=device)\n",
    "gnet_before.load_state_dict(torch.load(gnn_file))\n",
    "gnet_before = gnet_before.float().to(device)\n",
    "gnet_before.gprefix = [before_prefix, 'unknown'] \n",
    "\n",
    "gnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Pretrained UVG Embeddings\n",
    "generate pretrained embeddings from UVG network for each UVG. Note here we have gnet and gnet_before which represents UVG including both 'bef' and 'aft' user behaviors and including 'bef' user behaviors only. From the AUC performance output we see that gnet has better performance than gnet_before, which indicates the importance of taking 'aft' user behaviors into consideration. This can be considered as another ablation study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle_protocol = 4\n",
    "\n",
    "gnet.eval()\n",
    "gnet_before.eval()\n",
    "gstep = 0\n",
    "\n",
    "\n",
    "raw_sid_uvg_graphs_dic = {}\n",
    "\n",
    "promotion_emb_dic = {}\n",
    "session_emb_raw_dic = {}\n",
    "session_emb_raw_dic_before = {}\n",
    "\n",
    "gnn_pretrained_emb_file = 'data/gnet.pretrained.{epochs}.emb.pkl'.format(epochs=epochs)\n",
    "\n",
    "gnn_emb_ready = True if os.path.exists(gnn_pretrained_emb_file) else False\n",
    "\n",
    "def hash_func(ts, item_size):\n",
    "    return ts % item_size\n",
    "\n",
    "if gnn_emb_ready is False:\n",
    "    session_emb_dic = {}\n",
    "    sid_uvg_graphs_dic = {}\n",
    "    session_emb_dic_before = {}\n",
    "    for dat in DataLoader(gnn_dat, batch_size=batch_size * 30):\n",
    "        graph_dicts = dat.graph_dict\n",
    "        out = None\n",
    "        out2 = None\n",
    "        valid_list = []\n",
    "        valid_list2 = []\n",
    "        gstep += 1\n",
    "        for graph_dict in graph_dicts :\n",
    "            res, promotion_id, emb_promotion, session_id, emb_session_id = gnet(graph_dict)\n",
    "            res_before, _, _, _, emb_session_id_before = gnet_before(graph_dict)\n",
    "            if res is None or torch.isnan(res):\n",
    "                valid_list.append(False)\n",
    "                continue\n",
    "\n",
    "            valid_list.append(True)\n",
    "            out = res if out is None else torch.cat([out, res], dim=0)\n",
    "\n",
    "            promotion_emb_dic[promotion_id.unsqueeze(0).cpu().detach().numpy()[0]] = emb_promotion.cpu().detach().numpy()\n",
    "            session_emb_dic[session_id.unsqueeze(0).cpu().detach().numpy()[0]] = emb_session_id.cpu().detach().numpy()\n",
    "            sid_uvg_graphs_dic[session_id.unsqueeze(0).cpu().detach().numpy()[0]] = graph_dict\n",
    "            \n",
    "            if res_before is not None or torch.isnan(res) is False:\n",
    "                session_emb_dic_before[session_id.unsqueeze(0).cpu().detach().numpy()[0]] = emb_session_id_before.cpu().detach().numpy()\n",
    "                out2 = res_before if out2 is None else torch.cat([out2, res_before], dim=0)\n",
    "                valid_list2.append(True)\n",
    "            else :\n",
    "                valid_list2.append(False)\n",
    "\n",
    "        try:\n",
    "            lbe = dat.label.cpu()[valid_list]\n",
    "            lbe2 = dat.label.cpu()[valid_list2]\n",
    "            pred = out.cpu()\n",
    "            pred2 = out2.cpu()\n",
    "            loss = crit(pred, lbe)\n",
    "            loss2 = crit(pred2, lbe2)\n",
    "            auc = roc_auc_score(lbe.detach().numpy().ravel(), pred.detach().numpy().ravel())\n",
    "            auc2 = roc_auc_score(lbe2.detach().numpy().ravel(), pred2.detach().numpy().ravel())\n",
    "            print(\"gstep = {gstep}; auc = {auc}; loss = {loss}; auc_before = {auc2} {loss2}\".format(gstep=gstep,\n",
    "                                                                                                    auc=auc, \n",
    "                                                                                                    loss2=loss2,\n",
    "                                                                                                    auc2 =auc2,\n",
    "                                                                                                    loss=loss))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    for key, emb in tqdm(session_emb_dic.items()):\n",
    "        session_emb_raw_dic[sid_lbe.label_encoder.classes_[key]] = emb\n",
    "\n",
    "    # session_emb_raw_dic_before use for target session id with no after behaviors know beforehand\n",
    "    for key, emb in tqdm(session_emb_dic_before.items()):\n",
    "        session_emb_raw_dic_before[sid_lbe.label_encoder.classes_[key]] = emb\n",
    "\n",
    "    for key, uvg in tqdm(sid_uvg_graphs_dic.items()):\n",
    "         raw_sid_uvg_graphs_dic[sid_lbe.label_encoder.classes_[key]] = uvg\n",
    "        \n",
    "    with open(gnn_pretrained_emb_file, 'wb') as f:\n",
    "        pickle.dump(promotion_emb_dic, f, pickle_protocol)\n",
    "        pickle.dump(session_emb_raw_dic, f, pickle_protocol)\n",
    "        pickle.dump(session_emb_raw_dic_before, f, pickle_protocol)\n",
    "        pickle.dump(raw_sid_uvg_graphs_dic, f, pickle_protocol)\n",
    "\n",
    "else :\n",
    "    print('loading existing trained embeddings...')\n",
    "    with open(gnn_pretrained_emb_file, \"rb\") as f:\n",
    "        promotion_emb_dic = pickle.load(f)\n",
    "        session_emb_raw_dic = pickle.load(f)\n",
    "        session_emb_raw_dic_before = pickle.load(f)\n",
    "        raw_sid_uvg_graphs_dic = pickle.load(f)\n",
    "        \n",
    "len(promotion_emb_dic), len(session_emb_raw_dic), len(session_emb_raw_dic_before), len(raw_sid_uvg_graphs_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "labels = []\n",
    "scores = []\n",
    "\n",
    "labels_before = []\n",
    "scores_before = [] \n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "for iii in tqdm(range(len(session_df))):\n",
    "    sid = session_df['session_id'].values[iii]\n",
    "    promotion_id = int(session_df['promotion_id'].values[iii])\n",
    "    label = session_df['label'].values[iii]\n",
    "    \n",
    "    if sid not in session_emb_raw_dic:\n",
    "        continue\n",
    "    \n",
    "    session_emb = session_emb_raw_dic[sid]\n",
    "    promotion_emb = promotion_emb_dic[promotion_id]\n",
    "            \n",
    "    labels.append(label)\n",
    "    score = sigmoid(np.matmul(session_emb, promotion_emb))\n",
    "    scores.append(score)\n",
    "    \n",
    "    if sid in session_emb_raw_dic_before:\n",
    "        session_emb_before = session_emb_raw_dic_before[sid]\n",
    "        score_before = sigmoid(np.matmul(session_emb_before, promotion_emb))\n",
    "        scores_before.append(score_before)\n",
    "        labels_before.append(label)\n",
    "            \n",
    "auc = roc_auc_score(labels, scores)\n",
    "auc_before = roc_auc_score(labels_before, scores_before)\n",
    "len(scores), auc, auc_before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DMBGN Log Processing\n",
    "log processing for DMBGN training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = user_voucher_log.copy()\n",
    "df = df.take(np.random.permutation(len(df)))\n",
    "df['hist_sid'] = df['hist_session_id']\n",
    "\n",
    "sparse_feature = ['promotion_id','session_id','user_gender','user_age_level','user_purchase_level'] #['promotion_id','voucher_min_spend','voucher_discount_amount']\n",
    "\n",
    "hist_list_features = ['hist_promotion_id','hist_sid','keys_length']\n",
    "\n",
    "ignore_features=['hist_session_id', 'dtype','venture','ds','user_id','label','voucher_collect_time','voucher_redeem_time','campaign_name','rk']\n",
    "\n",
    "dense_feature = []\n",
    "train_features = []\n",
    "\n",
    "for feat in df.columns:\n",
    "    if feat in ignore_features:\n",
    "        continue\n",
    "    if feat not in hist_list_features:\n",
    "        train_features.append(feat)\n",
    "    if feat not in hist_list_features and feat not in sparse_feature:\n",
    "        dense_feature.append(feat)\n",
    "\n",
    "target = 'label'\n",
    "df[['session_id','promotion_id','user_gender','user_age_level','user_purchase_level']]=df[['session_id','promotion_id','user_gender','user_age_level','user_purchase_level']].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = {}\n",
    "for feat in sparse_feature:\n",
    "    df[feat] = df[feat].fillna(0)\n",
    "    print(\"lbe {}\".format(feat))\n",
    "    lbe = LabelEncoderExt()\n",
    "    lbe.fit(df[feat])\n",
    "    df[feat] = lbe.transform(df[feat])\n",
    "    label_encoder[feat] = lbe\n",
    "    logging.warn('LabelEncoder encoding ' + feat + \" len \" + str(len(lbe)))\n",
    "    \n",
    "label_encoder['sid'] = label_encoder['session_id']\n",
    "df['sid'] = df['promotion_id']\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_kv = {}\n",
    "std_kv = {}\n",
    "for feat in dense_feature:\n",
    "    print(feat)\n",
    "    mean_kv[feat] = df[feat].mean()\n",
    "    std_kv[feat] = df[feat].std()\n",
    "    df[feat] = (df[feat] - mean_kv[feat]) / std_kv[feat]\n",
    "\n",
    "deep_ctr_df = df \n",
    "dctr_train = deep_ctr_df[deep_ctr_df.dtype == 'train']\n",
    "dctr_v1 = deep_ctr_df[deep_ctr_df.dtype == 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xy_fd(dataset):\n",
    "    print (\"start generating x y data\")\n",
    "    \n",
    "    dnn_feature_columns = []\n",
    "    dnn_feature_columns += [SparseFeat(feat, len(label_encoder[feat]), embedding_dim = embedding_dim1) for feat in ['promotion_id', 'user_gender','user_age_level','user_purchase_level']]\n",
    "    dnn_feature_columns += [SparseFeat(feat, len(label_encoder['promotion_id']), embedding_dim = embedding_dim2) for feat in ['sid']]\n",
    "    \n",
    "    dnn_feature_columns += [VarLenSparseFeat(SparseFeat('hist_promotion_id', len(label_encoder[\"promotion_id\"]), embedding_dim=embedding_dim1), sequence_size)]\n",
    "    dnn_feature_columns += [VarLenSparseFeat(SparseFeat('hist_sid', len(label_encoder[\"sid\"]), embedding_dim=embedding_dim2), sequence_size)]\n",
    "    \n",
    "    dnn_feature_columns += [DenseFeat(feat, 1, )  for feat in dense_feature]\n",
    "    dnn_feature_columns += [DenseFeat(feat, 1, )  for feat in ['keys_length']]\n",
    "\n",
    "    feature_names = get_feature_names(dnn_feature_columns)\n",
    "    print (\"feature_names:\", feature_names)\n",
    "    \n",
    "    behavior_feature_list = ['promotion_id', 'sid']\n",
    "\n",
    "    y, x = gen_dmbgn_input_data(feature_names, dataset, target, label_encoder, 6, sparse_feature, hist_list_features)\n",
    " \n",
    "    return x, y, dnn_feature_columns, behavior_feature_list\n",
    "\n",
    "sequence_size = 6\n",
    "embedding_dim1 = 16 # pid\n",
    "embedding_dim2 = 16 # sid\n",
    "print(embedding_dim2)\n",
    "\n",
    "x, y, dnn_feature_columns, behavior_feature_list = get_xy_fd(dctr_train)\n",
    "test_model_input1, test_label1, _, _ = get_xy_fd(dctr_v1)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_emb_bef_aft_16 = init_emb_ts(session_emb_raw_dic, requires_grad = False, lbe = label_encoder['session_id'])\n",
    "promotion_emb_bef_aft_16 = init_emb_ts(promotion_emb_dic, requires_grad = True, lbe = label_encoder['promotion_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'DMBGN_Pretrained'\n",
    "\n",
    "model = DMBGN(dnn_feature_columns, \n",
    "            behavior_feature_list,\n",
    "            target_emb_dim_aft=0, \n",
    "            sequence_size=6,\n",
    "            device=device, \n",
    "            att_activation='prelu', \n",
    "            att_weight_normalization=False, \n",
    "            dnn_activation='relu', \n",
    "            l2_reg_dnn=0.1, \n",
    "            l2_reg_embedding = 0.0001, \n",
    "            dnn_hidden_units=(128,64), \n",
    "            att_hidden_size=(64,), \n",
    "            init_std=1, \n",
    "            dnn_dropout=0.5, \n",
    "            dnn_use_bn=True)\n",
    "\n",
    "\n",
    "gnn_fine_tune = False\n",
    "model.embedding_dict['hist_promotion_id'] = promotion_emb_bef_aft_16 \n",
    "model.embedding_dict['hist_promotion_id'].requires_grad = gnn_fine_tune\n",
    "model.embedding_dict['hist_promotion_id'].weight.requires_grad = gnn_fine_tune\n",
    "\n",
    "model.embedding_dict['hist_sid'] = session_emb_bef_aft_16\n",
    "model.embedding_dict['hist_sid'].requires_grad = gnn_fine_tune\n",
    "model.embedding_dict['hist_sid'].weight.requires_grad = gnn_fine_tune\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.05, amsgrad=True)\n",
    "model.compile(optimizer, 'binary_crossentropy', metrics=['auc', 'logloss'])\n",
    "\n",
    "\n",
    "loss_func = model.loss_func\n",
    "optim = model.optim\n",
    "metrics = model.metrics\n",
    "feature_index = model.feature_index\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_ids = [i for i in range(torch.cuda.device_count())]\n",
    "device_count = len(device_ids)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Use\", device_count, \"GPUs!\")\n",
    "    model = torch.nn.DataParallel(model, device_ids)\n",
    "    \n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 20\n",
    "batch_size = 300\n",
    "res, pred1 = fit(model, feature_index, optim, metrics, loss_func, x, y, batch_size=batch_size, epochs=epoch, validation_data=(test_model_input1,test_label1),verbose=1, device=device, device_count=device_count)\n",
    "\n",
    "results[model_name] = model, res, pred1, test_label1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DMBGN\n",
    "The proposed model in this work, which loads the pre-trained GNN network including the item and voucher node embeddings. The GNN network parameters are further fine-tuned according to the final training loss. \\\n",
    "Note that it might takes a longer time to train DMBGN as it involves the training of GNN network. In our work, we used multiple GPUs to accerlate the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xy_fd(dataset):\n",
    "    print (\"start generating x y data\")\n",
    "    \n",
    "    dnn_feature_columns = []\n",
    "    dnn_feature_columns += [SparseFeat(feat, len(label_encoder[feat]), embedding_dim = embedding_dim1) for feat in ['promotion_id', 'user_gender','user_age_level','user_purchase_level']]\n",
    "    dnn_feature_columns += [SparseFeat(feat, len(label_encoder['promotion_id']), embedding_dim = embedding_dim2) for feat in ['sid']]\n",
    "    dnn_feature_columns += [SparseFeat(feat, len(label_encoder[feat]), embedding_dim = 1) for feat in ['session_id']]\n",
    "    \n",
    "    dnn_feature_columns += [VarLenSparseFeat(SparseFeat('hist_promotion_id', len(label_encoder[\"promotion_id\"]), embedding_dim=embedding_dim1), sequence_size)]\n",
    "    dnn_feature_columns += [VarLenSparseFeat(SparseFeat('hist_sid', len(label_encoder[\"sid\"]), embedding_dim=embedding_dim2), sequence_size)]\n",
    "    \n",
    "    dnn_feature_columns += [DenseFeat(feat, 1, )  for feat in dense_feature]\n",
    "    dnn_feature_columns += [DenseFeat(feat, 1, )  for feat in ['keys_length']]\n",
    "\n",
    "    feature_names = get_feature_names(dnn_feature_columns)\n",
    "    print (\"feature_names:\", feature_names)\n",
    "    \n",
    "    behavior_feature_list = ['promotion_id', 'sid']\n",
    "\n",
    "    y, x = gen_dmbgn_input_data(feature_names, dataset, target, label_encoder, 6, sparse_feature, hist_list_features)\n",
    " \n",
    "    return x, y, dnn_feature_columns, behavior_feature_list\n",
    "\n",
    "sequence_size = 6\n",
    "embedding_dim1 = 16 # pid\n",
    "embedding_dim2 = 16 # sid\n",
    "print(embedding_dim2)\n",
    "\n",
    "x, y, dnn_feature_columns, behavior_feature_list = get_xy_fd(dctr_train)\n",
    "test_model_input1, test_label1, _, _ = get_xy_fd(dctr_v1)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_emb_bef_aft_16 = init_emb_ts(session_emb_raw_dic, requires_grad = False, lbe = label_encoder['session_id'])\n",
    "promotion_emb_bef_aft_16 = init_emb_ts(promotion_emb_dic, requires_grad = True, lbe = label_encoder['promotion_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_sid_uvg_graphs_dic = {}\n",
    "hash_sids = label_encoder['session_id'].transform([str(val) for val in raw_sid_uvg_graphs_dic.keys()])\n",
    "for i, (key, uvgs) in tqdm(enumerate(raw_sid_uvg_graphs_dic.items())):\n",
    "    hash_sid_uvg_graphs_dic[hash_sids[i]] = uvgs\n",
    "\n",
    "len(hash_sid_uvg_graphs_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'DMBGN'\n",
    "\n",
    "model = DMBGN(dnn_feature_columns, \n",
    "              behavior_feature_list,\n",
    "              target_emb_dim_aft=0, \n",
    "              sequence_size=6,\n",
    "              device=device, \n",
    "              att_activation='prelu', \n",
    "              att_weight_normalization=False, \n",
    "              dnn_activation='relu', \n",
    "              l2_reg_dnn=0.1, \n",
    "              l2_reg_embedding = 0.0001, \n",
    "              dnn_hidden_units=(128,64), \n",
    "              att_hidden_size=(64,), \n",
    "              init_std=1, \n",
    "              dnn_dropout=0.5, \n",
    "              dnn_use_bn=True,\n",
    "              gnet_tune=True,\n",
    "              hist_gnn_dropout=0.6, \n",
    "              gnet=gnet, \n",
    "              gnet_before=gnet_before,\n",
    "              hash_sid_uvg_graphs_dic=hash_sid_uvg_graphs_dic)\n",
    "\n",
    "\n",
    "zeros = torch.zeros(len(label_encoder['session_id']), 1, dtype = torch.float)\n",
    "model.embedding_dict['session_id'] = torch.nn.Embedding.from_pretrained(zeros)\n",
    "model.embedding_dict['session_id'].requires_grad = False\n",
    "model.embedding_dict['session_id'].weight.requires_grad = False\n",
    "\n",
    "model.embedding_dict['hist_promotion_id'] = promotion_emb_bef_aft_16\n",
    "model.embedding_dict['hist_promotion_id'].requires_grad = False\n",
    "model.embedding_dict['hist_promotion_id'].weight.requires_grad = False\n",
    "\n",
    "model.embedding_dict['hist_sid'] = session_emb_bef_aft_16\n",
    "model.embedding_dict['hist_sid'].requires_grad = False\n",
    "model.embedding_dict['hist_sid'].weight.requires_grad = False\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.05, amsgrad=True)\n",
    "model.compile(optimizer, 'binary_crossentropy', metrics=['auc', 'logloss'])\n",
    "\n",
    "\n",
    "loss_func = model.loss_func\n",
    "optim = model.optim\n",
    "metrics = model.metrics\n",
    "feature_index = model.feature_index\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_ids = [i for i in range(torch.cuda.device_count())]\n",
    "device_count = len(device_ids)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model = torch.nn.DataParallel(model, device_ids)\n",
    "    \n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 20\n",
    "batch_size = 300\n",
    "res, pred1 = fit(model, feature_index, optim, metrics, loss_func, x, y, batch_size=batch_size, epochs=epoch, validation_data=(test_model_input1,test_label1),verbose=1, device=device, device_count=device_count)\n",
    "\n",
    "results[model_name] = model, res, pred1, test_label1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "i = 0\n",
    "lw = 1\n",
    "\n",
    "colors = [\"cornflowerblue\", \"darkorange\", \"red\", \"blue\", \"green\", \"violet\", \"black\", \"purple\", \"olive\", \"cyan\"]\n",
    "\n",
    "\n",
    "for model_name, (model, res, pred1, test_label1) in results.items():\n",
    "    fpr[i], tpr[i], _ = roc_curve(test_label1.astype(int),  pred1)\n",
    "    roc_auc = auc(fpr[i], tpr[i])\n",
    "    plt.plot(fpr[i], tpr[i], color=colors[i], lw=lw, label = model_name + ' ROC curve (area = ' + str(round(roc_auc, 4)) + ')')\n",
    "\n",
    "    i += 1\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    \n",
    "plt.title('User-Voucher Redemption Dataset ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relaImpr(a, b):\n",
    "    x = ((a-0.5)/(b-0.5) - 1.0)*100.0\n",
    "    return str(\"%.2f\" % x) + '%'\n",
    "\n",
    "dnn_auc = results['DNN'][1]['eval_auc']\n",
    "din_auc = results['DIN'][1]['eval_auc']\n",
    "\n",
    "table = PrettyTable(['Model','AUC','RelaImpr(DNN)','RelaImpr(DIN)', 'Logloss'], digits = 4, rounds=True)\n",
    "for model_name, (model, res, pred1, test_label1) in results.items():\n",
    "    table.add_row([model_name, \"%.4f\" % res['eval_auc'], relaImpr(res['eval_auc'], dnn_auc), relaImpr(res['eval_auc'], din_auc), \"%.4f\" % res['eval_logloss']])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that xgBoost has a higher AUC compared to DNN and WDL, mainly due to the small sample size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [1] H Brendan McMahan, Gary Holt, David Sculley, Michael Young, Dietmar Ebner,Julian Grady, Lan Nie, Todd Phillips, Eugene Davydov, Daniel Golovin, et al.2013.  Ad click prediction: a view from the trenches. InProceedings of the 19thACM SIGKDD international conference on Knowledge discovery and data mining.1222–1230.\n",
    "- [2] Guolin Ke, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma,Qiwei Ye, and Tie-Yan Liu. 2017. Lightgbm: A highly efficient gradient boostingdecision tree.Advances in neural information processing systems30 (2017), 3146–3154.\n",
    "- [3] Heng-Tze Cheng, Levent Koc, Jeremiah Harmsen, Tal Shaked, Tushar Chandra,Hrishi Aradhye, Glen Anderson, Greg Corrado, Wei Chai, Mustafa Ispir, RohanAnil, Zakaria Haque, Lichan Hong, Vihan Jain, Xiaobing Liu, and Hemal Shah.2016. Wide & Deep Learning for Recommender Systems.CoRRabs/1606.07792(2016). arXiv:1606.07792  http://arxiv.org/abs/1606.07792 .\n",
    "- [4] Guorui Zhou, Xiaoqiang Zhu, Chenru Song, Ying Fan, Han Zhu, Xiao Ma, YanghuiYan, Junqi Jin, Han Li, and Kun Gai. 2018. Deep interest network for click-throughrate prediction. InProceedings of the 24th ACM SIGKDD International Conferenceon Knowledge Discovery & Data Mining. 1059–1068."
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "dmbgn",
   "name": "pytorch-gpu.1-11.m94",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-11:m94"
  },
  "kernelspec": {
   "display_name": "dmbgn",
   "language": "python",
   "name": "dmbgn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "304.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
