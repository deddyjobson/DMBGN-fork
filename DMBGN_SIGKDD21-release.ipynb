{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Public code for submitted paper \"DMBGN: Deep Multi-Behavior Graph Networks for Voucher Redemption Rate Prediction\" for SIGKDD 2021. This code covers the experimental results in Chapter 5 in the submitted paper. Note that the following experiments are conducted on a randomly desensitized sampled dataset from original dataset (Region C) mentioned in the paper, all related id features are hashed for public use.\n",
    "\n",
    "This notebook is organized into 4 parts:\n",
    "1. Data Processing: generate the training data from the original log table (for log description, please refer to README.md file under ./data directory\n",
    "2. Baseline Models: corresponding to 5 baseline models compared in the submitted paper, including LR, GBDT, DNN, WDL and DIN model.\n",
    "3. Proposed Method: DMBGN: our proposed model, which includes experiment 2 variants of DMBGN (AvgPooling and Pretrained) with our final model DMBGN\n",
    "4. Summary: a summary of experiment results\n",
    "\n",
    "Note that you can run all codes directly for all the results. For DMBGN it might takes a longer time and we used 8 GPUs for accerlation purpose,\n",
    "\n",
    "Author: \\\n",
    "    Lin Li (boolean.ll@alibaba-inc.com) \\\n",
    "    Fengtong Xiao (fengtong.xiao@alibaba-inc.com) \\\n",
    "    Weinan Xu (stella.xu@lazada.com)\n",
    "\n",
    "References: \\\n",
    "    DMBGN: Deep Multi-Behavior Graph Networks for Voucher Redemption Rate Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:70% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-28 11:47:47,082 [WARNING]: \n",
      "DeepCTR-PyTorch version 0.2.5 detected. Your version is 0.2.3.\n",
      "Use `pip install -U deepctr-torch` to upgrade.Changelog: https://github.com/shenweichen/DeepCTR-Torch/releases/tag/v0.2.5\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:70% !important; }</style>\"))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandasql as ps\n",
    "\n",
    "import warnings\n",
    "import logging\n",
    "import sys\n",
    "import pickle\n",
    "import csv\n",
    "import os\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "import torch\n",
    "from deepctr_torch.inputs import SparseFeat, DenseFeat,VarLenSparseFeat, get_feature_names\n",
    "from deepctr_torch.models import *\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.setrecursionlimit(9000000) \n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s]: %(message)s')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from models.util import *\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_device(idx=0):\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    return device\n",
    "device_count = torch.cuda.device_count()\n",
    "device = get_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((62068, 19), (1118593, 14), (286735, 6))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the pickle file, note you might need to unzip the kdd_data.pkl.zip to recover the pkl file\n",
    "# To unzip, use the following command line:\n",
    "# $ cd ./data\n",
    "# $ unzip kdd_data.pkl.zip\n",
    "\n",
    "file_path = './data/kdd_data.pkl'\n",
    "with open(file_path, \"rb\") as f:\n",
    "    log_df = pickle.load(f)\n",
    "    session_df = pickle.load(f)\n",
    "    item_df = pickle.load(f)\n",
    "log_df.shape, session_df.shape, item_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Logs Processing\n",
    "construct the historical UVG sequence following the chronological order \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>label</th>\n",
       "      <th>user_id</th>\n",
       "      <th>promotion_id</th>\n",
       "      <th>voucher_min_spend</th>\n",
       "      <th>voucher_discount</th>\n",
       "      <th>voucher_collect_time</th>\n",
       "      <th>voucher_redeem_time</th>\n",
       "      <th>campaign_name</th>\n",
       "      <th>user_age_level</th>\n",
       "      <th>user_gender</th>\n",
       "      <th>user_purchase_level</th>\n",
       "      <th>user_trd__orders_cnt_hist</th>\n",
       "      <th>user_trd__actual_gmv_usd_hist</th>\n",
       "      <th>user_trd__orders_cnt_platform_discount_hist</th>\n",
       "      <th>user_trd__max_gmv_usd_hist</th>\n",
       "      <th>user_trd__avg_gmv_usd_hist</th>\n",
       "      <th>user_trd__min_gmv_usd_hist</th>\n",
       "      <th>dtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12130_38</td>\n",
       "      <td>1</td>\n",
       "      <td>12130</td>\n",
       "      <td>38</td>\n",
       "      <td>888</td>\n",
       "      <td>80</td>\n",
       "      <td>14363</td>\n",
       "      <td>28292</td>\n",
       "      <td>C3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>706.648652</td>\n",
       "      <td>4.0</td>\n",
       "      <td>79.950388</td>\n",
       "      <td>11.584404</td>\n",
       "      <td>0.827519</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12130_85</td>\n",
       "      <td>0</td>\n",
       "      <td>12130</td>\n",
       "      <td>85</td>\n",
       "      <td>4999</td>\n",
       "      <td>500</td>\n",
       "      <td>49983</td>\n",
       "      <td>49983</td>\n",
       "      <td>C2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>822.218764</td>\n",
       "      <td>9.0</td>\n",
       "      <td>60.165341</td>\n",
       "      <td>8.747008</td>\n",
       "      <td>0.601405</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12156_64</td>\n",
       "      <td>0</td>\n",
       "      <td>12156</td>\n",
       "      <td>64</td>\n",
       "      <td>7799</td>\n",
       "      <td>700</td>\n",
       "      <td>21441</td>\n",
       "      <td>21441</td>\n",
       "      <td>C3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>349.797257</td>\n",
       "      <td>4.0</td>\n",
       "      <td>118.703723</td>\n",
       "      <td>8.531640</td>\n",
       "      <td>0.928380</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12156_91</td>\n",
       "      <td>1</td>\n",
       "      <td>12156</td>\n",
       "      <td>91</td>\n",
       "      <td>799</td>\n",
       "      <td>80</td>\n",
       "      <td>46418</td>\n",
       "      <td>52254</td>\n",
       "      <td>C2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>793.370613</td>\n",
       "      <td>7.0</td>\n",
       "      <td>215.294128</td>\n",
       "      <td>7.778143</td>\n",
       "      <td>0.517295</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12156_310</td>\n",
       "      <td>1</td>\n",
       "      <td>12156</td>\n",
       "      <td>310</td>\n",
       "      <td>349</td>\n",
       "      <td>30</td>\n",
       "      <td>121387</td>\n",
       "      <td>131549</td>\n",
       "      <td>C1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>842.410759</td>\n",
       "      <td>8.0</td>\n",
       "      <td>215.294128</td>\n",
       "      <td>7.589286</td>\n",
       "      <td>0.517295</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62063</th>\n",
       "      <td>11873_319</td>\n",
       "      <td>0</td>\n",
       "      <td>11873</td>\n",
       "      <td>319</td>\n",
       "      <td>1999</td>\n",
       "      <td>200</td>\n",
       "      <td>120575</td>\n",
       "      <td>120575</td>\n",
       "      <td>C1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>884.002906</td>\n",
       "      <td>16.0</td>\n",
       "      <td>260.133633</td>\n",
       "      <td>21.047688</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62064</th>\n",
       "      <td>11873_305</td>\n",
       "      <td>1</td>\n",
       "      <td>11873</td>\n",
       "      <td>305</td>\n",
       "      <td>4999</td>\n",
       "      <td>500</td>\n",
       "      <td>120576</td>\n",
       "      <td>131797</td>\n",
       "      <td>C1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>884.002906</td>\n",
       "      <td>16.0</td>\n",
       "      <td>260.133633</td>\n",
       "      <td>21.047688</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62065</th>\n",
       "      <td>11879_159</td>\n",
       "      <td>0</td>\n",
       "      <td>11879</td>\n",
       "      <td>159</td>\n",
       "      <td>799</td>\n",
       "      <td>70</td>\n",
       "      <td>72071</td>\n",
       "      <td>72071</td>\n",
       "      <td>C0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>340.424720</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.094769</td>\n",
       "      <td>28.368727</td>\n",
       "      <td>3.595659</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62066</th>\n",
       "      <td>11880_38</td>\n",
       "      <td>0</td>\n",
       "      <td>11880</td>\n",
       "      <td>38</td>\n",
       "      <td>888</td>\n",
       "      <td>80</td>\n",
       "      <td>3867</td>\n",
       "      <td>4451</td>\n",
       "      <td>C3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>5085.468023</td>\n",
       "      <td>24.0</td>\n",
       "      <td>501.537557</td>\n",
       "      <td>14.009554</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62067</th>\n",
       "      <td>11880_454</td>\n",
       "      <td>0</td>\n",
       "      <td>11880</td>\n",
       "      <td>454</td>\n",
       "      <td>799</td>\n",
       "      <td>70</td>\n",
       "      <td>125362</td>\n",
       "      <td>125362</td>\n",
       "      <td>C1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>7470.998268</td>\n",
       "      <td>34.0</td>\n",
       "      <td>501.537557</td>\n",
       "      <td>14.852879</td>\n",
       "      <td>0.094030</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62068 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      session_id  label user_id promotion_id  voucher_min_spend  \\\n",
       "0       12130_38      1   12130           38                888   \n",
       "1       12130_85      0   12130           85               4999   \n",
       "2       12156_64      0   12156           64               7799   \n",
       "3       12156_91      1   12156           91                799   \n",
       "4      12156_310      1   12156          310                349   \n",
       "...          ...    ...     ...          ...                ...   \n",
       "62063  11873_319      0   11873          319               1999   \n",
       "62064  11873_305      1   11873          305               4999   \n",
       "62065  11879_159      0   11879          159                799   \n",
       "62066   11880_38      0   11880           38                888   \n",
       "62067  11880_454      0   11880          454                799   \n",
       "\n",
       "       voucher_discount voucher_collect_time voucher_redeem_time  \\\n",
       "0                    80                14363               28292   \n",
       "1                   500                49983               49983   \n",
       "2                   700                21441               21441   \n",
       "3                    80                46418               52254   \n",
       "4                    30               121387              131549   \n",
       "...                 ...                  ...                 ...   \n",
       "62063               200               120575              120575   \n",
       "62064               500               120576              131797   \n",
       "62065                70                72071               72071   \n",
       "62066                80                 3867                4451   \n",
       "62067                70               125362              125362   \n",
       "\n",
       "      campaign_name  user_age_level user_gender  user_purchase_level  \\\n",
       "0                C3             5.0           1                  8.0   \n",
       "1                C2             5.0           1                  8.0   \n",
       "2                C3             4.0           0                  9.0   \n",
       "3                C2             4.0           0                  9.0   \n",
       "4                C1             4.0           0                  9.0   \n",
       "...             ...             ...         ...                  ...   \n",
       "62063            C1             2.0           1                  9.0   \n",
       "62064            C1             2.0           1                  9.0   \n",
       "62065            C0             4.0           0                  8.0   \n",
       "62066            C3             2.0           1                  9.0   \n",
       "62067            C1             2.0           1                  9.0   \n",
       "\n",
       "       user_trd__orders_cnt_hist  user_trd__actual_gmv_usd_hist  \\\n",
       "0                           52.0                     706.648652   \n",
       "1                           69.0                     822.218764   \n",
       "2                           26.0                     349.797257   \n",
       "3                           61.0                     793.370613   \n",
       "4                           65.0                     842.410759   \n",
       "...                          ...                            ...   \n",
       "62063                       18.0                     884.002906   \n",
       "62064                       18.0                     884.002906   \n",
       "62065                       10.0                     340.424720   \n",
       "62066                      169.0                    5085.468023   \n",
       "62067                      214.0                    7470.998268   \n",
       "\n",
       "       user_trd__orders_cnt_platform_discount_hist  \\\n",
       "0                                              4.0   \n",
       "1                                              9.0   \n",
       "2                                              4.0   \n",
       "3                                              7.0   \n",
       "4                                              8.0   \n",
       "...                                            ...   \n",
       "62063                                         16.0   \n",
       "62064                                         16.0   \n",
       "62065                                          1.0   \n",
       "62066                                         24.0   \n",
       "62067                                         34.0   \n",
       "\n",
       "       user_trd__max_gmv_usd_hist  user_trd__avg_gmv_usd_hist  \\\n",
       "0                       79.950388                   11.584404   \n",
       "1                       60.165341                    8.747008   \n",
       "2                      118.703723                    8.531640   \n",
       "3                      215.294128                    7.778143   \n",
       "4                      215.294128                    7.589286   \n",
       "...                           ...                         ...   \n",
       "62063                  260.133633                   21.047688   \n",
       "62064                  260.133633                   21.047688   \n",
       "62065                   53.094769                   28.368727   \n",
       "62066                  501.537557                   14.009554   \n",
       "62067                  501.537557                   14.852879   \n",
       "\n",
       "       user_trd__min_gmv_usd_hist  dtype  \n",
       "0                        0.827519  train  \n",
       "1                        0.601405   test  \n",
       "2                        0.928380   test  \n",
       "3                        0.517295   test  \n",
       "4                        0.517295  train  \n",
       "...                           ...    ...  \n",
       "62063                    0.000000  train  \n",
       "62064                    0.000000  train  \n",
       "62065                    3.595659   test  \n",
       "62066                    0.000000  train  \n",
       "62067                    0.094030   test  \n",
       "\n",
       "[62068 rows x 19 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = \"select *, ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY voucher_collect_time ASC) as rk from {logdf}\".format(logdf=\"log_df\")\n",
    "log_df = ps.sqldf(q1, locals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>label</th>\n",
       "      <th>user_id</th>\n",
       "      <th>promotion_id</th>\n",
       "      <th>voucher_min_spend</th>\n",
       "      <th>voucher_discount</th>\n",
       "      <th>voucher_collect_time</th>\n",
       "      <th>voucher_redeem_time</th>\n",
       "      <th>campaign_name</th>\n",
       "      <th>user_age_level</th>\n",
       "      <th>...</th>\n",
       "      <th>user_trd__orders_cnt_platform_discount_hist</th>\n",
       "      <th>user_trd__max_gmv_usd_hist</th>\n",
       "      <th>user_trd__avg_gmv_usd_hist</th>\n",
       "      <th>user_trd__min_gmv_usd_hist</th>\n",
       "      <th>dtype</th>\n",
       "      <th>rk</th>\n",
       "      <th>hist_session_id</th>\n",
       "      <th>hist_promotion_id</th>\n",
       "      <th>hist_rk</th>\n",
       "      <th>hist_voucher_collect_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>299</td>\n",
       "      <td>30</td>\n",
       "      <td>45451</td>\n",
       "      <td>45521</td>\n",
       "      <td>C2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.376755</td>\n",
       "      <td>3.917888</td>\n",
       "      <td>2.518198</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_425</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>425</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>100489</td>\n",
       "      <td>132869</td>\n",
       "      <td>C1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.976711</td>\n",
       "      <td>8.408431</td>\n",
       "      <td>0.739039</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10_82</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>82</td>\n",
       "      <td>299</td>\n",
       "      <td>30</td>\n",
       "      <td>46827</td>\n",
       "      <td>48182</td>\n",
       "      <td>C2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.972645</td>\n",
       "      <td>3.039102</td>\n",
       "      <td>1.498169</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100_310</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>310</td>\n",
       "      <td>349</td>\n",
       "      <td>30</td>\n",
       "      <td>119095</td>\n",
       "      <td>119095</td>\n",
       "      <td>C1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>397.755770</td>\n",
       "      <td>18.069456</td>\n",
       "      <td>0.003525</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000_386</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>386</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>96836</td>\n",
       "      <td>96836</td>\n",
       "      <td>C1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81612</th>\n",
       "      <td>6777_368</td>\n",
       "      <td>0</td>\n",
       "      <td>6777</td>\n",
       "      <td>368</td>\n",
       "      <td>1500</td>\n",
       "      <td>150</td>\n",
       "      <td>99368</td>\n",
       "      <td>99368</td>\n",
       "      <td>C1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>39.0</td>\n",
       "      <td>93.471440</td>\n",
       "      <td>7.566445</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>train</td>\n",
       "      <td>102</td>\n",
       "      <td>6777_248</td>\n",
       "      <td>248</td>\n",
       "      <td>79</td>\n",
       "      <td>74788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81613</th>\n",
       "      <td>6777_314</td>\n",
       "      <td>1</td>\n",
       "      <td>6777</td>\n",
       "      <td>314</td>\n",
       "      <td>199</td>\n",
       "      <td>30</td>\n",
       "      <td>99368</td>\n",
       "      <td>131246</td>\n",
       "      <td>C1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>39.0</td>\n",
       "      <td>93.471440</td>\n",
       "      <td>7.566445</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>train</td>\n",
       "      <td>103</td>\n",
       "      <td>6777_138</td>\n",
       "      <td>138</td>\n",
       "      <td>42</td>\n",
       "      <td>39379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81614</th>\n",
       "      <td>6777_314</td>\n",
       "      <td>1</td>\n",
       "      <td>6777</td>\n",
       "      <td>314</td>\n",
       "      <td>199</td>\n",
       "      <td>30</td>\n",
       "      <td>99368</td>\n",
       "      <td>131246</td>\n",
       "      <td>C1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>39.0</td>\n",
       "      <td>93.471440</td>\n",
       "      <td>7.566445</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>train</td>\n",
       "      <td>103</td>\n",
       "      <td>6777_206</td>\n",
       "      <td>206</td>\n",
       "      <td>57</td>\n",
       "      <td>59004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81615</th>\n",
       "      <td>6777_314</td>\n",
       "      <td>1</td>\n",
       "      <td>6777</td>\n",
       "      <td>314</td>\n",
       "      <td>199</td>\n",
       "      <td>30</td>\n",
       "      <td>99368</td>\n",
       "      <td>131246</td>\n",
       "      <td>C1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>39.0</td>\n",
       "      <td>93.471440</td>\n",
       "      <td>7.566445</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>train</td>\n",
       "      <td>103</td>\n",
       "      <td>6777_215</td>\n",
       "      <td>215</td>\n",
       "      <td>67</td>\n",
       "      <td>64992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81616</th>\n",
       "      <td>6777_314</td>\n",
       "      <td>1</td>\n",
       "      <td>6777</td>\n",
       "      <td>314</td>\n",
       "      <td>199</td>\n",
       "      <td>30</td>\n",
       "      <td>99368</td>\n",
       "      <td>131246</td>\n",
       "      <td>C1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>39.0</td>\n",
       "      <td>93.471440</td>\n",
       "      <td>7.566445</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>train</td>\n",
       "      <td>103</td>\n",
       "      <td>6777_248</td>\n",
       "      <td>248</td>\n",
       "      <td>79</td>\n",
       "      <td>74788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81617 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      session_id  label user_id promotion_id  voucher_min_spend  \\\n",
       "0           0_82      0       0           82                299   \n",
       "1          1_425      0       1          425                 40   \n",
       "2          10_82      0      10           82                299   \n",
       "3        100_310      0     100          310                349   \n",
       "4       1000_386      0    1000          386                  0   \n",
       "...          ...    ...     ...          ...                ...   \n",
       "81612   6777_368      0    6777          368               1500   \n",
       "81613   6777_314      1    6777          314                199   \n",
       "81614   6777_314      1    6777          314                199   \n",
       "81615   6777_314      1    6777          314                199   \n",
       "81616   6777_314      1    6777          314                199   \n",
       "\n",
       "       voucher_discount voucher_collect_time voucher_redeem_time  \\\n",
       "0                    30                45451               45521   \n",
       "1                     4               100489              132869   \n",
       "2                    30                46827               48182   \n",
       "3                    30               119095              119095   \n",
       "4                    60                96836               96836   \n",
       "...                 ...                  ...                 ...   \n",
       "81612               150                99368               99368   \n",
       "81613                30                99368              131246   \n",
       "81614                30                99368              131246   \n",
       "81615                30                99368              131246   \n",
       "81616                30                99368              131246   \n",
       "\n",
       "      campaign_name  user_age_level  ...  \\\n",
       "0                C2             4.0  ...   \n",
       "1                C1             0.0  ...   \n",
       "2                C2             NaN  ...   \n",
       "3                C1             3.0  ...   \n",
       "4                C1             3.0  ...   \n",
       "...             ...             ...  ...   \n",
       "81612            C1             4.0  ...   \n",
       "81613            C1             4.0  ...   \n",
       "81614            C1             4.0  ...   \n",
       "81615            C1             4.0  ...   \n",
       "81616            C1             4.0  ...   \n",
       "\n",
       "      user_trd__orders_cnt_platform_discount_hist  user_trd__max_gmv_usd_hist  \\\n",
       "0                                             0.0                    6.376755   \n",
       "1                                             1.0                   27.976711   \n",
       "2                                             0.0                    4.972645   \n",
       "3                                            40.0                  397.755770   \n",
       "4                                             0.0                    0.000000   \n",
       "...                                           ...                         ...   \n",
       "81612                                        39.0                   93.471440   \n",
       "81613                                        39.0                   93.471440   \n",
       "81614                                        39.0                   93.471440   \n",
       "81615                                        39.0                   93.471440   \n",
       "81616                                        39.0                   93.471440   \n",
       "\n",
       "       user_trd__avg_gmv_usd_hist  user_trd__min_gmv_usd_hist  dtype   rk  \\\n",
       "0                        3.917888                    2.518198  train    1   \n",
       "1                        8.408431                    0.739039  train    1   \n",
       "2                        3.039102                    1.498169  train    1   \n",
       "3                       18.069456                    0.003525  train    1   \n",
       "4                        0.000000                    0.000000  train    1   \n",
       "...                           ...                         ...    ...  ...   \n",
       "81612                    7.566445                    0.000000  train  102   \n",
       "81613                    7.566445                    0.000000  train  103   \n",
       "81614                    7.566445                    0.000000  train  103   \n",
       "81615                    7.566445                    0.000000  train  103   \n",
       "81616                    7.566445                    0.000000  train  103   \n",
       "\n",
       "       hist_session_id  hist_promotion_id hist_rk  hist_voucher_collect_time  \n",
       "0                                                                       None  \n",
       "1                                                                       None  \n",
       "2                                                                       None  \n",
       "3                                                                       None  \n",
       "4                                                                       None  \n",
       "...                ...                ...     ...                        ...  \n",
       "81612         6777_248                248      79                      74788  \n",
       "81613         6777_138                138      42                      39379  \n",
       "81614         6777_206                206      57                      59004  \n",
       "81615         6777_215                215      67                      64992  \n",
       "81616         6777_248                248      79                      74788  \n",
       "\n",
       "[81617 rows x 24 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = \" SELECT L.* \\\n",
    "            , coalesce(R.session_id, '') AS hist_session_id \\\n",
    "            , coalesce(R.promotion_id, '') AS hist_promotion_id \\\n",
    "            , coalesce(R.rk, '') AS hist_rk \\\n",
    "            , R.voucher_collect_time AS hist_voucher_collect_time \\\n",
    "        FROM {df} L \\\n",
    "        LEFT JOIN {df} R \\\n",
    "        ON L.user_id = R.user_id \\\n",
    "        AND L.session_id != R.session_id \\\n",
    "        AND L.campaign_name != R.campaign_name \\\n",
    "        AND R.label = 1 \\\n",
    "        AND L.rk > R.rk \\\n",
    "        ORDER BY L.rk ASC, R.rk ASC\".format(df='log_df')\n",
    "log_df_tmp = ps.sqldf(sql, locals())\n",
    "log_df_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_voucher_log = log_df_tmp.groupby([ 'session_id', 'label', 'user_id', 'promotion_id', 'voucher_min_spend', \n",
    "                       'voucher_discount', 'voucher_collect_time', 'voucher_redeem_time',\n",
    "                       'user_age_level', 'user_gender', 'user_purchase_level',\n",
    "                       'user_trd__orders_cnt_hist', 'user_trd__actual_gmv_usd_hist',\n",
    "                       'user_trd__orders_cnt_platform_discount_hist',\n",
    "                       'user_trd__max_gmv_usd_hist', 'user_trd__avg_gmv_usd_hist',\n",
    "                       'user_trd__min_gmv_usd_hist', 'dtype']) \\\n",
    "                .agg({'hist_session_id': lambda x: \"%s\" % ','.join(x),\n",
    "                      'hist_promotion_id': lambda x: \"%s\" % ','.join(x),\n",
    "                      'hist_rk': lambda x: list(x),\n",
    "                      'hist_voucher_collect_time': \"count\"}).reset_index()\n",
    "\n",
    "user_voucher_log['keys_length'] = user_voucher_log['hist_voucher_collect_time']\n",
    "user_voucher_log = user_voucher_log.drop(columns=['hist_rk', 'hist_voucher_collect_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>label</th>\n",
       "      <th>user_id</th>\n",
       "      <th>promotion_id</th>\n",
       "      <th>voucher_min_spend</th>\n",
       "      <th>voucher_discount</th>\n",
       "      <th>voucher_collect_time</th>\n",
       "      <th>voucher_redeem_time</th>\n",
       "      <th>user_age_level</th>\n",
       "      <th>user_gender</th>\n",
       "      <th>...</th>\n",
       "      <th>user_trd__orders_cnt_hist</th>\n",
       "      <th>user_trd__actual_gmv_usd_hist</th>\n",
       "      <th>user_trd__orders_cnt_platform_discount_hist</th>\n",
       "      <th>user_trd__max_gmv_usd_hist</th>\n",
       "      <th>user_trd__avg_gmv_usd_hist</th>\n",
       "      <th>user_trd__min_gmv_usd_hist</th>\n",
       "      <th>dtype</th>\n",
       "      <th>hist_session_id</th>\n",
       "      <th>hist_promotion_id</th>\n",
       "      <th>keys_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>299</td>\n",
       "      <td>30</td>\n",
       "      <td>45451</td>\n",
       "      <td>45521</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>23.507327</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.376755</td>\n",
       "      <td>3.917888</td>\n",
       "      <td>2.518198</td>\n",
       "      <td>train</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000_38</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>38</td>\n",
       "      <td>888</td>\n",
       "      <td>80</td>\n",
       "      <td>13253</td>\n",
       "      <td>13254</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>218.105824</td>\n",
       "      <td>9.0</td>\n",
       "      <td>42.643151</td>\n",
       "      <td>12.116990</td>\n",
       "      <td>3.581674</td>\n",
       "      <td>train</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10001_159</td>\n",
       "      <td>1</td>\n",
       "      <td>10001</td>\n",
       "      <td>159</td>\n",
       "      <td>799</td>\n",
       "      <td>70</td>\n",
       "      <td>80001</td>\n",
       "      <td>89306</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>39.0</td>\n",
       "      <td>373.530611</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.090705</td>\n",
       "      <td>6.225510</td>\n",
       "      <td>0.561611</td>\n",
       "      <td>train</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10001_319</td>\n",
       "      <td>0</td>\n",
       "      <td>10001</td>\n",
       "      <td>319</td>\n",
       "      <td>1999</td>\n",
       "      <td>200</td>\n",
       "      <td>115663</td>\n",
       "      <td>115663</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>42.0</td>\n",
       "      <td>381.810513</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.090705</td>\n",
       "      <td>5.614860</td>\n",
       "      <td>0.487420</td>\n",
       "      <td>train</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10001_38</td>\n",
       "      <td>0</td>\n",
       "      <td>10001</td>\n",
       "      <td>38</td>\n",
       "      <td>888</td>\n",
       "      <td>80</td>\n",
       "      <td>12867</td>\n",
       "      <td>19625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>133.172685</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.419591</td>\n",
       "      <td>11.097724</td>\n",
       "      <td>1.811817</td>\n",
       "      <td>train</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58046</th>\n",
       "      <td>99_82</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>82</td>\n",
       "      <td>299</td>\n",
       "      <td>30</td>\n",
       "      <td>46577</td>\n",
       "      <td>46577</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2462.818244</td>\n",
       "      <td>50.0</td>\n",
       "      <td>329.698604</td>\n",
       "      <td>18.944756</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>train</td>\n",
       "      <td>99_344</td>\n",
       "      <td>344</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58047</th>\n",
       "      <td>99_83</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>83</td>\n",
       "      <td>1999</td>\n",
       "      <td>200</td>\n",
       "      <td>35523</td>\n",
       "      <td>53242</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2397.249462</td>\n",
       "      <td>46.0</td>\n",
       "      <td>329.698604</td>\n",
       "      <td>19.025789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>test</td>\n",
       "      <td>99_344</td>\n",
       "      <td>344</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58048</th>\n",
       "      <td>99_91</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>91</td>\n",
       "      <td>799</td>\n",
       "      <td>80</td>\n",
       "      <td>35523</td>\n",
       "      <td>46578</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2397.249462</td>\n",
       "      <td>46.0</td>\n",
       "      <td>329.698604</td>\n",
       "      <td>19.025789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>train</td>\n",
       "      <td>99_344</td>\n",
       "      <td>344</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58049</th>\n",
       "      <td>9_61</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>61</td>\n",
       "      <td>2999</td>\n",
       "      <td>300</td>\n",
       "      <td>24981</td>\n",
       "      <td>28017</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>715.893947</td>\n",
       "      <td>23.0</td>\n",
       "      <td>150.129713</td>\n",
       "      <td>9.419657</td>\n",
       "      <td>1.116494</td>\n",
       "      <td>train</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58050</th>\n",
       "      <td>9_69</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>69</td>\n",
       "      <td>888</td>\n",
       "      <td>80</td>\n",
       "      <td>24983</td>\n",
       "      <td>24983</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>715.893947</td>\n",
       "      <td>23.0</td>\n",
       "      <td>150.129713</td>\n",
       "      <td>9.419657</td>\n",
       "      <td>1.116494</td>\n",
       "      <td>train</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58051 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      session_id  label user_id promotion_id  voucher_min_spend  \\\n",
       "0           0_82      0       0           82                299   \n",
       "1       10000_38      0   10000           38                888   \n",
       "2      10001_159      1   10001          159                799   \n",
       "3      10001_319      0   10001          319               1999   \n",
       "4       10001_38      0   10001           38                888   \n",
       "...          ...    ...     ...          ...                ...   \n",
       "58046      99_82      0      99           82                299   \n",
       "58047      99_83      1      99           83               1999   \n",
       "58048      99_91      0      99           91                799   \n",
       "58049       9_61      1       9           61               2999   \n",
       "58050       9_69      0       9           69                888   \n",
       "\n",
       "       voucher_discount voucher_collect_time voucher_redeem_time  \\\n",
       "0                    30                45451               45521   \n",
       "1                    80                13253               13254   \n",
       "2                    70                80001               89306   \n",
       "3                   200               115663              115663   \n",
       "4                    80                12867               19625   \n",
       "...                 ...                  ...                 ...   \n",
       "58046                30                46577               46577   \n",
       "58047               200                35523               53242   \n",
       "58048                80                35523               46578   \n",
       "58049               300                24981               28017   \n",
       "58050                80                24983               24983   \n",
       "\n",
       "       user_age_level user_gender  ...  user_trd__orders_cnt_hist  \\\n",
       "0                 4.0           0  ...                        4.0   \n",
       "1                 3.0           0  ...                        6.0   \n",
       "2                 0.0           0  ...                       39.0   \n",
       "3                 0.0           0  ...                       42.0   \n",
       "4                 0.0           0  ...                       11.0   \n",
       "...               ...         ...  ...                        ...   \n",
       "58046             3.0           0  ...                       44.0   \n",
       "58047             3.0           0  ...                       43.0   \n",
       "58048             3.0           0  ...                       43.0   \n",
       "58049             3.0           1  ...                       22.0   \n",
       "58050             3.0           1  ...                       22.0   \n",
       "\n",
       "       user_trd__actual_gmv_usd_hist  \\\n",
       "0                          23.507327   \n",
       "1                         218.105824   \n",
       "2                         373.530611   \n",
       "3                         381.810513   \n",
       "4                         133.172685   \n",
       "...                              ...   \n",
       "58046                    2462.818244   \n",
       "58047                    2397.249462   \n",
       "58048                    2397.249462   \n",
       "58049                     715.893947   \n",
       "58050                     715.893947   \n",
       "\n",
       "       user_trd__orders_cnt_platform_discount_hist  \\\n",
       "0                                              0.0   \n",
       "1                                              9.0   \n",
       "2                                              3.0   \n",
       "3                                              3.0   \n",
       "4                                              0.0   \n",
       "...                                            ...   \n",
       "58046                                         50.0   \n",
       "58047                                         46.0   \n",
       "58048                                         46.0   \n",
       "58049                                         23.0   \n",
       "58050                                         23.0   \n",
       "\n",
       "       user_trd__max_gmv_usd_hist  user_trd__avg_gmv_usd_hist  \\\n",
       "0                        6.376755                    3.917888   \n",
       "1                       42.643151                   12.116990   \n",
       "2                       32.090705                    6.225510   \n",
       "3                       32.090705                    5.614860   \n",
       "4                       26.419591                   11.097724   \n",
       "...                           ...                         ...   \n",
       "58046                  329.698604                   18.944756   \n",
       "58047                  329.698604                   19.025789   \n",
       "58048                  329.698604                   19.025789   \n",
       "58049                  150.129713                    9.419657   \n",
       "58050                  150.129713                    9.419657   \n",
       "\n",
       "       user_trd__min_gmv_usd_hist  dtype hist_session_id hist_promotion_id  \\\n",
       "0                        2.518198  train                                     \n",
       "1                        3.581674  train                                     \n",
       "2                        0.561611  train                                     \n",
       "3                        0.487420  train                                     \n",
       "4                        1.811817  train                                     \n",
       "...                           ...    ...             ...               ...   \n",
       "58046                    0.000000  train          99_344               344   \n",
       "58047                    0.000000   test          99_344               344   \n",
       "58048                    0.000000  train          99_344               344   \n",
       "58049                    1.116494  train                                     \n",
       "58050                    1.116494  train                                     \n",
       "\n",
       "      keys_length  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "...           ...  \n",
       "58046           1  \n",
       "58047           1  \n",
       "58048           1  \n",
       "58049           0  \n",
       "58050           0  \n",
       "\n",
       "[58051 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_voucher_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keys_length</th>\n",
       "      <th>session_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>41027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    keys_length  session_id\n",
       "0             0       41027\n",
       "1             1        8205\n",
       "2             2        4093\n",
       "3             3        2127\n",
       "4             4        1224\n",
       "5             5         630\n",
       "6             6         300\n",
       "7             7         197\n",
       "8             8          83\n",
       "9             9          60\n",
       "10           10          38\n",
       "11           11          15\n",
       "12           12          14\n",
       "13           13          12\n",
       "14           14           6\n",
       "15           15           2\n",
       "16           16           1\n",
       "17           18           7\n",
       "18           21           4\n",
       "19           22           6"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a statistics of historical UVG sequence distribution\n",
    "user_voucher_log.groupby(['keys_length']).agg({'session_id': \"count\"}).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoding and Normalization\n",
    "Label encoding for sparse features and normlaization for dense features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = user_voucher_log.copy()\n",
    "df = df.take(np.random.permutation(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_feature = ['promotion_id','session_id','user_gender','user_age_level','user_purchase_level'] #['promotion_id','voucher_min_spend','voucher_discount_amount']\n",
    "\n",
    "hist_list_features = ['hist_promotion_id','hist_session_id','keys_length']\n",
    "\n",
    "ignore_features=['dtype','venture','ds','user_id','label','voucher_collect_time','voucher_redeem_time','campaign_name','rk']\n",
    "ignore_features_key_words = ['out', 'emb']\n",
    "\n",
    "dense_feature = []\n",
    "train_features = []\n",
    "\n",
    "for feat in df.columns:\n",
    "    flag = True \n",
    "    for key in ignore_features_key_words:\n",
    "        if key in feat:\n",
    "            flag = False\n",
    "            break\n",
    "    if feat not in ignore_features and flag is True:\n",
    "        if feat not in hist_list_features:\n",
    "            train_features.append(feat)\n",
    "        if feat not in sparse_feature and feat not in hist_list_features:\n",
    "            dense_feature.append(feat)\n",
    "\n",
    "target = 'label'\n",
    "df[['session_id','promotion_id','user_gender','user_age_level','user_purchase_level']]=df[['session_id','promotion_id','user_gender','user_age_level','user_purchase_level']].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-28 11:47:58,444 [WARNING]: LabelEncoder encoding promotion_id len 462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lbe promotion_id\n",
      "LabelEncoderExt fitting...\n",
      "LabelEncoderExt transforming...\n",
      "lbe session_id\n",
      "LabelEncoderExt fitting...\n",
      "LabelEncoderExt transforming...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-28 11:47:58,671 [WARNING]: LabelEncoder encoding session_id len 58052\n",
      "2021-02-28 11:47:58,752 [WARNING]: LabelEncoder encoding user_gender len 4\n",
      "2021-02-28 11:47:58,835 [WARNING]: LabelEncoder encoding user_age_level len 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lbe user_gender\n",
      "LabelEncoderExt fitting...\n",
      "LabelEncoderExt transforming...\n",
      "lbe user_age_level\n",
      "LabelEncoderExt fitting...\n",
      "LabelEncoderExt transforming...\n",
      "lbe user_purchase_level\n",
      "LabelEncoderExt fitting...\n",
      "LabelEncoderExt transforming...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-28 11:47:58,920 [WARNING]: LabelEncoder encoding user_purchase_level len 12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "label_encoder = {}\n",
    "for feat in sparse_feature:\n",
    "    df[feat] = df[feat].fillna(0)\n",
    "    print(\"lbe {}\".format(feat))\n",
    "    \n",
    "    lbe = LabelEncoderExt()\n",
    "    lbe.fit(df[feat])\n",
    "        \n",
    "    df[feat] = lbe.transform(df[feat])\n",
    "    label_encoder[feat] = lbe\n",
    "    logging.warn('LabelEncoder encoding ' + feat + \" len \" + str(len(lbe)))\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voucher_min_spend\n",
      "voucher_discount\n",
      "user_trd__orders_cnt_hist\n",
      "user_trd__actual_gmv_usd_hist\n",
      "user_trd__orders_cnt_platform_discount_hist\n",
      "user_trd__max_gmv_usd_hist\n",
      "user_trd__avg_gmv_usd_hist\n",
      "user_trd__min_gmv_usd_hist\n"
     ]
    }
   ],
   "source": [
    "mean_kv = {}\n",
    "std_kv = {}\n",
    "for feat in dense_feature:\n",
    "    print(feat)\n",
    "    mean_kv[feat] = df[feat].mean()\n",
    "    std_kv[feat] = df[feat].std()\n",
    "    df[feat] = (df[feat] - mean_kv[feat]) / std_kv[feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_ctr_df = df \n",
    "\n",
    "dctr_train = deep_ctr_df[deep_ctr_df.dtype == 'train']\n",
    "dctr_v1 = deep_ctr_df[deep_ctr_df.dtype == 'test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "results={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 16\n",
    "sparse_feature_columns = [SparseFeat(feat, len(label_encoder[feat].classes_), embedding_dim = embedding_dim) for feat in sparse_feature]\n",
    "dense_feature_columns = [DenseFeat(feat, 1, ) for feat in dense_feature]\n",
    "\n",
    "dnn_feature_columns = sparse_feature_columns + dense_feature_columns\n",
    "linear_feature_columns = sparse_feature_columns + dense_feature_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR\n",
    "LR: Logistic Regression [1] is a shallow model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_model_input_data(feature_names, raw_features, target):\n",
    "    model_input = {}\n",
    "    for name in feature_names:\n",
    "        if name in sparse_feature:\n",
    "            model_input[name] = raw_features[name]\n",
    "        else:\n",
    "            model_input[name] = raw_features[name].fillna(0).astype(np.float32)\n",
    "    return raw_features[target], model_input\n",
    "\n",
    "feature_names = get_feature_names(dense_feature_columns + sparse_feature_columns)\n",
    "train_label, train_model_input = gen_model_input_data(feature_names, dctr_train, target)\n",
    "test_label1, test_model_input1 = gen_model_input_data(feature_names, dctr_v1, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:00, 88.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Train on 46361 samples, validate on 11690 samples, 155 steps per epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 102.50it/s]\n",
      "11it [00:00, 101.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1s - loss:  0.5973 - auc:  0.5395 - logloss:  0.5953 - val_auc:  0.6077 - val_logloss:  0.5217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 103.39it/s]\n",
      "11it [00:00, 101.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50\n",
      "1s - loss:  0.4862 - auc:  0.7375 - logloss:  0.4844 - val_auc:  0.6719 - val_logloss:  0.4590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 103.24it/s]\n",
      "11it [00:00, 100.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50\n",
      "1s - loss:  0.4459 - auc:  0.7664 - logloss:  0.4439 - val_auc:  0.7047 - val_logloss:  0.4362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 103.15it/s]\n",
      "11it [00:00, 100.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50\n",
      "1s - loss:  0.4298 - auc:  0.7739 - logloss:  0.4277 - val_auc:  0.7202 - val_logloss:  0.4257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 103.21it/s]\n",
      "11it [00:00, 100.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50\n",
      "1s - loss:  0.4211 - auc:  0.7739 - logloss:  0.4190 - val_auc:  0.7262 - val_logloss:  0.4193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 93.78it/s] \n",
      "11it [00:00, 100.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50\n",
      "1s - loss:  0.4152 - auc:  0.7732 - logloss:  0.4130 - val_auc:  0.7294 - val_logloss:  0.4146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 103.17it/s]\n",
      "11it [00:00, 101.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50\n",
      "1s - loss:  0.4106 - auc:  0.7703 - logloss:  0.4085 - val_auc:  0.7307 - val_logloss:  0.4108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 103.08it/s]\n",
      "11it [00:00, 100.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50\n",
      "1s - loss:  0.4068 - auc:  0.7685 - logloss:  0.4048 - val_auc:  0.7319 - val_logloss:  0.4077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 102.93it/s]\n",
      "10it [00:00, 98.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50\n",
      "1s - loss:  0.4036 - auc:  0.7666 - logloss:  0.4016 - val_auc:  0.7324 - val_logloss:  0.4051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 103.39it/s]\n",
      "10it [00:00, 98.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50\n",
      "1s - loss:  0.4010 - auc:  0.7660 - logloss:  0.3992 - val_auc:  0.7328 - val_logloss:  0.4030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 103.45it/s]\n",
      "11it [00:00, 100.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50\n",
      "1s - loss:  0.3989 - auc:  0.7645 - logloss:  0.3971 - val_auc:  0.7331 - val_logloss:  0.4012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 103.96it/s]\n",
      "11it [00:00, 100.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50\n",
      "1s - loss:  0.3971 - auc:  0.7638 - logloss:  0.3953 - val_auc:  0.7337 - val_logloss:  0.3997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 94.26it/s] \n",
      "11it [00:00, 101.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50\n",
      "1s - loss:  0.3955 - auc:  0.7630 - logloss:  0.3939 - val_auc:  0.7341 - val_logloss:  0.3984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 104.08it/s]\n",
      "11it [00:00, 100.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50\n",
      "1s - loss:  0.3943 - auc:  0.7626 - logloss:  0.3926 - val_auc:  0.7344 - val_logloss:  0.3973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 103.74it/s]\n",
      "11it [00:00, 101.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50\n",
      "1s - loss:  0.3931 - auc:  0.7622 - logloss:  0.3912 - val_auc:  0.7348 - val_logloss:  0.3964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 104.00it/s]\n",
      "11it [00:00, 101.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50\n",
      "1s - loss:  0.3922 - auc:  0.7616 - logloss:  0.3902 - val_auc:  0.7351 - val_logloss:  0.3956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 104.20it/s]\n",
      "11it [00:00, 101.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50\n",
      "1s - loss:  0.3914 - auc:  0.7620 - logloss:  0.3893 - val_auc:  0.7354 - val_logloss:  0.3949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 104.39it/s]\n",
      "11it [00:00, 101.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50\n",
      "1s - loss:  0.3907 - auc:  0.7622 - logloss:  0.3887 - val_auc:  0.7355 - val_logloss:  0.3943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 101.71it/s]\n",
      "10it [00:00, 97.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50\n",
      "1s - loss:  0.3901 - auc:  0.7616 - logloss:  0.3883 - val_auc:  0.7357 - val_logloss:  0.3938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 100.83it/s]\n",
      "10it [00:00, 98.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50\n",
      "1s - loss:  0.3896 - auc:  0.7619 - logloss:  0.3876 - val_auc:  0.7360 - val_logloss:  0.3934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 91.96it/s]\n",
      "10it [00:00, 98.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50\n",
      "1s - loss:  0.3891 - auc:  0.7612 - logloss:  0.3872 - val_auc:  0.7362 - val_logloss:  0.3930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 100.58it/s]\n",
      "10it [00:00, 98.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50\n",
      "1s - loss:  0.3887 - auc:  0.7614 - logloss:  0.3868 - val_auc:  0.7363 - val_logloss:  0.3926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 100.82it/s]\n",
      "10it [00:00, 98.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50\n",
      "1s - loss:  0.3884 - auc:  0.7605 - logloss:  0.3863 - val_auc:  0.7364 - val_logloss:  0.3923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 100.87it/s]\n",
      "10it [00:00, 97.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50\n",
      "1s - loss:  0.3881 - auc:  0.7609 - logloss:  0.3861 - val_auc:  0.7365 - val_logloss:  0.3920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 100.80it/s]\n",
      "10it [00:00, 98.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50\n",
      "1s - loss:  0.3878 - auc:  0.7611 - logloss:  0.3858 - val_auc:  0.7366 - val_logloss:  0.3918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 101.44it/s]\n",
      "11it [00:00, 101.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50\n",
      "1s - loss:  0.3875 - auc:  0.7609 - logloss:  0.3855 - val_auc:  0.7367 - val_logloss:  0.3916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 103.89it/s]\n",
      "11it [00:00, 101.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50\n",
      "1s - loss:  0.3873 - auc:  0.7613 - logloss:  0.3855 - val_auc:  0.7369 - val_logloss:  0.3914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 103.96it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50\n",
      "1s - loss:  0.3871 - auc:  0.7608 - logloss:  0.3849 - val_auc:  0.7370 - val_logloss:  0.3912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 94.44it/s] \n",
      "11it [00:00, 101.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50\n",
      "1s - loss:  0.3869 - auc:  0.7602 - logloss:  0.3848 - val_auc:  0.7371 - val_logloss:  0.3910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 103.88it/s]\n",
      "11it [00:00, 101.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50\n",
      "1s - loss:  0.3868 - auc:  0.7609 - logloss:  0.3845 - val_auc:  0.7371 - val_logloss:  0.3909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 104.21it/s]\n",
      "11it [00:00, 100.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50\n",
      "1s - loss:  0.3866 - auc:  0.7607 - logloss:  0.3847 - val_auc:  0.7372 - val_logloss:  0.3908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 103.76it/s]\n",
      "11it [00:00, 101.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50\n",
      "1s - loss:  0.3865 - auc:  0.7600 - logloss:  0.3846 - val_auc:  0.7372 - val_logloss:  0.3907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 103.78it/s]\n",
      "11it [00:00, 100.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50\n",
      "1s - loss:  0.3864 - auc:  0.7606 - logloss:  0.3843 - val_auc:  0.7373 - val_logloss:  0.3905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 103.64it/s]\n",
      "11it [00:00, 101.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50\n",
      "1s - loss:  0.3863 - auc:  0.7610 - logloss:  0.3845 - val_auc:  0.7373 - val_logloss:  0.3905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 103.70it/s]\n",
      "11it [00:00, 101.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50\n",
      "1s - loss:  0.3862 - auc:  0.7606 - logloss:  0.3843 - val_auc:  0.7374 - val_logloss:  0.3904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 94.32it/s] \n",
      "10it [00:00, 98.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50\n",
      "1s - loss:  0.3861 - auc:  0.7607 - logloss:  0.3839 - val_auc:  0.7374 - val_logloss:  0.3903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 103.49it/s]\n",
      "10it [00:00, 94.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50\n",
      "1s - loss:  0.3860 - auc:  0.7605 - logloss:  0.3839 - val_auc:  0.7374 - val_logloss:  0.3902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 99.86it/s] \n",
      "10it [00:00, 97.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50\n",
      "1s - loss:  0.3859 - auc:  0.7606 - logloss:  0.3836 - val_auc:  0.7375 - val_logloss:  0.3901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 100.79it/s]\n",
      "10it [00:00, 98.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50\n",
      "1s - loss:  0.3859 - auc:  0.7600 - logloss:  0.3839 - val_auc:  0.7375 - val_logloss:  0.3901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 101.03it/s]\n",
      "10it [00:00, 96.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50\n",
      "1s - loss:  0.3858 - auc:  0.7605 - logloss:  0.3838 - val_auc:  0.7375 - val_logloss:  0.3900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 100.84it/s]\n",
      "10it [00:00, 97.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50\n",
      "1s - loss:  0.3857 - auc:  0.7604 - logloss:  0.3836 - val_auc:  0.7375 - val_logloss:  0.3900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 100.95it/s]\n",
      "10it [00:00, 97.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50\n",
      "1s - loss:  0.3857 - auc:  0.7602 - logloss:  0.3836 - val_auc:  0.7375 - val_logloss:  0.3900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 100.84it/s]\n",
      "10it [00:00, 98.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50\n",
      "1s - loss:  0.3857 - auc:  0.7610 - logloss:  0.3840 - val_auc:  0.7376 - val_logloss:  0.3899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 91.68it/s]\n",
      "10it [00:00, 97.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50\n",
      "1s - loss:  0.3856 - auc:  0.7603 - logloss:  0.3835 - val_auc:  0.7376 - val_logloss:  0.3899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 100.81it/s]\n",
      "10it [00:00, 97.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50\n",
      "1s - loss:  0.3855 - auc:  0.7604 - logloss:  0.3835 - val_auc:  0.7376 - val_logloss:  0.3898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 100.71it/s]\n",
      "10it [00:00, 97.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50\n",
      "1s - loss:  0.3855 - auc:  0.7608 - logloss:  0.3834 - val_auc:  0.7376 - val_logloss:  0.3898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 100.92it/s]\n",
      "10it [00:00, 97.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50\n",
      "1s - loss:  0.3855 - auc:  0.7605 - logloss:  0.3836 - val_auc:  0.7376 - val_logloss:  0.3898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 100.86it/s]\n",
      "10it [00:00, 96.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50\n",
      "1s - loss:  0.3854 - auc:  0.7599 - logloss:  0.3833 - val_auc:  0.7377 - val_logloss:  0.3898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 100.70it/s]\n",
      "10it [00:00, 98.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50\n",
      "1s - loss:  0.3854 - auc:  0.7603 - logloss:  0.3833 - val_auc:  0.7376 - val_logloss:  0.3897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:01, 100.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50\n",
      "1s - loss:  0.3854 - auc:  0.7597 - logloss:  0.3835 - val_auc:  0.7376 - val_logloss:  0.3897\n"
     ]
    }
   ],
   "source": [
    "model_name = 'LR'\n",
    "epoch = 50\n",
    "batch_size = 300\n",
    "\n",
    "model = WDL(linear_feature_columns=dnn_feature_columns,\n",
    "            dnn_feature_columns=[], \n",
    "            dnn_use_bn=True,\n",
    "            l2_reg_dnn=0.1, \n",
    "            l2_reg_embedding = 0.0001, \n",
    "            dnn_hidden_units=(128,64), \n",
    "            init_std=1, \n",
    "            dnn_dropout=0.5, \n",
    "            task='binary', \n",
    "            dnn_activation='relu', \n",
    "            device=device)\n",
    "\n",
    "model\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.1, amsgrad=True)\n",
    "model.compile(optimizer, 'binary_crossentropy',metrics=['auc','logloss'])\n",
    "res, pred1 = model.fit(train_model_input,  train_label.values.astype(int), batch_size=batch_size, epochs=epoch, validation_data=(test_model_input1,test_label1),verbose=1)\n",
    "\n",
    "results[model_name] = model, res, pred1, test_label1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBDT\n",
    "GBDT: Gradient Boosting Decision Tree [2] is used to assess the performance of non deep-learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:49:25] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { num_leaves } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\teval-auc:0.68105\teval-logloss:0.66411\ttrain-auc:0.68754\ttrain-logloss:0.66409\n",
      "[1]\teval-auc:0.68337\teval-logloss:0.63841\ttrain-auc:0.68873\ttrain-logloss:0.63836\n",
      "[2]\teval-auc:0.68355\teval-logloss:0.61554\ttrain-auc:0.68905\ttrain-logloss:0.61545\n",
      "[3]\teval-auc:0.68284\teval-logloss:0.59521\ttrain-auc:0.68995\ttrain-logloss:0.59506\n",
      "[4]\teval-auc:0.68483\teval-logloss:0.57689\ttrain-auc:0.69079\ttrain-logloss:0.57673\n",
      "[5]\teval-auc:0.68322\teval-logloss:0.56058\ttrain-auc:0.69054\ttrain-logloss:0.56034\n",
      "[6]\teval-auc:0.69445\teval-logloss:0.54583\ttrain-auc:0.70259\ttrain-logloss:0.54549\n",
      "[7]\teval-auc:0.69612\teval-logloss:0.53250\ttrain-auc:0.70585\ttrain-logloss:0.53204\n",
      "[8]\teval-auc:0.69831\teval-logloss:0.52049\ttrain-auc:0.70832\ttrain-logloss:0.51992\n",
      "[9]\teval-auc:0.69864\teval-logloss:0.50958\ttrain-auc:0.70914\ttrain-logloss:0.50897\n",
      "[10]\teval-auc:0.69854\teval-logloss:0.49979\ttrain-auc:0.70950\ttrain-logloss:0.49911\n",
      "[11]\teval-auc:0.70076\teval-logloss:0.49085\ttrain-auc:0.71154\ttrain-logloss:0.49004\n",
      "[12]\teval-auc:0.70347\teval-logloss:0.48272\ttrain-auc:0.71581\ttrain-logloss:0.48175\n",
      "[13]\teval-auc:0.70600\teval-logloss:0.47534\ttrain-auc:0.71893\ttrain-logloss:0.47425\n",
      "[14]\teval-auc:0.70666\teval-logloss:0.46856\ttrain-auc:0.72052\ttrain-logloss:0.46733\n",
      "[15]\teval-auc:0.70765\teval-logloss:0.46258\ttrain-auc:0.72120\ttrain-logloss:0.46122\n",
      "[16]\teval-auc:0.70889\teval-logloss:0.45705\ttrain-auc:0.72267\ttrain-logloss:0.45549\n",
      "[17]\teval-auc:0.71044\teval-logloss:0.45196\ttrain-auc:0.72449\ttrain-logloss:0.45029\n",
      "[18]\teval-auc:0.71136\teval-logloss:0.44742\ttrain-auc:0.72617\ttrain-logloss:0.44559\n",
      "[19]\teval-auc:0.71181\teval-logloss:0.44320\ttrain-auc:0.72712\ttrain-logloss:0.44126\n",
      "[20]\teval-auc:0.71304\teval-logloss:0.43941\ttrain-auc:0.72848\ttrain-logloss:0.43739\n",
      "[21]\teval-auc:0.71419\teval-logloss:0.43590\ttrain-auc:0.72966\ttrain-logloss:0.43372\n",
      "[22]\teval-auc:0.71829\teval-logloss:0.43241\ttrain-auc:0.73395\ttrain-logloss:0.43011\n",
      "[23]\teval-auc:0.71902\teval-logloss:0.42936\ttrain-auc:0.73494\ttrain-logloss:0.42691\n",
      "[24]\teval-auc:0.71932\teval-logloss:0.42665\ttrain-auc:0.73492\ttrain-logloss:0.42413\n",
      "[25]\teval-auc:0.72017\teval-logloss:0.42425\ttrain-auc:0.73655\ttrain-logloss:0.42157\n",
      "[26]\teval-auc:0.72077\teval-logloss:0.42194\ttrain-auc:0.73743\ttrain-logloss:0.41909\n",
      "[27]\teval-auc:0.72127\teval-logloss:0.41970\ttrain-auc:0.73786\ttrain-logloss:0.41678\n",
      "[28]\teval-auc:0.72139\teval-logloss:0.41778\ttrain-auc:0.73868\ttrain-logloss:0.41461\n",
      "[29]\teval-auc:0.72314\teval-logloss:0.41601\ttrain-auc:0.74128\ttrain-logloss:0.41262\n",
      "[30]\teval-auc:0.72368\teval-logloss:0.41438\ttrain-auc:0.74207\ttrain-logloss:0.41081\n",
      "[31]\teval-auc:0.72454\teval-logloss:0.41275\ttrain-auc:0.74320\ttrain-logloss:0.40903\n",
      "[32]\teval-auc:0.72492\teval-logloss:0.41125\ttrain-auc:0.74379\ttrain-logloss:0.40738\n",
      "[33]\teval-auc:0.72657\teval-logloss:0.40980\ttrain-auc:0.74608\ttrain-logloss:0.40579\n",
      "[34]\teval-auc:0.72671\teval-logloss:0.40866\ttrain-auc:0.74678\ttrain-logloss:0.40446\n",
      "[35]\teval-auc:0.72696\teval-logloss:0.40754\ttrain-auc:0.74738\ttrain-logloss:0.40316\n",
      "[36]\teval-auc:0.72815\teval-logloss:0.40648\ttrain-auc:0.74872\ttrain-logloss:0.40190\n",
      "[37]\teval-auc:0.72815\teval-logloss:0.40564\ttrain-auc:0.74930\ttrain-logloss:0.40087\n",
      "[38]\teval-auc:0.72826\teval-logloss:0.40483\ttrain-auc:0.74970\ttrain-logloss:0.39986\n",
      "[39]\teval-auc:0.72887\teval-logloss:0.40387\ttrain-auc:0.75055\ttrain-logloss:0.39880\n",
      "[40]\teval-auc:0.72892\teval-logloss:0.40319\ttrain-auc:0.75103\ttrain-logloss:0.39789\n",
      "[41]\teval-auc:0.73022\teval-logloss:0.40221\ttrain-auc:0.75270\ttrain-logloss:0.39673\n",
      "[42]\teval-auc:0.73033\teval-logloss:0.40155\ttrain-auc:0.75306\ttrain-logloss:0.39588\n",
      "[43]\teval-auc:0.73123\teval-logloss:0.40080\ttrain-auc:0.75440\ttrain-logloss:0.39495\n",
      "[44]\teval-auc:0.73100\teval-logloss:0.40032\ttrain-auc:0.75460\ttrain-logloss:0.39428\n",
      "[45]\teval-auc:0.73122\teval-logloss:0.39978\ttrain-auc:0.75532\ttrain-logloss:0.39351\n",
      "[46]\teval-auc:0.73224\teval-logloss:0.39907\ttrain-auc:0.75663\ttrain-logloss:0.39262\n",
      "[47]\teval-auc:0.73224\teval-logloss:0.39863\ttrain-auc:0.75705\ttrain-logloss:0.39199\n",
      "[48]\teval-auc:0.73185\teval-logloss:0.39831\ttrain-auc:0.75712\ttrain-logloss:0.39145\n",
      "[49]\teval-auc:0.73204\teval-logloss:0.39787\ttrain-auc:0.75803\ttrain-logloss:0.39077\n",
      "[50]\teval-auc:0.73247\teval-logloss:0.39731\ttrain-auc:0.75868\ttrain-logloss:0.38999\n",
      "[51]\teval-auc:0.73277\teval-logloss:0.39694\ttrain-auc:0.75930\ttrain-logloss:0.38948\n",
      "[52]\teval-auc:0.73291\teval-logloss:0.39658\ttrain-auc:0.75986\ttrain-logloss:0.38889\n",
      "[53]\teval-auc:0.73340\teval-logloss:0.39614\ttrain-auc:0.76088\ttrain-logloss:0.38825\n",
      "[54]\teval-auc:0.73344\teval-logloss:0.39579\ttrain-auc:0.76149\ttrain-logloss:0.38767\n",
      "[55]\teval-auc:0.73344\teval-logloss:0.39555\ttrain-auc:0.76185\ttrain-logloss:0.38726\n",
      "[56]\teval-auc:0.73381\teval-logloss:0.39530\ttrain-auc:0.76263\ttrain-logloss:0.38682\n",
      "[57]\teval-auc:0.73451\teval-logloss:0.39486\ttrain-auc:0.76370\ttrain-logloss:0.38619\n",
      "[58]\teval-auc:0.73504\teval-logloss:0.39440\ttrain-auc:0.76479\ttrain-logloss:0.38547\n",
      "[59]\teval-auc:0.73575\teval-logloss:0.39401\ttrain-auc:0.76659\ttrain-logloss:0.38471\n",
      "[60]\teval-auc:0.73618\teval-logloss:0.39366\ttrain-auc:0.76738\ttrain-logloss:0.38419\n",
      "[61]\teval-auc:0.73625\teval-logloss:0.39351\ttrain-auc:0.76797\ttrain-logloss:0.38385\n",
      "[62]\teval-auc:0.73683\teval-logloss:0.39303\ttrain-auc:0.76926\ttrain-logloss:0.38305\n",
      "[63]\teval-auc:0.73675\teval-logloss:0.39289\ttrain-auc:0.76954\ttrain-logloss:0.38273\n",
      "[64]\teval-auc:0.73683\teval-logloss:0.39278\ttrain-auc:0.76998\ttrain-logloss:0.38246\n",
      "[65]\teval-auc:0.73758\teval-logloss:0.39236\ttrain-auc:0.77088\ttrain-logloss:0.38190\n",
      "[66]\teval-auc:0.73809\teval-logloss:0.39203\ttrain-auc:0.77184\ttrain-logloss:0.38135\n",
      "[67]\teval-auc:0.73825\teval-logloss:0.39191\ttrain-auc:0.77236\ttrain-logloss:0.38108\n",
      "[68]\teval-auc:0.73952\teval-logloss:0.39139\ttrain-auc:0.77431\ttrain-logloss:0.38027\n",
      "[69]\teval-auc:0.73991\teval-logloss:0.39106\ttrain-auc:0.77501\ttrain-logloss:0.37975\n",
      "[70]\teval-auc:0.73993\teval-logloss:0.39096\ttrain-auc:0.77537\ttrain-logloss:0.37949\n",
      "[71]\teval-auc:0.74098\teval-logloss:0.39048\ttrain-auc:0.77685\ttrain-logloss:0.37879\n",
      "[72]\teval-auc:0.74103\teval-logloss:0.39036\ttrain-auc:0.77716\ttrain-logloss:0.37844\n",
      "[73]\teval-auc:0.74156\teval-logloss:0.38994\ttrain-auc:0.77811\ttrain-logloss:0.37775\n",
      "[74]\teval-auc:0.74154\teval-logloss:0.38981\ttrain-auc:0.77849\ttrain-logloss:0.37742\n",
      "[75]\teval-auc:0.74198\teval-logloss:0.38954\ttrain-auc:0.77939\ttrain-logloss:0.37690\n",
      "[76]\teval-auc:0.74203\teval-logloss:0.38941\ttrain-auc:0.77968\ttrain-logloss:0.37661\n",
      "[77]\teval-auc:0.74225\teval-logloss:0.38925\ttrain-auc:0.78041\ttrain-logloss:0.37616\n",
      "[78]\teval-auc:0.74277\teval-logloss:0.38893\ttrain-auc:0.78148\ttrain-logloss:0.37557\n",
      "[79]\teval-auc:0.74300\teval-logloss:0.38881\ttrain-auc:0.78193\ttrain-logloss:0.37535\n",
      "[80]\teval-auc:0.74361\teval-logloss:0.38840\ttrain-auc:0.78291\ttrain-logloss:0.37465\n",
      "[81]\teval-auc:0.74390\teval-logloss:0.38826\ttrain-auc:0.78327\ttrain-logloss:0.37438\n",
      "[82]\teval-auc:0.74386\teval-logloss:0.38822\ttrain-auc:0.78375\ttrain-logloss:0.37405\n",
      "[83]\teval-auc:0.74418\teval-logloss:0.38798\ttrain-auc:0.78443\ttrain-logloss:0.37358\n",
      "[84]\teval-auc:0.74479\teval-logloss:0.38761\ttrain-auc:0.78536\ttrain-logloss:0.37300\n",
      "[85]\teval-auc:0.74485\teval-logloss:0.38757\ttrain-auc:0.78573\ttrain-logloss:0.37281\n",
      "[86]\teval-auc:0.74521\teval-logloss:0.38730\ttrain-auc:0.78665\ttrain-logloss:0.37227\n",
      "[87]\teval-auc:0.74501\teval-logloss:0.38727\ttrain-auc:0.78704\ttrain-logloss:0.37201\n",
      "[88]\teval-auc:0.74521\teval-logloss:0.38716\ttrain-auc:0.78744\ttrain-logloss:0.37174\n",
      "[89]\teval-auc:0.74516\teval-logloss:0.38706\ttrain-auc:0.78797\ttrain-logloss:0.37133\n",
      "[90]\teval-auc:0.74538\teval-logloss:0.38688\ttrain-auc:0.78833\ttrain-logloss:0.37101\n",
      "[91]\teval-auc:0.74545\teval-logloss:0.38678\ttrain-auc:0.78868\ttrain-logloss:0.37073\n",
      "[92]\teval-auc:0.74557\teval-logloss:0.38670\ttrain-auc:0.78894\ttrain-logloss:0.37054\n",
      "[93]\teval-auc:0.74573\teval-logloss:0.38662\ttrain-auc:0.78935\ttrain-logloss:0.37033\n",
      "[94]\teval-auc:0.74587\teval-logloss:0.38648\ttrain-auc:0.78990\ttrain-logloss:0.37000\n",
      "[95]\teval-auc:0.74569\teval-logloss:0.38646\ttrain-auc:0.79018\ttrain-logloss:0.36977\n",
      "[96]\teval-auc:0.74570\teval-logloss:0.38639\ttrain-auc:0.79050\ttrain-logloss:0.36952\n",
      "[97]\teval-auc:0.74588\teval-logloss:0.38628\ttrain-auc:0.79082\ttrain-logloss:0.36932\n",
      "[98]\teval-auc:0.74600\teval-logloss:0.38623\ttrain-auc:0.79107\ttrain-logloss:0.36915\n",
      "[99]\teval-auc:0.74610\teval-logloss:0.38607\ttrain-auc:0.79140\ttrain-logloss:0.36885\n",
      "[100]\teval-auc:0.74582\teval-logloss:0.38610\ttrain-auc:0.79167\ttrain-logloss:0.36864\n",
      "[101]\teval-auc:0.74620\teval-logloss:0.38589\ttrain-auc:0.79209\ttrain-logloss:0.36833\n",
      "[102]\teval-auc:0.74636\teval-logloss:0.38582\ttrain-auc:0.79236\ttrain-logloss:0.36817\n",
      "[103]\teval-auc:0.74658\teval-logloss:0.38568\ttrain-auc:0.79262\ttrain-logloss:0.36798\n",
      "[104]\teval-auc:0.74673\teval-logloss:0.38552\ttrain-auc:0.79307\ttrain-logloss:0.36763\n",
      "[105]\teval-auc:0.74689\teval-logloss:0.38543\ttrain-auc:0.79332\ttrain-logloss:0.36745\n",
      "[106]\teval-auc:0.74726\teval-logloss:0.38518\ttrain-auc:0.79420\ttrain-logloss:0.36691\n",
      "[107]\teval-auc:0.74731\teval-logloss:0.38506\ttrain-auc:0.79472\ttrain-logloss:0.36653\n",
      "[108]\teval-auc:0.74751\teval-logloss:0.38488\ttrain-auc:0.79544\ttrain-logloss:0.36607\n",
      "[109]\teval-auc:0.74756\teval-logloss:0.38480\ttrain-auc:0.79578\ttrain-logloss:0.36579\n",
      "[110]\teval-auc:0.74754\teval-logloss:0.38477\ttrain-auc:0.79585\ttrain-logloss:0.36570\n",
      "[111]\teval-auc:0.74765\teval-logloss:0.38471\ttrain-auc:0.79609\ttrain-logloss:0.36556\n",
      "[112]\teval-auc:0.74785\teval-logloss:0.38458\ttrain-auc:0.79676\ttrain-logloss:0.36517\n",
      "[113]\teval-auc:0.74772\teval-logloss:0.38459\ttrain-auc:0.79705\ttrain-logloss:0.36503\n",
      "[114]\teval-auc:0.74783\teval-logloss:0.38452\ttrain-auc:0.79733\ttrain-logloss:0.36484\n",
      "[115]\teval-auc:0.74781\teval-logloss:0.38447\ttrain-auc:0.79758\ttrain-logloss:0.36459\n",
      "[116]\teval-auc:0.74792\teval-logloss:0.38440\ttrain-auc:0.79783\ttrain-logloss:0.36439\n",
      "[117]\teval-auc:0.74784\teval-logloss:0.38440\ttrain-auc:0.79785\ttrain-logloss:0.36433\n",
      "[118]\teval-auc:0.74790\teval-logloss:0.38436\ttrain-auc:0.79812\ttrain-logloss:0.36417\n",
      "[119]\teval-auc:0.74789\teval-logloss:0.38435\ttrain-auc:0.79819\ttrain-logloss:0.36413\n",
      "[120]\teval-auc:0.74799\teval-logloss:0.38428\ttrain-auc:0.79838\ttrain-logloss:0.36394\n",
      "[121]\teval-auc:0.74796\teval-logloss:0.38426\ttrain-auc:0.79838\ttrain-logloss:0.36385\n",
      "[122]\teval-auc:0.74787\teval-logloss:0.38428\ttrain-auc:0.79870\ttrain-logloss:0.36369\n",
      "[123]\teval-auc:0.74786\teval-logloss:0.38427\ttrain-auc:0.79880\ttrain-logloss:0.36361\n",
      "[124]\teval-auc:0.74796\teval-logloss:0.38422\ttrain-auc:0.79899\ttrain-logloss:0.36342\n",
      "[125]\teval-auc:0.74790\teval-logloss:0.38421\ttrain-auc:0.79900\ttrain-logloss:0.36335\n",
      "[126]\teval-auc:0.74788\teval-logloss:0.38421\ttrain-auc:0.79916\ttrain-logloss:0.36326\n",
      "[127]\teval-auc:0.74811\teval-logloss:0.38412\ttrain-auc:0.79987\ttrain-logloss:0.36294\n",
      "[128]\teval-auc:0.74802\teval-logloss:0.38415\ttrain-auc:0.80013\ttrain-logloss:0.36279\n",
      "[129]\teval-auc:0.74804\teval-logloss:0.38412\ttrain-auc:0.80020\ttrain-logloss:0.36270\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "model_name = \"xgBoost\"\n",
    "xgb_data_train = dctr_train\n",
    "df_xgb_train =  xgb.DMatrix(xgb_data_train[sparse_feature], \n",
    "                            label=xgb_data_train[target])\n",
    "\n",
    "xgb_data_test1 = dctr_v1\n",
    "df_xgb_test1 = xgb.DMatrix(xgb_data_test1[sparse_feature],\n",
    "                            label=xgb_data_test1[target])\n",
    "\n",
    "params = {'objective': 'binary:logistic',\n",
    "          'eval_metric': ['auc', 'logloss'],\n",
    "          'learning_rate': 0.06,\n",
    "          'num_leaves':256,\n",
    "          'max_depth':7,\n",
    "          'max_bin':64}\n",
    "\n",
    "evallist = [(df_xgb_test1, 'eval'), (df_xgb_train, 'train')]\n",
    "num_boost_round = 130\n",
    "xgb = xgb.train(params,\n",
    "                df_xgb_train,\n",
    "                num_boost_round,\n",
    "                evallist) \n",
    "\n",
    "xgb_pred_v1 = xgb.predict(df_xgb_test1)\n",
    "xgb_label_v1 = xgb_data_test1[target]\n",
    "auc_t1 = roc_auc_score(xgb_label_v1, xgb_pred_v1)\n",
    "logloss_t1 = log_loss(xgb_label_v1, xgb_pred_v1)\n",
    "res = {'eval_auc':auc_t1, \"eval_logloss\":logloss_t1}\n",
    "\n",
    "results[model_name] = xgb, res, xgb_pred_v1, xgb_label_v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN\n",
    "The Deep Neural Network is used as the first baseline taking both dense features and embedding of sparse id features into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Train on 46361 samples, validate on 11690 samples, 155 steps per epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 66.64it/s]\n",
      "7it [00:00, 68.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2s - loss:  7.3254 - auc:  0.5274 - logloss:  0.4859 - val_auc:  0.6181 - val_logloss:  0.4506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 72.52it/s]\n",
      "7it [00:00, 69.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "2s - loss:  7.2633 - auc:  0.6458 - logloss:  0.4239 - val_auc:  0.6745 - val_logloss:  0.4146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 72.77it/s]\n",
      "7it [00:00, 68.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "2s - loss:  7.2520 - auc:  0.6836 - logloss:  0.4127 - val_auc:  0.6972 - val_logloss:  0.4073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 72.78it/s]\n",
      "7it [00:00, 69.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "2s - loss:  7.2449 - auc:  0.7038 - logloss:  0.4054 - val_auc:  0.7115 - val_logloss:  0.4022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 72.77it/s]\n",
      "7it [00:00, 68.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "2s - loss:  7.2393 - auc:  0.7200 - logloss:  0.4001 - val_auc:  0.7226 - val_logloss:  0.3969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 72.76it/s]\n",
      "7it [00:00, 69.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "2s - loss:  7.2345 - auc:  0.7296 - logloss:  0.3953 - val_auc:  0.7314 - val_logloss:  0.3927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 72.68it/s]\n",
      "7it [00:00, 69.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "2s - loss:  7.2310 - auc:  0.7368 - logloss:  0.3917 - val_auc:  0.7376 - val_logloss:  0.3896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 72.02it/s]\n",
      "7it [00:00, 67.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "2s - loss:  7.2282 - auc:  0.7428 - logloss:  0.3889 - val_auc:  0.7421 - val_logloss:  0.3877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 66.60it/s]\n",
      "7it [00:00, 67.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n",
      "2s - loss:  7.2261 - auc:  0.7471 - logloss:  0.3866 - val_auc:  0.7460 - val_logloss:  0.3862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 71.22it/s]\n",
      "7it [00:00, 67.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n",
      "2s - loss:  7.2247 - auc:  0.7504 - logloss:  0.3855 - val_auc:  0.7478 - val_logloss:  0.3846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 71.26it/s]\n",
      "7it [00:00, 67.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "2s - loss:  7.2236 - auc:  0.7512 - logloss:  0.3841 - val_auc:  0.7510 - val_logloss:  0.3835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 71.19it/s]\n",
      "7it [00:00, 67.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "2s - loss:  7.2227 - auc:  0.7549 - logloss:  0.3833 - val_auc:  0.7524 - val_logloss:  0.3830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 71.10it/s]\n",
      "7it [00:00, 69.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "2s - loss:  7.2217 - auc:  0.7561 - logloss:  0.3825 - val_auc:  0.7540 - val_logloss:  0.3816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 73.19it/s]\n",
      "7it [00:00, 69.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n",
      "2s - loss:  7.2209 - auc:  0.7573 - logloss:  0.3815 - val_auc:  0.7553 - val_logloss:  0.3817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 73.18it/s]\n",
      "7it [00:00, 69.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20\n",
      "2s - loss:  7.2204 - auc:  0.7588 - logloss:  0.3811 - val_auc:  0.7569 - val_logloss:  0.3803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 73.37it/s]\n",
      "8it [00:00, 70.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "2s - loss:  7.2195 - auc:  0.7597 - logloss:  0.3802 - val_auc:  0.7583 - val_logloss:  0.3797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 68.49it/s]\n",
      "8it [00:00, 70.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n",
      "2s - loss:  7.2190 - auc:  0.7603 - logloss:  0.3797 - val_auc:  0.7588 - val_logloss:  0.3792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 73.32it/s]\n",
      "7it [00:00, 69.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20\n",
      "2s - loss:  7.2182 - auc:  0.7623 - logloss:  0.3792 - val_auc:  0.7602 - val_logloss:  0.3788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 73.29it/s]\n",
      "7it [00:00, 69.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n",
      "2s - loss:  7.2178 - auc:  0.7623 - logloss:  0.3784 - val_auc:  0.7605 - val_logloss:  0.3786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 73.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "2s - loss:  7.2171 - auc:  0.7649 - logloss:  0.3778 - val_auc:  0.7614 - val_logloss:  0.3783\n"
     ]
    }
   ],
   "source": [
    "model_name = 'DNN'\n",
    "epoch = 20\n",
    "batch_size = 300\n",
    "\n",
    "model = WDL(linear_feature_columns=[], \n",
    "            dnn_feature_columns=dnn_feature_columns, \n",
    "            dnn_use_bn=True,\n",
    "            l2_reg_dnn=0.1, \n",
    "            l2_reg_embedding = 0.0001, \n",
    "            dnn_hidden_units=(128,64), \n",
    "            init_std=1, \n",
    "            dnn_dropout=0.5, \n",
    "            task='binary', \n",
    "            dnn_activation='relu', \n",
    "            device=device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.1, amsgrad=True)\n",
    "model.compile(optimizer, 'binary_crossentropy',metrics=['auc','logloss'])\n",
    "res, pred1 = model.fit(train_model_input,  train_label.values.astype(int), batch_size=batch_size, epochs=epoch, validation_data=(test_model_input1,test_label1),verbose=1)\n",
    "\n",
    "results[model_name] = model, res, pred1, test_label1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WDL\n",
    "Wide and Deep model [3] is widely accepted in real industrial applications. Compared with DNN, it has an additional linear model besides the deep model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:00, 54.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Train on 46361 samples, validate on 11690 samples, 155 steps per epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 58.74it/s]\n",
      "6it [00:00, 57.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2s - loss:  7.3520 - auc:  0.5224 - logloss:  0.5105 - val_auc:  0.6203 - val_logloss:  0.4442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 60.02it/s]\n",
      "6it [00:00, 57.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "2s - loss:  7.2607 - auc:  0.6699 - logloss:  0.4192 - val_auc:  0.6906 - val_logloss:  0.4106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 60.04it/s]\n",
      "6it [00:00, 57.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "2s - loss:  7.2443 - auc:  0.7224 - logloss:  0.4029 - val_auc:  0.7144 - val_logloss:  0.4013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 56.74it/s]\n",
      "6it [00:00, 57.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "2s - loss:  7.2348 - auc:  0.7429 - logloss:  0.3938 - val_auc:  0.7295 - val_logloss:  0.3951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 59.90it/s]\n",
      "6it [00:00, 57.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "2s - loss:  7.2279 - auc:  0.7563 - logloss:  0.3865 - val_auc:  0.7390 - val_logloss:  0.3908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 60.09it/s]\n",
      "6it [00:00, 57.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "2s - loss:  7.2228 - auc:  0.7659 - logloss:  0.3815 - val_auc:  0.7451 - val_logloss:  0.3869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 60.06it/s]\n",
      "6it [00:00, 57.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "2s - loss:  7.2189 - auc:  0.7719 - logloss:  0.3776 - val_auc:  0.7494 - val_logloss:  0.3842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 60.05it/s]\n",
      "6it [00:00, 57.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "2s - loss:  7.2156 - auc:  0.7768 - logloss:  0.3743 - val_auc:  0.7537 - val_logloss:  0.3819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 60.03it/s]\n",
      "6it [00:00, 57.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n",
      "2s - loss:  7.2134 - auc:  0.7801 - logloss:  0.3719 - val_auc:  0.7565 - val_logloss:  0.3805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 60.05it/s]\n",
      "6it [00:00, 57.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n",
      "2s - loss:  7.2113 - auc:  0.7829 - logloss:  0.3702 - val_auc:  0.7591 - val_logloss:  0.3788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 60.09it/s]\n",
      "6it [00:00, 57.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "2s - loss:  7.2097 - auc:  0.7866 - logloss:  0.3683 - val_auc:  0.7610 - val_logloss:  0.3779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 56.76it/s]\n",
      "6it [00:00, 57.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "2s - loss:  7.2085 - auc:  0.7891 - logloss:  0.3670 - val_auc:  0.7622 - val_logloss:  0.3770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 60.03it/s]\n",
      "6it [00:00, 56.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "2s - loss:  7.2071 - auc:  0.7908 - logloss:  0.3657 - val_auc:  0.7638 - val_logloss:  0.3765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 59.85it/s]\n",
      "6it [00:00, 57.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n",
      "2s - loss:  7.2061 - auc:  0.7920 - logloss:  0.3650 - val_auc:  0.7656 - val_logloss:  0.3756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 59.98it/s]\n",
      "6it [00:00, 57.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20\n",
      "2s - loss:  7.2050 - auc:  0.7942 - logloss:  0.3637 - val_auc:  0.7663 - val_logloss:  0.3749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 59.91it/s]\n",
      "6it [00:00, 56.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "2s - loss:  7.2041 - auc:  0.7977 - logloss:  0.3627 - val_auc:  0.7668 - val_logloss:  0.3743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 59.81it/s]\n",
      "6it [00:00, 57.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n",
      "2s - loss:  7.2030 - auc:  0.7977 - logloss:  0.3617 - val_auc:  0.7677 - val_logloss:  0.3738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 60.01it/s]\n",
      "6it [00:00, 57.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20\n",
      "2s - loss:  7.2023 - auc:  0.7991 - logloss:  0.3611 - val_auc:  0.7690 - val_logloss:  0.3738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 60.02it/s]\n",
      "6it [00:00, 56.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n",
      "2s - loss:  7.2011 - auc:  0.8023 - logloss:  0.3596 - val_auc:  0.7700 - val_logloss:  0.3725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:02, 59.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "2s - loss:  7.2000 - auc:  0.8031 - logloss:  0.3589 - val_auc:  0.7708 - val_logloss:  0.3719\n"
     ]
    }
   ],
   "source": [
    "model_name = 'WDL'\n",
    "epoch = 20\n",
    "batch_size = 300\n",
    "\n",
    "model = WDL(linear_feature_columns=linear_feature_columns, \n",
    "            dnn_feature_columns=dnn_feature_columns, \n",
    "            dnn_use_bn=True,\n",
    "            l2_reg_dnn=0.1, \n",
    "            l2_reg_embedding = 0.0001, \n",
    "            dnn_hidden_units=(128,64), \n",
    "            init_std=1, \n",
    "            dnn_dropout=0.5, \n",
    "            task='binary', \n",
    "            dnn_activation='relu', \n",
    "            device=device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.05, amsgrad=True)\n",
    "model.compile(optimizer, 'binary_crossentropy',metrics=['auc','logloss'])\n",
    "res, pred1 = model.fit(train_model_input,  train_label.values.astype(int), batch_size=batch_size, epochs=epoch, validation_data=(test_model_input1,test_label1),verbose=1)\n",
    "\n",
    "results[model_name] = model, res, pred1, test_label1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIN\n",
    "Deep Interest Network [4] is an attention-based model in recommendation systems that has been proven successful in Alibaba. We use this as our second baseline, replacing the user’s historical item sequences with user’s historical voucher sequences to adapt to the VRR prediction task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 6776/46361 [00:00<00:00, 67757.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start generating x y data\n",
      "['session_id', 'user_gender', 'user_age_level', 'user_purchase_level', 'promotion_id', 'hist_promotion_id', 'voucher_min_spend', 'voucher_discount', 'user_trd__orders_cnt_hist', 'user_trd__actual_gmv_usd_hist', 'user_trd__orders_cnt_platform_discount_hist', 'user_trd__max_gmv_usd_hist', 'user_trd__avg_gmv_usd_hist', 'user_trd__min_gmv_usd_hist', 'keys_length']\n",
      "handling hist_list_features Feature: hist_promotion_id\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46361/46361 [00:00<00:00, 71214.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoderExt transforming...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11690/11690 [00:00<00:00, 68780.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start generating x y data\n",
      "['session_id', 'user_gender', 'user_age_level', 'user_purchase_level', 'promotion_id', 'hist_promotion_id', 'voucher_min_spend', 'voucher_discount', 'user_trd__orders_cnt_hist', 'user_trd__actual_gmv_usd_hist', 'user_trd__orders_cnt_platform_discount_hist', 'user_trd__max_gmv_usd_hist', 'user_trd__avg_gmv_usd_hist', 'user_trd__min_gmv_usd_hist', 'keys_length']\n",
      "handling hist_list_features Feature: hist_promotion_id\n",
      "LabelEncoderExt transforming...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "def get_xy_fd(dataset):\n",
    "    print (\"start generating x y data\")\n",
    "    \n",
    "    dnn_feature_columns = []\n",
    "    dnn_feature_columns += [SparseFeat(feat, len(label_encoder[feat]), embedding_dim = 16) \n",
    "                            for feat in ['session_id','user_gender','user_age_level','user_purchase_level', 'promotion_id']]\n",
    "    \n",
    "    dnn_feature_columns += [VarLenSparseFeat(SparseFeat('hist_promotion_id', len(label_encoder[\"promotion_id\"]), embedding_dim=16), sequence_size)]\n",
    "    \n",
    "    dnn_feature_columns += [DenseFeat(feat, 1, )  for feat in dense_feature]\n",
    "    dnn_feature_columns += [DenseFeat(feat, 1, )  for feat in ['keys_length']]\n",
    "\n",
    "    feature_names = get_feature_names(dnn_feature_columns)\n",
    "    print (feature_names)\n",
    "    \n",
    "    behavior_feature_list = ['promotion_id']\n",
    "\n",
    "    y, x = gen_dmbgn_input_data(feature_names, dataset, target, label_encoder, 6, sparse_feature, hist_list_features)\n",
    "    return x, y, dnn_feature_columns, behavior_feature_list\n",
    "\n",
    "sequence_size = 6\n",
    "embedding_dim1 = 16\n",
    "\n",
    "x, y, dnn_feature_columns, behavior_feature_list = get_xy_fd(dctr_train)\n",
    "test_model_input1, test_label1, _, _ = get_xy_fd(dctr_v1)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DIN(\n",
       "  (embedding_dict): ModuleDict(\n",
       "    (session_id): Embedding(58052, 16)\n",
       "    (user_gender): Embedding(4, 16)\n",
       "    (user_age_level): Embedding(10, 16)\n",
       "    (user_purchase_level): Embedding(12, 16)\n",
       "    (promotion_id): Embedding(462, 16)\n",
       "    (hist_promotion_id): Embedding(462, 16)\n",
       "  )\n",
       "  (linear_model): Linear(\n",
       "    (embedding_dict): ModuleDict()\n",
       "  )\n",
       "  (out): PredictionLayer()\n",
       "  (attention): HistAttentionSeqPoolingLayer(\n",
       "    (local_att): AttentionUnit(\n",
       "      (dnn): DNN(\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (linears): ModuleList(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (activation_layers): ModuleList(\n",
       "          (0): PReLU(num_parameters=1)\n",
       "        )\n",
       "      )\n",
       "      (dense): Linear(in_features=64, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (dnn): DNN(\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (linears): ModuleList(\n",
       "      (0): Linear(in_features=104, out_features=128, bias=True)\n",
       "      (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "    )\n",
       "    (bn): ModuleList(\n",
       "      (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (activation_layers): ModuleList(\n",
       "      (0): ReLU(inplace=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (dnn_linear): Linear(in_features=64, out_features=1, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'DIN'\n",
    "\n",
    "model = DIN(dnn_feature_columns, \n",
    "            behavior_feature_list, \n",
    "            target_emb_dim_aft=0, \n",
    "            device=device, \n",
    "            att_activation='prelu', \n",
    "            att_weight_normalization=False, \n",
    "            dnn_activation='relu', \n",
    "            l2_reg_dnn=0.1, \n",
    "            l2_reg_embedding = 0.0001, \n",
    "            dnn_hidden_units=(128,64), \n",
    "            att_hidden_size=(64,), \n",
    "            init_std=1, \n",
    "            dnn_dropout=0.5, \n",
    "            dnn_use_bn=True)\n",
    "\n",
    "\n",
    "model.embedding_dict['promotion_id'].requires_grad = True\n",
    "model.embedding_dict['promotion_id'].weight.requires_grad = True\n",
    "\n",
    "model.embedding_dict['hist_promotion_id'].requires_grad = True\n",
    "model.embedding_dict['hist_promotion_id'].weight.requires_grad = True\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.05, amsgrad=True)\n",
    "model.compile(optimizer, 'binary_crossentropy', metrics=['auc', 'logloss'])\n",
    "\n",
    "loss_func = model.loss_func\n",
    "optim = model.optim\n",
    "metrics = model.metrics\n",
    "feature_index = model.feature_index\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use 8 GPUs!\n"
     ]
    }
   ],
   "source": [
    "device_ids = [i for i in range(torch.cuda.device_count())]\n",
    "device_count = len(device_ids)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model = torch.nn.DataParallel(model, device_ids)\n",
    "    \n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 46361 samples, validate on 11690 samples, 155 steps per epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:39,  3.92it/s]\n",
      "2it [00:00, 16.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "Epoch Time : 40\n",
      "40s - loss:  0.4707 - auc:  0.6202 - logloss:  0.4675 - val_auc:  0.7099 - val_logloss:  0.4010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:09, 17.15it/s]\n",
      "2it [00:00, 16.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "Epoch Time : 10\n",
      "10s - loss:  0.3941 - auc:  0.7340 - logloss:  0.3914 - val_auc:  0.7483 - val_logloss:  0.3833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:08, 17.38it/s]\n",
      "2it [00:00, 16.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "Epoch Time : 10\n",
      "10s - loss:  0.3821 - auc:  0.7603 - logloss:  0.3799 - val_auc:  0.7601 - val_logloss:  0.3787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:09, 17.12it/s]\n",
      "2it [00:00, 16.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "Epoch Time : 10\n",
      "10s - loss:  0.3743 - auc:  0.7740 - logloss:  0.3722 - val_auc:  0.7682 - val_logloss:  0.3741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:09, 17.05it/s]\n",
      "2it [00:00, 16.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "Epoch Time : 10\n",
      "10s - loss:  0.3682 - auc:  0.7844 - logloss:  0.3663 - val_auc:  0.7699 - val_logloss:  0.3720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:09, 16.79it/s]\n",
      "2it [00:00, 16.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "Epoch Time : 10\n",
      "10s - loss:  0.3645 - auc:  0.7914 - logloss:  0.3628 - val_auc:  0.7730 - val_logloss:  0.3711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:09, 17.11it/s]\n",
      "2it [00:00, 16.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "Epoch Time : 10\n",
      "10s - loss:  0.3598 - auc:  0.8003 - logloss:  0.3581 - val_auc:  0.7780 - val_logloss:  0.3694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:09, 17.11it/s]\n",
      "2it [00:00, 16.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "Epoch Time : 10\n",
      "10s - loss:  0.3559 - auc:  0.8047 - logloss:  0.3547 - val_auc:  0.7757 - val_logloss:  0.3688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:09, 16.94it/s]\n",
      "2it [00:00, 16.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n",
      "Epoch Time : 10\n",
      "10s - loss:  0.3514 - auc:  0.8105 - logloss:  0.3502 - val_auc:  0.7778 - val_logloss:  0.3679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:09, 16.98it/s]\n",
      "2it [00:00, 16.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n",
      "Epoch Time : 10\n",
      "10s - loss:  0.3469 - auc:  0.8174 - logloss:  0.3459 - val_auc:  0.7779 - val_logloss:  0.3741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:08, 17.30it/s]\n",
      "2it [00:00, 16.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "Epoch Time : 10\n",
      "10s - loss:  0.3429 - auc:  0.8226 - logloss:  0.3419 - val_auc:  0.7693 - val_logloss:  0.3733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:09, 17.03it/s]\n",
      "2it [00:00, 16.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "Epoch Time : 10\n",
      "10s - loss:  0.3376 - auc:  0.8299 - logloss:  0.3368 - val_auc:  0.7740 - val_logloss:  0.3720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:09, 17.13it/s]\n",
      "2it [00:00, 16.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "Epoch Time : 10\n",
      "10s - loss:  0.3302 - auc:  0.8397 - logloss:  0.3294 - val_auc:  0.7704 - val_logloss:  0.3825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:08, 17.54it/s]\n",
      "2it [00:00, 16.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n",
      "Epoch Time : 10\n",
      "10s - loss:  0.3222 - auc:  0.8499 - logloss:  0.3216 - val_auc:  0.7709 - val_logloss:  0.3821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:09, 16.94it/s]\n",
      "2it [00:00, 16.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20\n",
      "Epoch Time : 10\n",
      "10s - loss:  0.3051 - auc:  0.8695 - logloss:  0.3043 - val_auc:  0.7629 - val_logloss:  0.4008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:08, 17.51it/s]\n",
      "2it [00:00, 16.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "Epoch Time : 10\n",
      "10s - loss:  0.2778 - auc:  0.8976 - logloss:  0.2773 - val_auc:  0.7556 - val_logloss:  0.4196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:09, 16.64it/s]\n",
      "2it [00:00, 16.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n",
      "Epoch Time : 10\n",
      "10s - loss:  0.2242 - auc:  0.9379 - logloss:  0.2238 - val_auc:  0.7391 - val_logloss:  0.4889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:08, 17.29it/s]\n",
      "2it [00:00, 16.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20\n",
      "Epoch Time : 10\n",
      "10s - loss:  0.1470 - auc:  0.9725 - logloss:  0.1464 - val_auc:  0.7237 - val_logloss:  0.6083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:09, 16.95it/s]\n",
      "2it [00:00, 16.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n",
      "Epoch Time : 10\n",
      "10s - loss:  0.0817 - auc:  0.9900 - logloss:  0.0800 - val_auc:  0.7144 - val_logloss:  0.7021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:08, 17.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "Epoch Time : 10\n",
      "10s - loss:  0.0357 - auc:  0.9972 - logloss:  0.0353 - val_auc:  0.7168 - val_logloss:  0.8786\n"
     ]
    }
   ],
   "source": [
    "epoch = 20\n",
    "batch_size = 300\n",
    "res, pred1 = fit(model, feature_index, optim, metrics, loss_func, x, y, batch_size=batch_size, epochs=epoch, validation_data=(test_model_input1,test_label1),verbose=1, device=device, device_count=device_count)\n",
    "\n",
    "results[model_name] = model, res, pred1, test_label1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Method: DMBGN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DMBGN-AvgPooling\n",
    "Instead of using Higher-order Graph Neural Networks to model user-voucher-item relationships, it directly takes an average of pre-trained item embeddings from user behavior happening both before and after voucher collection. For target UVG, it only takes an average of pre-collection item embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "286735it [00:38, 7519.09it/s]\n"
     ]
    }
   ],
   "source": [
    "def process_pretrain_emb(emb, emb_size = 16, spliter = \" \"):\n",
    "    return np.zeros(emb_size, dtype=np.float32) if emb == 'nan' else np.array(emb.split(spliter), dtype=np.float32)\n",
    "\n",
    "item_df[['atc_emb', 'ord_emb']] = item_df[['atc_emb', 'ord_emb']].astype('str')\n",
    "item_emb_dict = {}\n",
    "for index, row in tqdm(item_df.iterrows()):\n",
    "    item_emb_dict[row['item_id']] = process_pretrain_emb(row['atc_emb']), process_pretrain_emb(row['ord_emb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoderExt transforming...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1118593it [02:16, 8215.83it/s]\n",
      "100%|██████████| 58052/58052 [00:00<00:00, 90100.22it/s]\n",
      "100%|██████████| 58052/58052 [00:00<00:00, 310334.38it/s]\n"
     ]
    }
   ],
   "source": [
    "emb_size = 16\n",
    "sid_emb_dict_tmp = {}\n",
    "\n",
    "session_df['sid_enc'] = label_encoder['session_id'].transform(session_df['session_id'])\n",
    "\n",
    "for index, row in tqdm(session_df.iterrows()):\n",
    "    sid = row['sid_enc']\n",
    "    if sid not in sid_emb_dict_tmp:\n",
    "        sid_emb_dict_tmp[row['sid_enc']] = np.zeros(emb_size, dtype=np.float32), np.zeros(emb_size, dtype=np.float32), 0, 0\n",
    "    \n",
    "    if row['rk'] > 6:\n",
    "        continue\n",
    "    \n",
    "    emb_bef, emb_aft, cnt_bef, cnt_aft = sid_emb_dict_tmp.get(sid)\n",
    "    item_atc_emb, item_ord_emb = item_emb_dict.get(row['item_id'])\n",
    "    if row['type'] == 'bef':\n",
    "        emb_bef += item_atc_emb if row['action_type'] == 'cart' else item_ord_emb\n",
    "        cnt_bef += 1\n",
    "    else:\n",
    "        emb_aft += item_atc_emb if row['action_type'] == 'cart' else item_ord_emb\n",
    "        cnt_aft += 1\n",
    "    sid_emb_dict_tmp[sid] = emb_bef, emb_aft, cnt_bef, cnt_aft\n",
    "\n",
    "sid_emb_dict = {}\n",
    "for sid, value in tqdm(sid_emb_dict_tmp.items()):\n",
    "    emb_bef, emb_aft, cnt_bef, cnt_aft = value\n",
    "    sid_emb_dict[sid] = np.concatenate((emb_bef/(1.0*cnt_bef), emb_aft/(1.0*cnt_aft)), axis=0)\n",
    "\n",
    "sid_emb_dict_bef = {}\n",
    "for sid, value in tqdm(sid_emb_dict_tmp.items()):\n",
    "    emb_bef, emb_aft, cnt_bef, cnt_aft = value\n",
    "    sid_emb_dict_bef[sid] = emb_bef/(1.0*cnt_bef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_emb_ts(emb_dic, requires_grad = False, emb_size = 16, lbe = None):\n",
    "    if lbe is None:\n",
    "        raise Exception(\"Encoder is empty\")\n",
    "        \n",
    "    indices = lbe.transform([str(val) for val in emb_dic.keys()])\n",
    "    session_size = int(len(lbe))\n",
    "    \n",
    "    ts_emb = torch.rand(session_size, emb_size, dtype = torch.float)\n",
    "    for i, (key, emb) in tqdm(enumerate(emb_dic.items())):\n",
    "        ts_emb[indices[i]] = torch.FloatTensor(emb)\n",
    "    emb_ts = torch.nn.Embedding.from_pretrained(ts_emb)\n",
    "    emb_ts.weight.requires_grad = requires_grad\n",
    "    return emb_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4914it [00:00, 49133.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoderExt transforming...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "58052it [00:01, 52966.06it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(58052, 32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sid_emb_ts = init_emb_ts(sid_emb_dict, emb_size = 32, lbe=label_encoder['session_id'])\n",
    "sid_emb_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xy_fd(dataset):\n",
    "    print (\"start generating x y data\")\n",
    "    \n",
    "    dnn_feature_columns = []\n",
    "    dnn_feature_columns += [SparseFeat(feat, len(label_encoder[feat]), embedding_dim = embedding_dim1) for feat in ['user_gender','user_age_level','user_purchase_level']]\n",
    "    dnn_feature_columns += [SparseFeat(feat, len(label_encoder['promotion_id']), embedding_dim = embedding_dim2) for feat in ['session_id']]\n",
    "    dnn_feature_columns += [SparseFeat(feat, len(label_encoder[feat]), embedding_dim = embedding_dim2) for feat in ['promotion_id']]\n",
    "    dnn_feature_columns += [SparseFeat(feat, len(label_encoder['session_id']), embedding_dim = embedding_dim1) for feat in ['sid']]\n",
    "    \n",
    "    dnn_feature_columns += [VarLenSparseFeat(SparseFeat('hist_promotion_id', len(label_encoder[\"promotion_id\"]), embedding_dim=embedding_dim2), sequence_size)]\n",
    "    dnn_feature_columns += [VarLenSparseFeat(SparseFeat('hist_session_id', len(label_encoder[\"session_id\"]), embedding_dim=embedding_dim2), sequence_size)]\n",
    "\n",
    "    dnn_feature_columns += [DenseFeat(feat, 1, )  for feat in dense_feature]\n",
    "    dnn_feature_columns += [DenseFeat(feat, 1, )  for feat in ['keys_length']]\n",
    "\n",
    "    feature_names = get_feature_names(dnn_feature_columns)\n",
    "    print (\"feature_names:\", feature_names)\n",
    "    \n",
    "    behavior_feature_list = ['promotion_id', 'session_id']\n",
    "    dataset['sid'] = dataset['session_id']\n",
    "    y, x = gen_dmbgn_input_data(feature_names, dataset, target, label_encoder, 6, sparse_feature, hist_list_features)\n",
    "    x['session_id'] = x['promotion_id']\n",
    "    return x, y, dnn_feature_columns, behavior_feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 14452/46361 [00:00<00:00, 69124.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "start generating x y data\n",
      "feature_names: ['user_gender', 'user_age_level', 'user_purchase_level', 'session_id', 'promotion_id', 'sid', 'hist_promotion_id', 'hist_session_id', 'voucher_min_spend', 'voucher_discount', 'user_trd__orders_cnt_hist', 'user_trd__actual_gmv_usd_hist', 'user_trd__orders_cnt_platform_discount_hist', 'user_trd__max_gmv_usd_hist', 'user_trd__avg_gmv_usd_hist', 'user_trd__min_gmv_usd_hist', 'keys_length']\n",
      "handling hist_list_features Feature: hist_promotion_id\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46361/46361 [00:00<00:00, 67785.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoderExt transforming...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 14523/46361 [00:00<00:00, 69013.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "handling hist_list_features Feature: hist_session_id\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46361/46361 [00:00<00:00, 70162.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoderExt transforming...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11690/11690 [00:00<00:00, 67800.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start generating x y data\n",
      "feature_names: ['user_gender', 'user_age_level', 'user_purchase_level', 'session_id', 'promotion_id', 'sid', 'hist_promotion_id', 'hist_session_id', 'voucher_min_spend', 'voucher_discount', 'user_trd__orders_cnt_hist', 'user_trd__actual_gmv_usd_hist', 'user_trd__orders_cnt_platform_discount_hist', 'user_trd__max_gmv_usd_hist', 'user_trd__avg_gmv_usd_hist', 'user_trd__min_gmv_usd_hist', 'keys_length']\n",
      "handling hist_list_features Feature: hist_promotion_id\n",
      "LabelEncoderExt transforming...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 11690/11690 [00:00<00:00, 67981.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "handling hist_list_features Feature: hist_session_id\n",
      "LabelEncoderExt transforming...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "sequence_size = 6\n",
    "embedding_dim1 = 16 # pid\n",
    "embedding_dim2 = sid_emb_ts.weight.shape[1] #sid\n",
    "print(embedding_dim2)\n",
    "\n",
    "x, y, dnn_feature_columns, behavior_feature_list = get_xy_fd(dctr_train)\n",
    "test_model_input1, test_label1, _, _ = get_xy_fd(dctr_v1)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DMBGN(\n",
       "  (embedding_dict): ModuleDict(\n",
       "    (user_gender): Embedding(4, 16)\n",
       "    (user_age_level): Embedding(10, 16)\n",
       "    (user_purchase_level): Embedding(12, 16)\n",
       "    (session_id): Embedding(462, 32)\n",
       "    (promotion_id): Embedding(462, 32)\n",
       "    (sid): Embedding(58052, 16)\n",
       "    (hist_promotion_id): Embedding(462, 32)\n",
       "    (hist_session_id): Embedding(58052, 32)\n",
       "  )\n",
       "  (linear_model): Linear(\n",
       "    (embedding_dict): ModuleDict()\n",
       "  )\n",
       "  (out): PredictionLayer()\n",
       "  (attention): HistAttentionSeqPoolingLayer(\n",
       "    (local_att): AttentionUnit(\n",
       "      (dnn): DNN(\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (linears): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=64, bias=True)\n",
       "        )\n",
       "        (activation_layers): ModuleList(\n",
       "          (0): PReLU(num_parameters=1)\n",
       "        )\n",
       "      )\n",
       "      (dense): Linear(in_features=64, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (dnn): DNN(\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (linears): ModuleList(\n",
       "      (0): Linear(in_features=209, out_features=128, bias=True)\n",
       "      (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "    )\n",
       "    (bn): ModuleList(\n",
       "      (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (activation_layers): ModuleList(\n",
       "      (0): ReLU(inplace=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (dnn_linear): Linear(in_features=64, out_features=1, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'DMBGN_AvgPooling'\n",
    "\n",
    "model = DMBGN(dnn_feature_columns, \n",
    "            behavior_feature_list, \n",
    "            target_emb_dim_aft=0, \n",
    "            sequence_size=6,\n",
    "            device=device, \n",
    "            att_activation='prelu', \n",
    "            att_weight_normalization=False, \n",
    "            dnn_activation='relu', \n",
    "            l2_reg_dnn=0.1, \n",
    "            l2_reg_embedding = 0.0001, \n",
    "            dnn_hidden_units=(128,64), \n",
    "            att_hidden_size=(64,), \n",
    "            init_std=1, \n",
    "            dnn_dropout=0.5, \n",
    "            dnn_use_bn=True)\n",
    "\n",
    "model.embedding_dict['hist_session_id'] = sid_emb_ts\n",
    "model.embedding_dict['hist_session_id'].requires_grad = False\n",
    "model.embedding_dict['hist_session_id'].weight.requires_grad = False\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.05, amsgrad=True)\n",
    "model.compile(optimizer, 'binary_crossentropy', metrics=['auc', 'logloss'])\n",
    "\n",
    "\n",
    "loss_func = model.loss_func\n",
    "optim = model.optim\n",
    "metrics = model.metrics\n",
    "feature_index = model.feature_index\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use 8 GPUs!\n"
     ]
    }
   ],
   "source": [
    "device_ids = [i for i in range(torch.cuda.device_count())]\n",
    "device_count = len(device_ids)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Use\", device_count, \"GPUs!\")\n",
    "    model = torch.nn.DataParallel(model, device_ids)\n",
    "    \n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 46361 samples, validate on 11690 samples, 155 steps per epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:11, 13.16it/s]\n",
      "2it [00:00, 13.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "Epoch Time : 13\n",
      "13s - loss:  1.1236 - auc:  0.6142 - logloss:  0.4727 - val_auc:  0.7144 - val_logloss:  0.4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:11, 13.52it/s]\n",
      "2it [00:00, 13.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "Epoch Time : 13\n",
      "13s - loss:  0.8716 - auc:  0.7377 - logloss:  0.3899 - val_auc:  0.7513 - val_logloss:  0.3819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:11, 13.36it/s]\n",
      "2it [00:00, 12.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "Epoch Time : 13\n",
      "13s - loss:  0.7766 - auc:  0.7605 - logloss:  0.3793 - val_auc:  0.7605 - val_logloss:  0.3782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:11, 13.70it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "Epoch Time : 13\n",
      "13s - loss:  0.7427 - auc:  0.7725 - logloss:  0.3734 - val_auc:  0.7623 - val_logloss:  0.3763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:11, 13.32it/s]\n",
      "2it [00:00, 12.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "Epoch Time : 13\n",
      "13s - loss:  0.7199 - auc:  0.7804 - logloss:  0.3687 - val_auc:  0.7682 - val_logloss:  0.3737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:11, 13.84it/s]\n",
      "2it [00:00, 13.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "Epoch Time : 12\n",
      "12s - loss:  0.6998 - auc:  0.7863 - logloss:  0.3654 - val_auc:  0.7735 - val_logloss:  0.3708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:11, 13.33it/s]\n",
      "2it [00:00, 13.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "Epoch Time : 13\n",
      "13s - loss:  0.6897 - auc:  0.7947 - logloss:  0.3607 - val_auc:  0.7747 - val_logloss:  0.3711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:11, 13.74it/s]\n",
      "2it [00:00, 12.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "Epoch Time : 12\n",
      "12s - loss:  0.6840 - auc:  0.7990 - logloss:  0.3588 - val_auc:  0.7777 - val_logloss:  0.3697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:11, 13.37it/s]\n",
      "2it [00:00, 13.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n",
      "Epoch Time : 13\n",
      "13s - loss:  0.6780 - auc:  0.8030 - logloss:  0.3550 - val_auc:  0.7749 - val_logloss:  0.3700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:11, 13.84it/s]\n",
      "2it [00:00, 13.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n",
      "Epoch Time : 12\n",
      "12s - loss:  0.6729 - auc:  0.8064 - logloss:  0.3530 - val_auc:  0.7736 - val_logloss:  0.3708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:11, 13.43it/s]\n",
      "2it [00:00, 13.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "Epoch Time : 13\n",
      "13s - loss:  0.6715 - auc:  0.8106 - logloss:  0.3502 - val_auc:  0.7755 - val_logloss:  0.3707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:11, 13.72it/s]\n",
      "2it [00:00, 13.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "Epoch Time : 12\n",
      "12s - loss:  0.6650 - auc:  0.8156 - logloss:  0.3471 - val_auc:  0.7719 - val_logloss:  0.3710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:11, 13.30it/s]\n",
      "2it [00:00, 13.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "Epoch Time : 13\n",
      "13s - loss:  0.6571 - auc:  0.8199 - logloss:  0.3439 - val_auc:  0.7794 - val_logloss:  0.3701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:11, 13.64it/s]\n",
      "2it [00:00, 13.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n",
      "Epoch Time : 13\n",
      "13s - loss:  0.6547 - auc:  0.8263 - logloss:  0.3398 - val_auc:  0.7774 - val_logloss:  0.3701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:11, 13.40it/s]\n",
      "2it [00:00, 12.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20\n",
      "Epoch Time : 13\n",
      "13s - loss:  0.6490 - auc:  0.8373 - logloss:  0.3323 - val_auc:  0.7707 - val_logloss:  0.3808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:11, 13.86it/s]\n",
      "2it [00:00, 12.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "Epoch Time : 12\n",
      "12s - loss:  0.6328 - auc:  0.8525 - logloss:  0.3198 - val_auc:  0.7620 - val_logloss:  0.3908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:11, 13.47it/s]\n",
      "2it [00:00, 13.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n",
      "Epoch Time : 13\n",
      "13s - loss:  0.6082 - auc:  0.8843 - logloss:  0.2933 - val_auc:  0.7481 - val_logloss:  0.4176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:11, 13.79it/s]\n",
      "2it [00:00, 13.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20\n",
      "Epoch Time : 12\n",
      "12s - loss:  0.5510 - auc:  0.9301 - logloss:  0.2383 - val_auc:  0.7324 - val_logloss:  0.4873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:11, 13.42it/s]\n",
      "2it [00:00, 13.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n",
      "Epoch Time : 13\n",
      "13s - loss:  0.4733 - auc:  0.9703 - logloss:  0.1587 - val_auc:  0.7134 - val_logloss:  0.6181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:11, 13.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "Epoch Time : 12\n",
      "12s - loss:  0.4012 - auc:  0.9902 - logloss:  0.0840 - val_auc:  0.7126 - val_logloss:  0.7805\n"
     ]
    }
   ],
   "source": [
    "epoch = 20\n",
    "batch_size = 300\n",
    "res, pred1 = fit(model, feature_index, optim, metrics, loss_func, x, y, batch_size=batch_size, epochs=epoch, validation_data=(test_model_input1,test_label1),verbose=1, device=device, device_count=device_count)\n",
    "\n",
    "results[model_name] = model, res, pred1, test_label1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DMBGN-Pretrained\n",
    "It uses the same weight parameters of Higher-order GNN learned during the voucher embedding pre-training as mentioned in Section 3.3. The values of weight parameters are not further updated during the main task training for DMBGN-Pretrained variant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoderExt fitting...\n",
      "LabelEncoderExt transforming...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>session_id</th>\n",
       "      <th>promotion_id</th>\n",
       "      <th>voucher_min_spend</th>\n",
       "      <th>voucher_discount_amount</th>\n",
       "      <th>voucher_collect_time</th>\n",
       "      <th>item_id</th>\n",
       "      <th>action_type</th>\n",
       "      <th>type</th>\n",
       "      <th>rk</th>\n",
       "      <th>action_time</th>\n",
       "      <th>item_category_id</th>\n",
       "      <th>item_brand_id</th>\n",
       "      <th>item_price_level</th>\n",
       "      <th>sid_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9180</td>\n",
       "      <td>20</td>\n",
       "      <td>4999</td>\n",
       "      <td>600</td>\n",
       "      <td>10999</td>\n",
       "      <td>85356</td>\n",
       "      <td>cart</td>\n",
       "      <td>bef</td>\n",
       "      <td>12</td>\n",
       "      <td>6874</td>\n",
       "      <td>9567</td>\n",
       "      <td>106903</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>9180</td>\n",
       "      <td>20</td>\n",
       "      <td>4999</td>\n",
       "      <td>600</td>\n",
       "      <td>10999</td>\n",
       "      <td>85352</td>\n",
       "      <td>cart</td>\n",
       "      <td>bef</td>\n",
       "      <td>11</td>\n",
       "      <td>6850</td>\n",
       "      <td>9567</td>\n",
       "      <td>106903</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>9180</td>\n",
       "      <td>20</td>\n",
       "      <td>4999</td>\n",
       "      <td>600</td>\n",
       "      <td>10999</td>\n",
       "      <td>85351</td>\n",
       "      <td>cart</td>\n",
       "      <td>bef</td>\n",
       "      <td>10</td>\n",
       "      <td>6838</td>\n",
       "      <td>9567</td>\n",
       "      <td>106903</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>9180</td>\n",
       "      <td>20</td>\n",
       "      <td>4999</td>\n",
       "      <td>600</td>\n",
       "      <td>10999</td>\n",
       "      <td>92250</td>\n",
       "      <td>cart</td>\n",
       "      <td>bef</td>\n",
       "      <td>9</td>\n",
       "      <td>6871</td>\n",
       "      <td>9567</td>\n",
       "      <td>106903</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>9180</td>\n",
       "      <td>20</td>\n",
       "      <td>4999</td>\n",
       "      <td>600</td>\n",
       "      <td>10999</td>\n",
       "      <td>88965</td>\n",
       "      <td>cart</td>\n",
       "      <td>bef</td>\n",
       "      <td>8</td>\n",
       "      <td>6838</td>\n",
       "      <td>2272</td>\n",
       "      <td>106903</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118588</th>\n",
       "      <td>0</td>\n",
       "      <td>17339</td>\n",
       "      <td>310</td>\n",
       "      <td>349</td>\n",
       "      <td>30</td>\n",
       "      <td>119218</td>\n",
       "      <td>19882</td>\n",
       "      <td>order</td>\n",
       "      <td>aft</td>\n",
       "      <td>3</td>\n",
       "      <td>129021</td>\n",
       "      <td>12057</td>\n",
       "      <td>56645</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118589</th>\n",
       "      <td>0</td>\n",
       "      <td>17339</td>\n",
       "      <td>310</td>\n",
       "      <td>349</td>\n",
       "      <td>30</td>\n",
       "      <td>119218</td>\n",
       "      <td>1333</td>\n",
       "      <td>order</td>\n",
       "      <td>aft</td>\n",
       "      <td>4</td>\n",
       "      <td>129021</td>\n",
       "      <td>13895</td>\n",
       "      <td>56645</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118590</th>\n",
       "      <td>0</td>\n",
       "      <td>17339</td>\n",
       "      <td>310</td>\n",
       "      <td>349</td>\n",
       "      <td>30</td>\n",
       "      <td>119218</td>\n",
       "      <td>65011</td>\n",
       "      <td>order</td>\n",
       "      <td>aft</td>\n",
       "      <td>5</td>\n",
       "      <td>129021</td>\n",
       "      <td>12141</td>\n",
       "      <td>56645</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118591</th>\n",
       "      <td>0</td>\n",
       "      <td>17339</td>\n",
       "      <td>310</td>\n",
       "      <td>349</td>\n",
       "      <td>30</td>\n",
       "      <td>119218</td>\n",
       "      <td>18048</td>\n",
       "      <td>order</td>\n",
       "      <td>aft</td>\n",
       "      <td>6</td>\n",
       "      <td>129021</td>\n",
       "      <td>13895</td>\n",
       "      <td>56645</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118592</th>\n",
       "      <td>0</td>\n",
       "      <td>17339</td>\n",
       "      <td>310</td>\n",
       "      <td>349</td>\n",
       "      <td>30</td>\n",
       "      <td>119218</td>\n",
       "      <td>8252</td>\n",
       "      <td>order</td>\n",
       "      <td>aft</td>\n",
       "      <td>7</td>\n",
       "      <td>129021</td>\n",
       "      <td>6505</td>\n",
       "      <td>56645</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1118593 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         label  session_id promotion_id  voucher_min_spend  \\\n",
       "0            0        9180           20               4999   \n",
       "1            0        9180           20               4999   \n",
       "2            0        9180           20               4999   \n",
       "3            0        9180           20               4999   \n",
       "4            0        9180           20               4999   \n",
       "...        ...         ...          ...                ...   \n",
       "1118588      0       17339          310                349   \n",
       "1118589      0       17339          310                349   \n",
       "1118590      0       17339          310                349   \n",
       "1118591      0       17339          310                349   \n",
       "1118592      0       17339          310                349   \n",
       "\n",
       "         voucher_discount_amount voucher_collect_time item_id action_type  \\\n",
       "0                            600                10999   85356        cart   \n",
       "1                            600                10999   85352        cart   \n",
       "2                            600                10999   85351        cart   \n",
       "3                            600                10999   92250        cart   \n",
       "4                            600                10999   88965        cart   \n",
       "...                          ...                  ...     ...         ...   \n",
       "1118588                       30               119218   19882       order   \n",
       "1118589                       30               119218    1333       order   \n",
       "1118590                       30               119218   65011       order   \n",
       "1118591                       30               119218   18048       order   \n",
       "1118592                       30               119218    8252       order   \n",
       "\n",
       "        type  rk action_time  item_category_id  item_brand_id  \\\n",
       "0        bef  12        6874              9567         106903   \n",
       "1        bef  11        6850              9567         106903   \n",
       "2        bef  10        6838              9567         106903   \n",
       "3        bef   9        6871              9567         106903   \n",
       "4        bef   8        6838              2272         106903   \n",
       "...      ...  ..         ...               ...            ...   \n",
       "1118588  aft   3      129021             12057          56645   \n",
       "1118589  aft   4      129021             13895          56645   \n",
       "1118590  aft   5      129021             12141          56645   \n",
       "1118591  aft   6      129021             13895          56645   \n",
       "1118592  aft   7      129021              6505          56645   \n",
       "\n",
       "         item_price_level  sid_enc  \n",
       "0                     7.0     8998  \n",
       "1                     7.0     8998  \n",
       "2                     7.0     8998  \n",
       "3                     7.0     8998  \n",
       "4                     5.0     8998  \n",
       "...                   ...      ...  \n",
       "1118588               1.0    16986  \n",
       "1118589               2.0    16986  \n",
       "1118590               2.0    16986  \n",
       "1118591               1.0    16986  \n",
       "1118592               3.0    16986  \n",
       "\n",
       "[1118593 rows x 15 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnn_session_df = session_df.copy()\n",
    "sid_lbe = LabelEncoderExt()\n",
    "gnn_session_df['session_id'] = sid_lbe.fit_transform(gnn_session_df['session_id'])\n",
    "gnn_session_df = gnn_session_df.fillna(0)\n",
    "gnn_session_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UVG Networks\n",
    "load the related UVG network into the InMemoryDataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62068/62068 [20:16<00:00, 51.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch_geometric.data.dataloader.DataLoader at 0x2baa0efbd908>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "batch_size= 512\n",
    "\n",
    "geometric_data_path = './data/voucher_geometric/'\n",
    "processed_file_name = 'graph_cache'\n",
    "gnn_dat = VoucherGraphDataset(root=geometric_data_path, processed_file_name=processed_file_name, gnn_session_df=gnn_session_df)\n",
    "\n",
    "data_loader = DataLoader(gnn_dat, batch_size=batch_size)\n",
    "data_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GNN Networks\n",
    "In this section, we first define the User-behavior Voucher Graph (UVG) network with VoucherGraphNet, training the network with loaded dataset data_loader with VoucherGraphDataset and output the generated UVG embedding $e_{UVG}$ with UVG score $s_{UVG}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Pretrained Item Embeddings\n",
    "load the pretrinaed embedding results for atc/ord item into the embedding tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 286735/286735 [00:23<00:00, 12215.29it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Embedding(344082, 16), Embedding(344082, 16))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_size = int(len(item_df) * 1.2)\n",
    "emb_size = 16\n",
    "atc_emb_ts = torch.zeros(item_size, emb_size, dtype = torch.double)\n",
    "ord_emb_ts = torch.zeros(item_size, emb_size, dtype = torch.double)\n",
    "\n",
    "for i in tqdm(range(len(item_df))):\n",
    "    item_id = int(item_df['item_id'][i])\n",
    "    idx = hash_func(item_id, item_size)\n",
    "    \n",
    "    if pd.isna(item_df['atc_emb'][i]) is False and len(item_df['atc_emb'][i].split(' ')) > 3:\n",
    "        atc_emb = [float(val) for val in item_df['atc_emb'][i].split(' ')]\n",
    "        atc_emb_ts[idx] = torch.FloatTensor(atc_emb)\n",
    "    \n",
    "    if pd.isna(item_df['ord_emb'][i]) is False and len(item_df['ord_emb'][i].split(' ')) > 3:\n",
    "        ord_emb = [float(val) for val in item_df['ord_emb'][i].split(' ')]\n",
    "        ord_emb_ts[idx] = torch.FloatTensor(ord_emb) \n",
    "        \n",
    "atc_emb_ts = torch.nn.Embedding.from_pretrained(atc_emb_ts)\n",
    "atc_emb_ts.weight.requires_grad = False\n",
    "ord_emb_ts = torch.nn.Embedding.from_pretrained(ord_emb_ts) \n",
    "ord_emb_ts.weight.requires_grad = False\n",
    "\n",
    "atc_emb_ts, ord_emb_ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train GNN\n",
    "train the UVG Graph with Higher-order GNN, the AUC output here repesents the AUC performance using only GNN network, which can be considered as another ablation study. The trained GNN is saved in the ./data/gnet.pretrained_{epochs}.bin file to be loaded for fine-tune later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_features = ['item_id', 'item_category_id', 'item_brand_id', 'item_price_level']\n",
    "promotion_features = ['promotion_id', 'session_id', 'voucher_min_spend', 'voucher_discount_amount']\n",
    "all_features = item_features + promotion_features + ['action_type', 'label']\n",
    "\n",
    "after_prefix = 'a_'\n",
    "before_prefix = 'b_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/122 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch - 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 25/122 [06:07<23:54, 14.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN[25] - auc 0.5098590160701961; loss 0.5881080031394958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 50/122 [12:09<16:28, 13.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN[50] - auc 0.5390803307516744; loss 0.4756115972995758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 75/122 [17:51<10:28, 13.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN[75] - auc 0.5889131489568171; loss 0.39700013399124146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 100/122 [23:18<04:48, 13.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN[100] - auc 0.6827335858585859; loss 0.4064457416534424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [27:57<00:00, 13.75s/it]\n",
      "  0%|          | 0/122 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch - 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 3/122 [00:43<28:56, 14.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN[125] - auc 0.7065954539808719; loss 0.45573800802230835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 28/122 [06:43<22:18, 14.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN[150] - auc 0.6814671272502597; loss 0.43105319142341614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 53/122 [12:35<15:25, 13.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN[175] - auc 0.6874337601329094; loss 0.43508458137512207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 78/122 [18:13<09:48, 13.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN[200] - auc 0.7553992348512897; loss 0.37773483991622925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 103/122 [23:39<04:02, 12.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN[225] - auc 0.7355014463448198; loss 0.40350326895713806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [27:38<00:00, 13.59s/it]\n",
      "  0%|          | 0/122 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch - 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 6/122 [01:27<28:27, 14.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN[250] - auc 0.680890999547716; loss 0.4961029589176178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 31/122 [07:28<22:25, 14.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN[275] - auc 0.6300832194758414; loss 0.48935168981552124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 56/122 [13:25<15:10, 13.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN[300] - auc 0.7524388936535163; loss 0.4194798469543457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 81/122 [19:08<09:13, 13.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN[325] - auc 0.7347334042229987; loss 0.33465683460235596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 106/122 [24:39<03:21, 12.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN[350] - auc 0.7515558467081559; loss 0.3907470405101776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [28:08<00:00, 13.84s/it]\n"
     ]
    }
   ],
   "source": [
    "torch.set_default_tensor_type(torch.FloatTensor)\n",
    "\n",
    "emb_info = {\n",
    "    'item_category_id': (6000, 1),\n",
    "    'item_price_level': (300, 1),\n",
    "    'promotion_id': (600, int(atc_emb_ts.weight.shape[1])),\n",
    "    'voucher_min_spend': (500, 1),\n",
    "    'voucher_discount_amount': (500, 1),\n",
    "}\n",
    "\n",
    "emb_dict = {\n",
    "    'atc': atc_emb_ts,\n",
    "    'ord': ord_emb_ts,\n",
    "}\n",
    "\n",
    "gnet = VoucherGraphNet(item_features, promotion_features, emb_info, emb_dict, \n",
    "                       gprefix = [before_prefix, after_prefix], gactions = ['atc', 'ord'],\n",
    "                       device=device)\n",
    "gnet = gnet.float().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(gnet.parameters(), lr=0.001)\n",
    "crit = torch.nn.BCELoss()\n",
    "\n",
    "epochs = 3\n",
    "gnn_file = './data/gnet.pretrained_{epochs}.bin'.format(epochs=epochs)\n",
    "\n",
    "train_ready = True if os.path.exists(gnn_file) else False\n",
    "\n",
    "if train_ready is False:\n",
    "    gstep = 0\n",
    "    gnet.train()\n",
    "    loader_cnt = 0\n",
    "    for epoch in range(epochs):\n",
    "        print(\"# Epoch - {epoch}\".format(epoch=epoch))\n",
    "        try:\n",
    "            for dat in tqdm(data_loader):\n",
    "                optimizer.zero_grad()\n",
    "                graph_dicts = dat.graph_dict\n",
    "                out = None\n",
    "                valid_list = []\n",
    "                gstep += 1\n",
    "                for graph_dict in graph_dicts:\n",
    "                    res, promotion_id, emb_promotion, session_id, emb_session_id = gnet(graph_dict)\n",
    "                    if res is None or torch.isnan(res):\n",
    "                        valid_list.append(False)\n",
    "                        continue\n",
    "                    valid_list.append(True)\n",
    "                    out = res if out is None else torch.cat([out, res], dim=0)\n",
    "\n",
    "                pred = out.cpu()\n",
    "                lbe = dat.label.cpu()[valid_list]\n",
    "                loss = crit(pred, lbe)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                if gstep % 25 == 0:\n",
    "                    auc = roc_auc_score(lbe.detach().numpy().ravel(), pred.detach().numpy().ravel())\n",
    "                    print('GNN[{gstep}] - auc {auc}; loss {loss}'.format(auc=auc ,gstep=gstep ,loss=loss))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    torch.save(gnet.state_dict(), gnn_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VoucherGraphNet(\n",
       "  (emb_dic): ModuleDict(\n",
       "    (atc_emb): Embedding(344082, 16)\n",
       "    (ord_emb): Embedding(344082, 16)\n",
       "    (item_category_id): Embedding(6000, 1)\n",
       "    (item_price_level): Embedding(300, 1)\n",
       "    (promotion_id): Embedding(600, 16)\n",
       "    (voucher_min_spend): Embedding(500, 1)\n",
       "    (voucher_discount_amount): Embedding(500, 1)\n",
       "  )\n",
       "  (convs): ModuleList(\n",
       "    (0): GraphConv(18, 16)\n",
       "    (1): GraphConv(16, 16)\n",
       "  )\n",
       "  (pools): ModuleList(\n",
       "    (0): TopKPooling(16, ratio=0.9, multiplier=1)\n",
       "    (1): TopKPooling(16, ratio=0.9, multiplier=1)\n",
       "  )\n",
       "  (linears): ModuleList(\n",
       "    (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the pretrained GNN network parameter\n",
    "gnet = VoucherGraphNet(item_features, promotion_features, emb_info, emb_dict, \n",
    "                       gprefix = [before_prefix, after_prefix], gactions = ['atc', 'ord'], \n",
    "                       device=device)\n",
    "gnet.load_state_dict(torch.load(gnn_file))\n",
    "gnet = gnet.float().to(device)\n",
    "\n",
    "\n",
    "# Use Before UVG Only\n",
    "gnet_before = VoucherGraphNet(item_features, promotion_features, emb_info, emb_dict, device=device)\n",
    "gnet_before.load_state_dict(torch.load(gnn_file))\n",
    "gnet_before = gnet_before.float().to(device)\n",
    "gnet_before.gprefix = [before_prefix, 'unknown'] \n",
    "\n",
    "gnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Pretrained Embeddings\n",
    "generate pretrained embeddings from UVG network for each UVG. Note here we have gnet and gnet_before which represents UVG including both 'bef' and 'aft' user behaviors and including 'bef' user behaviors only. From the AUC performance output we see that gnet has better performance than gnet_before, which indicates the importance of taking 'aft' user behaviors into consideration. This can be considered as another ablation study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gstep = 1; auc = 0.716714596731331; loss = 0.4340111315250397; auc_before = 0.5803768601021925 0.5024860501289368\n",
      "gstep = 2; auc = 0.7343799763178309; loss = 0.40651506185531616; auc_before = 0.5919482391139335 0.4862906336784363\n",
      "gstep = 3; auc = 0.7559779898396956; loss = 0.35435977578163147; auc_before = 0.6002010714152302 0.45418480038642883\n",
      "gstep = 4; auc = 0.7783587166749366; loss = 0.3566122055053711; auc_before = 0.5878568189048866 0.4580093026161194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62068/62068 [00:00<00:00, 492357.50it/s]\n",
      "100%|██████████| 43989/43989 [00:00<00:00, 723474.02it/s]\n",
      "  0%|          | 0/62068 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gstep = 5; auc = 0.7412623202522659; loss = 0.4386313855648041; auc_before = 0.588513267902581 0.49945828318595886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62068/62068 [00:00<00:00, 732640.45it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(462, 62068, 43989, 62068)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "pickle_protocol = 4\n",
    "\n",
    "gnet.eval()\n",
    "gnet_before.eval()\n",
    "gstep = 0\n",
    "\n",
    "\n",
    "raw_sid_uvg_graphs_dic = {}\n",
    "\n",
    "promotion_emb_dic = {}\n",
    "session_emb_raw_dic = {}\n",
    "session_emb_raw_dic_before = {}\n",
    "\n",
    "gnn_pretrained_emb_file = 'data/gnet.pretrained.{epochs}.emb.pkl'.format(epochs=epochs)\n",
    "\n",
    "gnn_emb_ready = True if os.path.exists(gnn_pretrained_emb_file) else False\n",
    "\n",
    "def hash_func(ts, item_size):\n",
    "    return ts % item_size\n",
    "\n",
    "if gnn_emb_ready is False:\n",
    "    session_emb_dic = {}\n",
    "    sid_uvg_graphs_dic = {}\n",
    "    session_emb_dic_before = {}\n",
    "    for dat in DataLoader(gnn_dat, batch_size=batch_size * 30):\n",
    "        graph_dicts = dat.graph_dict\n",
    "        out = None\n",
    "        out2 = None\n",
    "        valid_list = []\n",
    "        valid_list2 = []\n",
    "        gstep += 1\n",
    "        for graph_dict in graph_dicts :\n",
    "            res, promotion_id, emb_promotion, session_id, emb_session_id = gnet(graph_dict)\n",
    "            res_before, _, _, _, emb_session_id_before = gnet_before(graph_dict)\n",
    "            if res is None or torch.isnan(res):\n",
    "                valid_list.append(False)\n",
    "                continue\n",
    "\n",
    "            valid_list.append(True)\n",
    "            out = res if out is None else torch.cat([out, res], dim=0)\n",
    "\n",
    "            promotion_emb_dic[promotion_id.unsqueeze(0).cpu().detach().numpy()[0]] = emb_promotion.cpu().detach().numpy()\n",
    "            session_emb_dic[session_id.unsqueeze(0).cpu().detach().numpy()[0]] = emb_session_id.cpu().detach().numpy()\n",
    "            sid_uvg_graphs_dic[session_id.unsqueeze(0).cpu().detach().numpy()[0]] = graph_dict\n",
    "            \n",
    "            if res_before is not None or torch.isnan(res) is False:\n",
    "                session_emb_dic_before[session_id.unsqueeze(0).cpu().detach().numpy()[0]] = emb_session_id_before.cpu().detach().numpy()\n",
    "                out2 = res_before if out2 is None else torch.cat([out2, res_before], dim=0)\n",
    "                valid_list2.append(True)\n",
    "            else :\n",
    "                valid_list2.append(False)\n",
    "\n",
    "        try:\n",
    "            lbe = dat.label.cpu()[valid_list]\n",
    "            lbe2 = dat.label.cpu()[valid_list2]\n",
    "            pred = out.cpu()\n",
    "            pred2 = out2.cpu()\n",
    "            loss = crit(pred, lbe)\n",
    "            loss2 = crit(pred2, lbe2)\n",
    "            auc = roc_auc_score(lbe.detach().numpy().ravel(), pred.detach().numpy().ravel())\n",
    "            auc2 = roc_auc_score(lbe2.detach().numpy().ravel(), pred2.detach().numpy().ravel())\n",
    "            print(\"gstep = {gstep}; auc = {auc}; loss = {loss}; auc_before = {auc2} {loss2}\".format(gstep=gstep,\n",
    "                                                                                                    auc=auc, \n",
    "                                                                                                    loss2=loss2,\n",
    "                                                                                                    auc2 =auc2,\n",
    "                                                                                                    loss=loss))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    for key, emb in tqdm(session_emb_dic.items()):\n",
    "        session_emb_raw_dic[sid_lbe.label_encoder.classes_[key]] = emb\n",
    "\n",
    "    # session_emb_raw_dic_before use for target session id with no after behaviors know beforehand\n",
    "    for key, emb in tqdm(session_emb_dic_before.items()):\n",
    "        session_emb_raw_dic_before[sid_lbe.label_encoder.classes_[key]] = emb\n",
    "\n",
    "    for key, uvg in tqdm(sid_uvg_graphs_dic.items()):\n",
    "         raw_sid_uvg_graphs_dic[sid_lbe.label_encoder.classes_[key]] = uvg\n",
    "        \n",
    "    with open(gnn_pretrained_emb_file, 'wb') as f:\n",
    "        pickle.dump(promotion_emb_dic, f, pickle_protocol)\n",
    "        pickle.dump(session_emb_raw_dic, f, pickle_protocol)\n",
    "        pickle.dump(session_emb_raw_dic_before, f, pickle_protocol)\n",
    "        pickle.dump(raw_sid_uvg_graphs_dic, f, pickle_protocol)\n",
    "\n",
    "else :\n",
    "    print('loading existing trained embeddings...')\n",
    "    with open(gnn_pretrained_emb_file, \"rb\") as f:\n",
    "        promotion_emb_dic = pickle.load(f)\n",
    "        session_emb_raw_dic = pickle.load(f)\n",
    "        session_emb_raw_dic_before = pickle.load(f)\n",
    "        raw_sid_uvg_graphs_dic = pickle.load(f)\n",
    "        \n",
    "len(promotion_emb_dic), len(session_emb_raw_dic), len(session_emb_raw_dic_before), len(raw_sid_uvg_graphs_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1118593/1118593 [00:19<00:00, 56126.09it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1118593, 0.7234987098668464, 0.5588852361568042)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "labels = []\n",
    "scores = []\n",
    "\n",
    "labels_before = []\n",
    "scores_before = [] \n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "for iii in tqdm(range(len(session_df))):\n",
    "    sid = session_df['session_id'].values[iii]\n",
    "    promotion_id = int(session_df['promotion_id'].values[iii])\n",
    "    label = session_df['label'].values[iii]\n",
    "    \n",
    "    if sid not in session_emb_raw_dic:\n",
    "        continue\n",
    "    \n",
    "    session_emb = session_emb_raw_dic[sid]\n",
    "    promotion_emb = promotion_emb_dic[promotion_id]\n",
    "            \n",
    "    labels.append(label)\n",
    "    score = sigmoid(np.matmul(session_emb, promotion_emb))\n",
    "    scores.append(score)\n",
    "    \n",
    "    if sid in session_emb_raw_dic_before:\n",
    "        session_emb_before = session_emb_raw_dic_before[sid]\n",
    "        score_before = sigmoid(np.matmul(session_emb_before, promotion_emb))\n",
    "        scores_before.append(score_before)\n",
    "        labels_before.append(label)\n",
    "            \n",
    "auc = roc_auc_score(labels, scores)\n",
    "auc_before = roc_auc_score(labels_before, scores_before)\n",
    "len(scores), auc, auc_before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DMBGN Log Processing\n",
    "log processing for DMBGN training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = user_voucher_log.copy()\n",
    "df = df.take(np.random.permutation(len(df)))\n",
    "df['hist_sid'] = df['hist_session_id']\n",
    "\n",
    "sparse_feature = ['promotion_id','session_id','user_gender','user_age_level','user_purchase_level'] #['promotion_id','voucher_min_spend','voucher_discount_amount']\n",
    "\n",
    "hist_list_features = ['hist_promotion_id','hist_sid','keys_length']\n",
    "\n",
    "ignore_features=['hist_session_id', 'dtype','venture','ds','user_id','label','voucher_collect_time','voucher_redeem_time','campaign_name','rk']\n",
    "\n",
    "dense_feature = []\n",
    "train_features = []\n",
    "\n",
    "for feat in df.columns:\n",
    "    if feat in ignore_features:\n",
    "        continue\n",
    "    if feat not in hist_list_features:\n",
    "        train_features.append(feat)\n",
    "    if feat not in hist_list_features and feat not in sparse_feature:\n",
    "        dense_feature.append(feat)\n",
    "\n",
    "target = 'label'\n",
    "df[['session_id','promotion_id','user_gender','user_age_level','user_purchase_level']]=df[['session_id','promotion_id','user_gender','user_age_level','user_purchase_level']].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-28 14:18:07,315 [WARNING]: LabelEncoder encoding promotion_id len 462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lbe promotion_id\n",
      "LabelEncoderExt fitting...\n",
      "LabelEncoderExt transforming...\n",
      "lbe session_id\n",
      "LabelEncoderExt fitting...\n",
      "LabelEncoderExt transforming...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-28 14:18:07,553 [WARNING]: LabelEncoder encoding session_id len 58052\n",
      "2021-02-28 14:18:07,639 [WARNING]: LabelEncoder encoding user_gender len 4\n",
      "2021-02-28 14:18:07,725 [WARNING]: LabelEncoder encoding user_age_level len 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lbe user_gender\n",
      "LabelEncoderExt fitting...\n",
      "LabelEncoderExt transforming...\n",
      "lbe user_age_level\n",
      "LabelEncoderExt fitting...\n",
      "LabelEncoderExt transforming...\n",
      "lbe user_purchase_level\n",
      "LabelEncoderExt fitting...\n",
      "LabelEncoderExt transforming...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-28 14:18:07,811 [WARNING]: LabelEncoder encoding user_purchase_level len 12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "label_encoder = {}\n",
    "for feat in sparse_feature:\n",
    "    df[feat] = df[feat].fillna(0)\n",
    "    print(\"lbe {}\".format(feat))\n",
    "    lbe = LabelEncoderExt()\n",
    "    lbe.fit(df[feat])\n",
    "    df[feat] = lbe.transform(df[feat])\n",
    "    label_encoder[feat] = lbe\n",
    "    logging.warn('LabelEncoder encoding ' + feat + \" len \" + str(len(lbe)))\n",
    "    \n",
    "label_encoder['sid'] = label_encoder['session_id']\n",
    "df['sid'] = df['promotion_id']\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voucher_min_spend\n",
      "voucher_discount\n",
      "user_trd__orders_cnt_hist\n",
      "user_trd__actual_gmv_usd_hist\n",
      "user_trd__orders_cnt_platform_discount_hist\n",
      "user_trd__max_gmv_usd_hist\n",
      "user_trd__avg_gmv_usd_hist\n",
      "user_trd__min_gmv_usd_hist\n"
     ]
    }
   ],
   "source": [
    "mean_kv = {}\n",
    "std_kv = {}\n",
    "for feat in dense_feature:\n",
    "    print(feat)\n",
    "    mean_kv[feat] = df[feat].mean()\n",
    "    std_kv[feat] = df[feat].std()\n",
    "    df[feat] = (df[feat] - mean_kv[feat]) / std_kv[feat]\n",
    "\n",
    "deep_ctr_df = df \n",
    "dctr_train = deep_ctr_df[deep_ctr_df.dtype == 'train']\n",
    "dctr_v1 = deep_ctr_df[deep_ctr_df.dtype == 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/46361 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "start generating x y data\n",
      "feature_names: ['promotion_id', 'user_gender', 'user_age_level', 'user_purchase_level', 'sid', 'hist_promotion_id', 'hist_sid', 'voucher_min_spend', 'voucher_discount', 'user_trd__orders_cnt_hist', 'user_trd__actual_gmv_usd_hist', 'user_trd__orders_cnt_platform_discount_hist', 'user_trd__max_gmv_usd_hist', 'user_trd__avg_gmv_usd_hist', 'user_trd__min_gmv_usd_hist', 'keys_length']\n",
      "handling hist_list_features Feature: hist_promotion_id\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46361/46361 [00:00<00:00, 64716.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoderExt transforming...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 12579/46361 [00:00<00:00, 62949.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "handling hist_list_features Feature: hist_sid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46361/46361 [00:00<00:00, 66557.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoderExt transforming...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11690/11690 [00:00<00:00, 67846.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start generating x y data\n",
      "feature_names: ['promotion_id', 'user_gender', 'user_age_level', 'user_purchase_level', 'sid', 'hist_promotion_id', 'hist_sid', 'voucher_min_spend', 'voucher_discount', 'user_trd__orders_cnt_hist', 'user_trd__actual_gmv_usd_hist', 'user_trd__orders_cnt_platform_discount_hist', 'user_trd__max_gmv_usd_hist', 'user_trd__avg_gmv_usd_hist', 'user_trd__min_gmv_usd_hist', 'keys_length']\n",
      "handling hist_list_features Feature: hist_promotion_id\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/11690 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoderExt transforming...\n",
      "handling hist_list_features Feature: hist_sid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11690/11690 [00:00<00:00, 65785.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoderExt transforming...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "def get_xy_fd(dataset):\n",
    "    print (\"start generating x y data\")\n",
    "    \n",
    "    dnn_feature_columns = []\n",
    "    dnn_feature_columns += [SparseFeat(feat, len(label_encoder[feat]), embedding_dim = embedding_dim1) for feat in ['promotion_id', 'user_gender','user_age_level','user_purchase_level']]\n",
    "    dnn_feature_columns += [SparseFeat(feat, len(label_encoder['promotion_id']), embedding_dim = embedding_dim2) for feat in ['sid']]\n",
    "    \n",
    "    dnn_feature_columns += [VarLenSparseFeat(SparseFeat('hist_promotion_id', len(label_encoder[\"promotion_id\"]), embedding_dim=embedding_dim1), sequence_size)]\n",
    "    dnn_feature_columns += [VarLenSparseFeat(SparseFeat('hist_sid', len(label_encoder[\"sid\"]), embedding_dim=embedding_dim2), sequence_size)]\n",
    "    \n",
    "    dnn_feature_columns += [DenseFeat(feat, 1, )  for feat in dense_feature]\n",
    "    dnn_feature_columns += [DenseFeat(feat, 1, )  for feat in ['keys_length']]\n",
    "\n",
    "    feature_names = get_feature_names(dnn_feature_columns)\n",
    "    print (\"feature_names:\", feature_names)\n",
    "    \n",
    "    behavior_feature_list = ['promotion_id', 'sid']\n",
    "\n",
    "    y, x = gen_dmbgn_input_data(feature_names, dataset, target, label_encoder, 6, sparse_feature, hist_list_features)\n",
    " \n",
    "    return x, y, dnn_feature_columns, behavior_feature_list\n",
    "\n",
    "sequence_size = 6\n",
    "embedding_dim1 = 16 # pid\n",
    "embedding_dim2 = 16 # sid\n",
    "print(embedding_dim2)\n",
    "\n",
    "x, y, dnn_feature_columns, behavior_feature_list = get_xy_fd(dctr_train)\n",
    "test_model_input1, test_label1, _, _ = get_xy_fd(dctr_v1)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoderExt transforming...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "62068it [00:01, 50547.19it/s]\n",
      "462it [00:00, 44989.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoderExt transforming...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "session_emb_bef_aft_16 = init_emb_ts(session_emb_raw_dic, requires_grad = False, lbe = label_encoder['session_id'])\n",
    "promotion_emb_bef_aft_16 = init_emb_ts(promotion_emb_dic, requires_grad = True, lbe = label_encoder['promotion_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DMBGN(\n",
       "  (embedding_dict): ModuleDict(\n",
       "    (promotion_id): Embedding(462, 16)\n",
       "    (user_gender): Embedding(4, 16)\n",
       "    (user_age_level): Embedding(10, 16)\n",
       "    (user_purchase_level): Embedding(12, 16)\n",
       "    (sid): Embedding(462, 16)\n",
       "    (hist_promotion_id): Embedding(462, 16)\n",
       "    (hist_sid): Embedding(58052, 16)\n",
       "  )\n",
       "  (linear_model): Linear(\n",
       "    (embedding_dict): ModuleDict()\n",
       "  )\n",
       "  (out): PredictionLayer()\n",
       "  (attention): HistAttentionSeqPoolingLayer(\n",
       "    (local_att): AttentionUnit(\n",
       "      (dnn): DNN(\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (linears): ModuleList(\n",
       "          (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "        )\n",
       "        (activation_layers): ModuleList(\n",
       "          (0): PReLU(num_parameters=1)\n",
       "        )\n",
       "      )\n",
       "      (dense): Linear(in_features=64, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (dnn): DNN(\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (linears): ModuleList(\n",
       "      (0): Linear(in_features=129, out_features=128, bias=True)\n",
       "      (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "    )\n",
       "    (bn): ModuleList(\n",
       "      (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (activation_layers): ModuleList(\n",
       "      (0): ReLU(inplace=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (dnn_linear): Linear(in_features=64, out_features=1, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'DMBGN_Pretrained'\n",
    "\n",
    "model = DMBGN(dnn_feature_columns, \n",
    "            behavior_feature_list,\n",
    "            target_emb_dim_aft=0, \n",
    "            sequence_size=6,\n",
    "            device=device, \n",
    "            att_activation='prelu', \n",
    "            att_weight_normalization=False, \n",
    "            dnn_activation='relu', \n",
    "            l2_reg_dnn=0.1, \n",
    "            l2_reg_embedding = 0.0001, \n",
    "            dnn_hidden_units=(128,64), \n",
    "            att_hidden_size=(64,), \n",
    "            init_std=1, \n",
    "            dnn_dropout=0.5, \n",
    "            dnn_use_bn=True)\n",
    "\n",
    "\n",
    "gnn_fine_tune = False\n",
    "model.embedding_dict['hist_promotion_id'] = promotion_emb_bef_aft_16 \n",
    "model.embedding_dict['hist_promotion_id'].requires_grad = gnn_fine_tune\n",
    "model.embedding_dict['hist_promotion_id'].weight.requires_grad = gnn_fine_tune\n",
    "\n",
    "model.embedding_dict['hist_sid'] = session_emb_bef_aft_16\n",
    "model.embedding_dict['hist_sid'].requires_grad = gnn_fine_tune\n",
    "model.embedding_dict['hist_sid'].weight.requires_grad = gnn_fine_tune\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.05, amsgrad=True)\n",
    "model.compile(optimizer, 'binary_crossentropy', metrics=['auc', 'logloss'])\n",
    "\n",
    "\n",
    "loss_func = model.loss_func\n",
    "optim = model.optim\n",
    "metrics = model.metrics\n",
    "feature_index = model.feature_index\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use 8 GPUs!\n"
     ]
    }
   ],
   "source": [
    "device_ids = [i for i in range(torch.cuda.device_count())]\n",
    "device_count = len(device_ids)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Use\", device_count, \"GPUs!\")\n",
    "    model = torch.nn.DataParallel(model, device_ids)\n",
    "    \n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 46361 samples, validate on 11690 samples, 155 steps per epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:10, 14.24it/s]\n",
      "2it [00:00, 13.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "Epoch Time : 12\n",
      "12s - loss:  1.4697 - auc:  0.6263 - logloss:  0.4552 - val_auc:  0.7207 - val_logloss:  0.3976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:10, 14.52it/s]\n",
      "2it [00:00, 12.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "Epoch Time : 12\n",
      "12s - loss:  1.4110 - auc:  0.7412 - logloss:  0.3891 - val_auc:  0.7530 - val_logloss:  0.3823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:10, 14.75it/s]\n",
      "2it [00:00, 13.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "Epoch Time : 12\n",
      "12s - loss:  1.3876 - auc:  0.7632 - logloss:  0.3778 - val_auc:  0.7616 - val_logloss:  0.3775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:10, 15.02it/s]\n",
      "2it [00:00, 13.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "Epoch Time : 11\n",
      "11s - loss:  1.3856 - auc:  0.7752 - logloss:  0.3713 - val_auc:  0.7710 - val_logloss:  0.3714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:10, 14.63it/s]\n",
      "2it [00:00, 13.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "Epoch Time : 12\n",
      "12s - loss:  1.3923 - auc:  0.7840 - logloss:  0.3663 - val_auc:  0.7751 - val_logloss:  0.3703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:10, 14.90it/s]\n",
      "2it [00:00, 13.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "Epoch Time : 12\n",
      "12s - loss:  1.3870 - auc:  0.7935 - logloss:  0.3613 - val_auc:  0.7723 - val_logloss:  0.3718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:10, 14.86it/s]\n",
      "2it [00:00, 14.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "Epoch Time : 12\n",
      "12s - loss:  1.3851 - auc:  0.7985 - logloss:  0.3584 - val_auc:  0.7764 - val_logloss:  0.3721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:11, 13.68it/s]\n",
      "2it [00:00, 13.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "Epoch Time : 12\n",
      "12s - loss:  1.3633 - auc:  0.8035 - logloss:  0.3543 - val_auc:  0.7775 - val_logloss:  0.3689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:10, 14.62it/s]\n",
      "2it [00:00, 13.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n",
      "Epoch Time : 12\n",
      "12s - loss:  1.3664 - auc:  0.8072 - logloss:  0.3514 - val_auc:  0.7783 - val_logloss:  0.3688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:10, 14.67it/s]\n",
      "2it [00:00, 12.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n",
      "Epoch Time : 12\n",
      "12s - loss:  1.3617 - auc:  0.8107 - logloss:  0.3494 - val_auc:  0.7813 - val_logloss:  0.3663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:10, 14.25it/s]\n",
      "2it [00:00, 13.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "Epoch Time : 12\n",
      "12s - loss:  1.3594 - auc:  0.8166 - logloss:  0.3457 - val_auc:  0.7757 - val_logloss:  0.3702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:10, 14.85it/s]\n",
      "2it [00:00, 13.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "Epoch Time : 12\n",
      "12s - loss:  1.3723 - auc:  0.8190 - logloss:  0.3433 - val_auc:  0.7784 - val_logloss:  0.3731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:11, 13.72it/s]\n",
      "2it [00:00, 14.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "Epoch Time : 12\n",
      "12s - loss:  1.3558 - auc:  0.8221 - logloss:  0.3419 - val_auc:  0.7742 - val_logloss:  0.3744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:10, 14.96it/s]\n",
      "2it [00:00, 14.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n",
      "Epoch Time : 11\n",
      "11s - loss:  1.3618 - auc:  0.8251 - logloss:  0.3387 - val_auc:  0.7790 - val_logloss:  0.3689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:10, 14.99it/s]\n",
      "2it [00:00, 13.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20\n",
      "Epoch Time : 11\n",
      "11s - loss:  1.3481 - auc:  0.8284 - logloss:  0.3367 - val_auc:  0.7757 - val_logloss:  0.3710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:10, 14.89it/s]\n",
      "2it [00:00, 13.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "Epoch Time : 12\n",
      "12s - loss:  1.3582 - auc:  0.8323 - logloss:  0.3333 - val_auc:  0.7669 - val_logloss:  0.3808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:10, 14.65it/s]\n",
      "2it [00:00, 13.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n",
      "Epoch Time : 12\n",
      "12s - loss:  1.3626 - auc:  0.8341 - logloss:  0.3316 - val_auc:  0.7728 - val_logloss:  0.3763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:11, 13.69it/s]\n",
      "2it [00:00, 13.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20\n",
      "Epoch Time : 12\n",
      "12s - loss:  1.3503 - auc:  0.8381 - logloss:  0.3288 - val_auc:  0.7760 - val_logloss:  0.3737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:10, 14.93it/s]\n",
      "2it [00:00, 13.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n",
      "Epoch Time : 12\n",
      "12s - loss:  1.3495 - auc:  0.8411 - logloss:  0.3262 - val_auc:  0.7683 - val_logloss:  0.3791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [00:10, 14.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "Epoch Time : 12\n",
      "12s - loss:  1.3573 - auc:  0.8442 - logloss:  0.3240 - val_auc:  0.7746 - val_logloss:  0.3819\n"
     ]
    }
   ],
   "source": [
    "epoch = 20\n",
    "batch_size = 300\n",
    "res, pred1 = fit(model, feature_index, optim, metrics, loss_func, x, y, batch_size=batch_size, epochs=epoch, validation_data=(test_model_input1,test_label1),verbose=1, device=device, device_count=device_count)\n",
    "\n",
    "results[model_name] = model, res, pred1, test_label1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DMBGN\n",
    "The proposed model in this work, which loads the pre-trained GNN network including the item and voucher node embeddings. The GNN network parameters are further fine-tuned according to the final training loss. \\\n",
    "Note that it might takes a longer time to train DMBGN as it involves the training of GNN network. In our work, we used 8 GPUs to accerlate the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 6611/46361 [00:00<00:00, 66100.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "start generating x y data\n",
      "feature_names: ['promotion_id', 'user_gender', 'user_age_level', 'user_purchase_level', 'sid', 'session_id', 'hist_promotion_id', 'hist_sid', 'voucher_min_spend', 'voucher_discount', 'user_trd__orders_cnt_hist', 'user_trd__actual_gmv_usd_hist', 'user_trd__orders_cnt_platform_discount_hist', 'user_trd__max_gmv_usd_hist', 'user_trd__avg_gmv_usd_hist', 'user_trd__min_gmv_usd_hist', 'keys_length']\n",
      "handling hist_list_features Feature: hist_promotion_id\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46361/46361 [00:00<00:00, 67379.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoderExt transforming...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 13525/46361 [00:00<00:00, 68405.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "handling hist_list_features Feature: hist_sid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46361/46361 [00:00<00:00, 65167.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoderExt transforming...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11690/11690 [00:00<00:00, 64002.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start generating x y data\n",
      "feature_names: ['promotion_id', 'user_gender', 'user_age_level', 'user_purchase_level', 'sid', 'session_id', 'hist_promotion_id', 'hist_sid', 'voucher_min_spend', 'voucher_discount', 'user_trd__orders_cnt_hist', 'user_trd__actual_gmv_usd_hist', 'user_trd__orders_cnt_platform_discount_hist', 'user_trd__max_gmv_usd_hist', 'user_trd__avg_gmv_usd_hist', 'user_trd__min_gmv_usd_hist', 'keys_length']\n",
      "handling hist_list_features Feature: hist_promotion_id\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 56%|█████▌    | 6536/11690 [00:00<00:00, 65355.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoderExt transforming...\n",
      "handling hist_list_features Feature: hist_sid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11690/11690 [00:00<00:00, 65051.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoderExt transforming...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "def get_xy_fd(dataset):\n",
    "    print (\"start generating x y data\")\n",
    "    \n",
    "    dnn_feature_columns = []\n",
    "    dnn_feature_columns += [SparseFeat(feat, len(label_encoder[feat]), embedding_dim = embedding_dim1) for feat in ['promotion_id', 'user_gender','user_age_level','user_purchase_level']]\n",
    "    dnn_feature_columns += [SparseFeat(feat, len(label_encoder['promotion_id']), embedding_dim = embedding_dim2) for feat in ['sid']]\n",
    "    dnn_feature_columns += [SparseFeat(feat, len(label_encoder[feat]), embedding_dim = 1) for feat in ['session_id']]\n",
    "    \n",
    "    dnn_feature_columns += [VarLenSparseFeat(SparseFeat('hist_promotion_id', len(label_encoder[\"promotion_id\"]), embedding_dim=embedding_dim1), sequence_size)]\n",
    "    dnn_feature_columns += [VarLenSparseFeat(SparseFeat('hist_sid', len(label_encoder[\"sid\"]), embedding_dim=embedding_dim2), sequence_size)]\n",
    "    \n",
    "    dnn_feature_columns += [DenseFeat(feat, 1, )  for feat in dense_feature]\n",
    "    dnn_feature_columns += [DenseFeat(feat, 1, )  for feat in ['keys_length']]\n",
    "\n",
    "    feature_names = get_feature_names(dnn_feature_columns)\n",
    "    print (\"feature_names:\", feature_names)\n",
    "    \n",
    "    behavior_feature_list = ['promotion_id', 'sid']\n",
    "\n",
    "    y, x = gen_dmbgn_input_data(feature_names, dataset, target, label_encoder, 6, sparse_feature, hist_list_features)\n",
    " \n",
    "    return x, y, dnn_feature_columns, behavior_feature_list\n",
    "\n",
    "sequence_size = 6\n",
    "embedding_dim1 = 16 # pid\n",
    "embedding_dim2 = 16 # sid\n",
    "print(embedding_dim2)\n",
    "\n",
    "x, y, dnn_feature_columns, behavior_feature_list = get_xy_fd(dctr_train)\n",
    "test_model_input1, test_label1, _, _ = get_xy_fd(dctr_v1)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "462it [00:00, 43507.23it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoderExt transforming...\n",
      "LabelEncoderExt transforming...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "62068it [00:01, 51243.70it/s]\n",
      "462it [00:00, 46361.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoderExt transforming...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "session_emb_bef_aft_16 = init_emb_ts(session_emb_raw_dic, requires_grad = False, lbe = label_encoder['session_id'])\n",
    "promotion_emb_bef_aft_16 = init_emb_ts(promotion_emb_dic, requires_grad = True, lbe = label_encoder['promotion_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoderExt transforming...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "62068it [00:00, 1341060.67it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "58052"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hash_sid_uvg_graphs_dic = {}\n",
    "hash_sids = label_encoder['session_id'].transform([str(val) for val in raw_sid_uvg_graphs_dic.keys()])\n",
    "for i, (key, uvgs) in tqdm(enumerate(raw_sid_uvg_graphs_dic.items())):\n",
    "    hash_sid_uvg_graphs_dic[hash_sids[i]] = uvgs\n",
    "\n",
    "len(hash_sid_uvg_graphs_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DMBGN(\n",
       "  (embedding_dict): ModuleDict(\n",
       "    (promotion_id): Embedding(462, 16)\n",
       "    (user_gender): Embedding(4, 16)\n",
       "    (user_age_level): Embedding(10, 16)\n",
       "    (user_purchase_level): Embedding(12, 16)\n",
       "    (sid): Embedding(462, 16)\n",
       "    (session_id): Embedding(58052, 1)\n",
       "    (hist_promotion_id): Embedding(462, 16)\n",
       "    (hist_sid): Embedding(58052, 16)\n",
       "  )\n",
       "  (linear_model): Linear(\n",
       "    (embedding_dict): ModuleDict()\n",
       "  )\n",
       "  (out): PredictionLayer()\n",
       "  (attention): HistAttentionSeqPoolingLayer(\n",
       "    (local_att): AttentionUnit(\n",
       "      (dnn): DNN(\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (linears): ModuleList(\n",
       "          (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "        )\n",
       "        (activation_layers): ModuleList(\n",
       "          (0): PReLU(num_parameters=1)\n",
       "        )\n",
       "      )\n",
       "      (dense): Linear(in_features=64, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (dnn): DNN(\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (linears): ModuleList(\n",
       "      (0): Linear(in_features=130, out_features=128, bias=True)\n",
       "      (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "    )\n",
       "    (bn): ModuleList(\n",
       "      (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (activation_layers): ModuleList(\n",
       "      (0): ReLU(inplace=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (dnn_linear): Linear(in_features=64, out_features=1, bias=False)\n",
       "  (gnet): VoucherGraphNet(\n",
       "    (emb_dic): ModuleDict(\n",
       "      (atc_emb): Embedding(344082, 16)\n",
       "      (ord_emb): Embedding(344082, 16)\n",
       "      (item_category_id): Embedding(6000, 1)\n",
       "      (item_price_level): Embedding(300, 1)\n",
       "      (promotion_id): Embedding(600, 16)\n",
       "      (voucher_min_spend): Embedding(500, 1)\n",
       "      (voucher_discount_amount): Embedding(500, 1)\n",
       "    )\n",
       "    (convs): ModuleList(\n",
       "      (0): GraphConv(18, 16)\n",
       "      (1): GraphConv(16, 16)\n",
       "    )\n",
       "    (pools): ModuleList(\n",
       "      (0): TopKPooling(16, ratio=0.9, multiplier=1)\n",
       "      (1): TopKPooling(16, ratio=0.9, multiplier=1)\n",
       "    )\n",
       "    (linears): ModuleList(\n",
       "      (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (gnet_before): VoucherGraphNet(\n",
       "    (emb_dic): ModuleDict(\n",
       "      (atc_emb): Embedding(344082, 16)\n",
       "      (ord_emb): Embedding(344082, 16)\n",
       "      (item_category_id): Embedding(6000, 1)\n",
       "      (item_price_level): Embedding(300, 1)\n",
       "      (promotion_id): Embedding(600, 16)\n",
       "      (voucher_min_spend): Embedding(500, 1)\n",
       "      (voucher_discount_amount): Embedding(500, 1)\n",
       "    )\n",
       "    (convs): ModuleList(\n",
       "      (0): GraphConv(18, 16)\n",
       "      (1): GraphConv(16, 16)\n",
       "    )\n",
       "    (pools): ModuleList(\n",
       "      (0): TopKPooling(16, ratio=0.9, multiplier=1)\n",
       "      (1): TopKPooling(16, ratio=0.9, multiplier=1)\n",
       "    )\n",
       "    (linears): ModuleList(\n",
       "      (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'DMBGN'\n",
    "\n",
    "model = DMBGN(dnn_feature_columns, \n",
    "              behavior_feature_list,\n",
    "              target_emb_dim_aft=0, \n",
    "              sequence_size=6,\n",
    "              device=device, \n",
    "              att_activation='prelu', \n",
    "              att_weight_normalization=False, \n",
    "              dnn_activation='relu', \n",
    "              l2_reg_dnn=0.1, \n",
    "              l2_reg_embedding = 0.0001, \n",
    "              dnn_hidden_units=(128,64), \n",
    "              att_hidden_size=(64,), \n",
    "              init_std=1, \n",
    "              dnn_dropout=0.5, \n",
    "              dnn_use_bn=True,\n",
    "              gnet_tune=True,\n",
    "              hist_gnn_dropout=0.6, \n",
    "              gnet=gnet, \n",
    "              gnet_before=gnet_before,\n",
    "              hash_sid_uvg_graphs_dic=hash_sid_uvg_graphs_dic)\n",
    "\n",
    "\n",
    "zeros = torch.zeros(len(label_encoder['session_id']), 1, dtype = torch.float)\n",
    "model.embedding_dict['session_id'] = torch.nn.Embedding.from_pretrained(zeros)\n",
    "model.embedding_dict['session_id'].requires_grad = False\n",
    "model.embedding_dict['session_id'].weight.requires_grad = False\n",
    "\n",
    "model.embedding_dict['hist_promotion_id'] = promotion_emb_bef_aft_16\n",
    "model.embedding_dict['hist_promotion_id'].requires_grad = False\n",
    "model.embedding_dict['hist_promotion_id'].weight.requires_grad = False\n",
    "\n",
    "model.embedding_dict['hist_sid'] = session_emb_bef_aft_16\n",
    "model.embedding_dict['hist_sid'].requires_grad = False\n",
    "model.embedding_dict['hist_sid'].weight.requires_grad = False\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.05, amsgrad=True)\n",
    "model.compile(optimizer, 'binary_crossentropy', metrics=['auc', 'logloss'])\n",
    "\n",
    "\n",
    "loss_func = model.loss_func\n",
    "optim = model.optim\n",
    "metrics = model.metrics\n",
    "feature_index = model.feature_index\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use 8 GPUs!\n"
     ]
    }
   ],
   "source": [
    "device_ids = [i for i in range(torch.cuda.device_count())]\n",
    "device_count = len(device_ids)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model = torch.nn.DataParallel(model, device_ids)\n",
    "    \n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 46361 samples, validate on 11690 samples, 155 steps per epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [25:42,  9.95s/it]\n",
      "1it [00:00,  8.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "Epoch Time : 2253\n",
      "2253s - loss:  1.2781 - auc:  0.6219 - logloss:  0.5095 - val_auc:  0.7131 - val_logloss:  0.4040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [24:06,  9.33s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "Epoch Time : 2159\n",
      "2159s - loss:  1.1431 - auc:  0.7344 - logloss:  0.3914 - val_auc:  0.7379 - val_logloss:  0.3882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [25:40,  9.94s/it]\n",
      "1it [00:00,  7.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "Epoch Time : 2254\n",
      "2254s - loss:  1.1025 - auc:  0.7571 - logloss:  0.3810 - val_auc:  0.7535 - val_logloss:  0.3811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [24:06,  9.33s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "Epoch Time : 2158\n",
      "2158s - loss:  1.1187 - auc:  0.7697 - logloss:  0.3742 - val_auc:  0.7607 - val_logloss:  0.3790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [25:34,  9.90s/it]\n",
      "1it [00:00,  8.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "Epoch Time : 2248\n",
      "2248s - loss:  1.1070 - auc:  0.7767 - logloss:  0.3703 - val_auc:  0.7676 - val_logloss:  0.3727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [24:00,  9.29s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "Epoch Time : 2150\n",
      "2150s - loss:  1.1004 - auc:  0.7842 - logloss:  0.3661 - val_auc:  0.7710 - val_logloss:  0.3722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [25:38,  9.93s/it]\n",
      "1it [00:00,  7.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "Epoch Time : 2247\n",
      "2247s - loss:  1.0944 - auc:  0.7889 - logloss:  0.3633 - val_auc:  0.7762 - val_logloss:  0.3687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [23:56,  9.27s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "Epoch Time : 2145\n",
      "2145s - loss:  1.1102 - auc:  0.7948 - logloss:  0.3596 - val_auc:  0.7779 - val_logloss:  0.3672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [25:32,  9.89s/it]\n",
      "1it [00:00,  8.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n",
      "Epoch Time : 2241\n",
      "2241s - loss:  1.0970 - auc:  0.7983 - logloss:  0.3580 - val_auc:  0.7772 - val_logloss:  0.3685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [23:59,  9.29s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n",
      "Epoch Time : 2148\n",
      "2148s - loss:  1.0955 - auc:  0.7998 - logloss:  0.3562 - val_auc:  0.7820 - val_logloss:  0.3643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [25:34,  9.90s/it]\n",
      "1it [00:00,  8.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "Epoch Time : 2241\n",
      "2241s - loss:  1.0736 - auc:  0.8033 - logloss:  0.3546 - val_auc:  0.7796 - val_logloss:  0.3668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [23:58,  9.28s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "Epoch Time : 2142\n",
      "2142s - loss:  1.0887 - auc:  0.8070 - logloss:  0.3518 - val_auc:  0.7815 - val_logloss:  0.3677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [25:26,  9.85s/it]\n",
      "1it [00:00,  8.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "Epoch Time : 2235\n",
      "2235s - loss:  1.0679 - auc:  0.8095 - logloss:  0.3495 - val_auc:  0.7812 - val_logloss:  0.3658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [23:53,  9.25s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n",
      "Epoch Time : 2142\n",
      "2142s - loss:  1.0991 - auc:  0.8107 - logloss:  0.3486 - val_auc:  0.7815 - val_logloss:  0.3644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [25:40,  9.94s/it]\n",
      "1it [00:00,  8.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20\n",
      "Epoch Time : 2256\n",
      "2256s - loss:  1.0765 - auc:  0.8120 - logloss:  0.3487 - val_auc:  0.7832 - val_logloss:  0.3635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [24:04,  9.32s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "Epoch Time : 2152\n",
      "2152s - loss:  1.0788 - auc:  0.8165 - logloss:  0.3447 - val_auc:  0.7779 - val_logloss:  0.3676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [25:43,  9.96s/it]\n",
      "1it [00:00,  8.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n",
      "Epoch Time : 2257\n",
      "2257s - loss:  1.0787 - auc:  0.8175 - logloss:  0.3436 - val_auc:  0.7809 - val_logloss:  0.3645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [24:06,  9.33s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20\n",
      "Epoch Time : 2158\n",
      "2158s - loss:  1.0738 - auc:  0.8192 - logloss:  0.3434 - val_auc:  0.7835 - val_logloss:  0.3644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [25:41,  9.95s/it]\n",
      "1it [00:00,  8.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n",
      "Epoch Time : 2260\n",
      "2260s - loss:  1.0717 - auc:  0.8210 - logloss:  0.3414 - val_auc:  0.7865 - val_logloss:  0.3620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [24:04,  9.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "Epoch Time : 2154\n",
      "2154s - loss:  1.0962 - auc:  0.8222 - logloss:  0.3402 - val_auc:  0.7827 - val_logloss:  0.3627\n"
     ]
    }
   ],
   "source": [
    "epoch = 20\n",
    "batch_size = 300\n",
    "res, pred1 = fit(model, feature_index, optim, metrics, loss_func, x, y, batch_size=batch_size, epochs=epoch, validation_data=(test_model_input1,test_label1),verbose=1, device=device, device_count=device_count)\n",
    "\n",
    "results[model_name] = model, res, pred1, test_label1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LR': (WDL(\n",
       "    (embedding_dict): ModuleDict()\n",
       "    (linear_model): Linear(\n",
       "      (embedding_dict): ModuleDict(\n",
       "        (promotion_id): Embedding(462, 1)\n",
       "        (session_id): Embedding(58052, 1)\n",
       "        (user_gender): Embedding(4, 1)\n",
       "        (user_age_level): Embedding(10, 1)\n",
       "        (user_purchase_level): Embedding(12, 1)\n",
       "      )\n",
       "    )\n",
       "    (out): PredictionLayer()\n",
       "  ),\n",
       "  {'eval_auc': 0.7376503953682485, 'eval_logloss': 0.3897108499613474},\n",
       "  array([[0.03800213],\n",
       "         [0.10965838],\n",
       "         [0.02754197],\n",
       "         ...,\n",
       "         [0.08124392],\n",
       "         [0.05961311],\n",
       "         [0.10519708]]),\n",
       "  32875    0\n",
       "  9359     0\n",
       "  39695    0\n",
       "  3915     0\n",
       "  47840    0\n",
       "          ..\n",
       "  9759     1\n",
       "  49961    0\n",
       "  8110     0\n",
       "  40668    0\n",
       "  23663    0\n",
       "  Name: label, Length: 11690, dtype: int64),\n",
       " 'xgBoost': (<xgboost.core.Booster at 0x2baa14cde1d0>,\n",
       "  {'eval_auc': 0.7480371818272428, 'eval_logloss': 0.38412074364042204},\n",
       "  array([0.01218249, 0.09592863, 0.04206705, ..., 0.06155384, 0.08038117,\n",
       "         0.07864305], dtype=float32),\n",
       "  32875    0\n",
       "  9359     0\n",
       "  39695    0\n",
       "  3915     0\n",
       "  47840    0\n",
       "          ..\n",
       "  9759     1\n",
       "  49961    0\n",
       "  8110     0\n",
       "  40668    0\n",
       "  23663    0\n",
       "  Name: label, Length: 11690, dtype: int64),\n",
       " 'DNN': (WDL(\n",
       "    (embedding_dict): ModuleDict(\n",
       "      (promotion_id): Embedding(462, 16)\n",
       "      (session_id): Embedding(58052, 16)\n",
       "      (user_gender): Embedding(4, 16)\n",
       "      (user_age_level): Embedding(10, 16)\n",
       "      (user_purchase_level): Embedding(12, 16)\n",
       "    )\n",
       "    (linear_model): Linear(\n",
       "      (embedding_dict): ModuleDict()\n",
       "    )\n",
       "    (out): PredictionLayer()\n",
       "    (dnn): DNN(\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "      (linears): ModuleList(\n",
       "        (0): Linear(in_features=88, out_features=128, bias=True)\n",
       "        (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "      )\n",
       "      (bn): ModuleList(\n",
       "        (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (activation_layers): ModuleList(\n",
       "        (0): ReLU(inplace=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (dnn_linear): Linear(in_features=64, out_features=1, bias=False)\n",
       "  ),\n",
       "  {'eval_auc': 0.7613638184814294, 'eval_logloss': 0.3783172404668609},\n",
       "  array([[0.01677375],\n",
       "         [0.06211503],\n",
       "         [0.01579599],\n",
       "         ...,\n",
       "         [0.03970122],\n",
       "         [0.09765757],\n",
       "         [0.08995593]]),\n",
       "  32875    0\n",
       "  9359     0\n",
       "  39695    0\n",
       "  3915     0\n",
       "  47840    0\n",
       "          ..\n",
       "  9759     1\n",
       "  49961    0\n",
       "  8110     0\n",
       "  40668    0\n",
       "  23663    0\n",
       "  Name: label, Length: 11690, dtype: int64),\n",
       " 'WDL': (WDL(\n",
       "    (embedding_dict): ModuleDict(\n",
       "      (promotion_id): Embedding(462, 16)\n",
       "      (session_id): Embedding(58052, 16)\n",
       "      (user_gender): Embedding(4, 16)\n",
       "      (user_age_level): Embedding(10, 16)\n",
       "      (user_purchase_level): Embedding(12, 16)\n",
       "    )\n",
       "    (linear_model): Linear(\n",
       "      (embedding_dict): ModuleDict(\n",
       "        (promotion_id): Embedding(462, 1)\n",
       "        (session_id): Embedding(58052, 1)\n",
       "        (user_gender): Embedding(4, 1)\n",
       "        (user_age_level): Embedding(10, 1)\n",
       "        (user_purchase_level): Embedding(12, 1)\n",
       "      )\n",
       "    )\n",
       "    (out): PredictionLayer()\n",
       "    (dnn): DNN(\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "      (linears): ModuleList(\n",
       "        (0): Linear(in_features=88, out_features=128, bias=True)\n",
       "        (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "      )\n",
       "      (bn): ModuleList(\n",
       "        (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (activation_layers): ModuleList(\n",
       "        (0): ReLU(inplace=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (dnn_linear): Linear(in_features=64, out_features=1, bias=False)\n",
       "  ),\n",
       "  {'eval_auc': 0.7708423984751682, 'eval_logloss': 0.3719189936696797},\n",
       "  array([[0.02149253],\n",
       "         [0.05581734],\n",
       "         [0.00913832],\n",
       "         ...,\n",
       "         [0.04136476],\n",
       "         [0.10225472],\n",
       "         [0.07887056]]),\n",
       "  32875    0\n",
       "  9359     0\n",
       "  39695    0\n",
       "  3915     0\n",
       "  47840    0\n",
       "          ..\n",
       "  9759     1\n",
       "  49961    0\n",
       "  8110     0\n",
       "  40668    0\n",
       "  23663    0\n",
       "  Name: label, Length: 11690, dtype: int64),\n",
       " 'DIN': (DataParallel(\n",
       "    (module): DIN(\n",
       "      (embedding_dict): ModuleDict(\n",
       "        (session_id): Embedding(58052, 16)\n",
       "        (user_gender): Embedding(4, 16)\n",
       "        (user_age_level): Embedding(10, 16)\n",
       "        (user_purchase_level): Embedding(12, 16)\n",
       "        (promotion_id): Embedding(462, 16)\n",
       "        (hist_promotion_id): Embedding(462, 16)\n",
       "      )\n",
       "      (linear_model): Linear(\n",
       "        (embedding_dict): ModuleDict()\n",
       "      )\n",
       "      (out): PredictionLayer()\n",
       "      (attention): HistAttentionSeqPoolingLayer(\n",
       "        (local_att): AttentionUnit(\n",
       "          (dnn): DNN(\n",
       "            (dropout): Dropout(p=0, inplace=False)\n",
       "            (linears): ModuleList(\n",
       "              (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "            )\n",
       "            (activation_layers): ModuleList(\n",
       "              (0): PReLU(num_parameters=1)\n",
       "            )\n",
       "          )\n",
       "          (dense): Linear(in_features=64, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dnn): DNN(\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "        (linears): ModuleList(\n",
       "          (0): Linear(in_features=104, out_features=128, bias=True)\n",
       "          (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "        )\n",
       "        (bn): ModuleList(\n",
       "          (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (activation_layers): ModuleList(\n",
       "          (0): ReLU(inplace=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (dnn_linear): Linear(in_features=64, out_features=1, bias=False)\n",
       "    )\n",
       "  ),\n",
       "  {'eval_auc': 0.7780161455756035, 'eval_logloss': 0.367873283307874},\n",
       "  array([[0.00571912],\n",
       "         [0.04304482],\n",
       "         [0.01293333],\n",
       "         ...,\n",
       "         [0.05002562],\n",
       "         [0.1725402 ],\n",
       "         [0.02827179]], dtype=float32),\n",
       "  array([0, 0, 0, ..., 0, 0, 0])),\n",
       " 'DMBGN_AvgPooling': (DataParallel(\n",
       "    (module): DMBGN(\n",
       "      (embedding_dict): ModuleDict(\n",
       "        (user_gender): Embedding(4, 16)\n",
       "        (user_age_level): Embedding(10, 16)\n",
       "        (user_purchase_level): Embedding(12, 16)\n",
       "        (session_id): Embedding(462, 32)\n",
       "        (promotion_id): Embedding(462, 32)\n",
       "        (sid): Embedding(58052, 16)\n",
       "        (hist_promotion_id): Embedding(462, 32)\n",
       "        (hist_session_id): Embedding(58052, 32)\n",
       "      )\n",
       "      (linear_model): Linear(\n",
       "        (embedding_dict): ModuleDict()\n",
       "      )\n",
       "      (out): PredictionLayer()\n",
       "      (attention): HistAttentionSeqPoolingLayer(\n",
       "        (local_att): AttentionUnit(\n",
       "          (dnn): DNN(\n",
       "            (dropout): Dropout(p=0, inplace=False)\n",
       "            (linears): ModuleList(\n",
       "              (0): Linear(in_features=256, out_features=64, bias=True)\n",
       "            )\n",
       "            (activation_layers): ModuleList(\n",
       "              (0): PReLU(num_parameters=1)\n",
       "            )\n",
       "          )\n",
       "          (dense): Linear(in_features=64, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dnn): DNN(\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "        (linears): ModuleList(\n",
       "          (0): Linear(in_features=209, out_features=128, bias=True)\n",
       "          (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "        )\n",
       "        (bn): ModuleList(\n",
       "          (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (activation_layers): ModuleList(\n",
       "          (0): ReLU(inplace=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (dnn_linear): Linear(in_features=64, out_features=1, bias=False)\n",
       "    )\n",
       "  ),\n",
       "  {'eval_auc': 0.7793704009269825, 'eval_logloss': 0.36966940263966636},\n",
       "  array([[0.00764415],\n",
       "         [0.02178934],\n",
       "         [0.00162929],\n",
       "         ...,\n",
       "         [0.0554126 ],\n",
       "         [0.08198448],\n",
       "         [0.0560065 ]], dtype=float32),\n",
       "  array([0, 0, 0, ..., 0, 0, 0])),\n",
       " 'DMBGN_Pretrained': (DataParallel(\n",
       "    (module): DMBGN(\n",
       "      (embedding_dict): ModuleDict(\n",
       "        (promotion_id): Embedding(462, 16)\n",
       "        (user_gender): Embedding(4, 16)\n",
       "        (user_age_level): Embedding(10, 16)\n",
       "        (user_purchase_level): Embedding(12, 16)\n",
       "        (sid): Embedding(462, 16)\n",
       "        (hist_promotion_id): Embedding(462, 16)\n",
       "        (hist_sid): Embedding(58052, 16)\n",
       "      )\n",
       "      (linear_model): Linear(\n",
       "        (embedding_dict): ModuleDict()\n",
       "      )\n",
       "      (out): PredictionLayer()\n",
       "      (attention): HistAttentionSeqPoolingLayer(\n",
       "        (local_att): AttentionUnit(\n",
       "          (dnn): DNN(\n",
       "            (dropout): Dropout(p=0, inplace=False)\n",
       "            (linears): ModuleList(\n",
       "              (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "            )\n",
       "            (activation_layers): ModuleList(\n",
       "              (0): PReLU(num_parameters=1)\n",
       "            )\n",
       "          )\n",
       "          (dense): Linear(in_features=64, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dnn): DNN(\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "        (linears): ModuleList(\n",
       "          (0): Linear(in_features=129, out_features=128, bias=True)\n",
       "          (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "        )\n",
       "        (bn): ModuleList(\n",
       "          (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (activation_layers): ModuleList(\n",
       "          (0): ReLU(inplace=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (dnn_linear): Linear(in_features=64, out_features=1, bias=False)\n",
       "    )\n",
       "  ),\n",
       "  {'eval_auc': 0.7812800357146465, 'eval_logloss': 0.3662845631863273},\n",
       "  array([[0.02528269],\n",
       "         [0.02130732],\n",
       "         [0.09286698],\n",
       "         ...,\n",
       "         [0.3230889 ],\n",
       "         [0.16891375],\n",
       "         [0.02704608]], dtype=float32),\n",
       "  array([1, 0, 0, ..., 0, 0, 0])),\n",
       " 'DMBGN': (DataParallel(\n",
       "    (module): DMBGN(\n",
       "      (embedding_dict): ModuleDict(\n",
       "        (promotion_id): Embedding(462, 16)\n",
       "        (user_gender): Embedding(4, 16)\n",
       "        (user_age_level): Embedding(10, 16)\n",
       "        (user_purchase_level): Embedding(12, 16)\n",
       "        (sid): Embedding(462, 16)\n",
       "        (session_id): Embedding(58052, 1)\n",
       "        (hist_promotion_id): Embedding(462, 16)\n",
       "        (hist_sid): Embedding(58052, 16)\n",
       "      )\n",
       "      (linear_model): Linear(\n",
       "        (embedding_dict): ModuleDict()\n",
       "      )\n",
       "      (out): PredictionLayer()\n",
       "      (attention): HistAttentionSeqPoolingLayer(\n",
       "        (local_att): AttentionUnit(\n",
       "          (dnn): DNN(\n",
       "            (dropout): Dropout(p=0, inplace=False)\n",
       "            (linears): ModuleList(\n",
       "              (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "            )\n",
       "            (activation_layers): ModuleList(\n",
       "              (0): PReLU(num_parameters=1)\n",
       "            )\n",
       "          )\n",
       "          (dense): Linear(in_features=64, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dnn): DNN(\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "        (linears): ModuleList(\n",
       "          (0): Linear(in_features=130, out_features=128, bias=True)\n",
       "          (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "        )\n",
       "        (bn): ModuleList(\n",
       "          (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (activation_layers): ModuleList(\n",
       "          (0): ReLU(inplace=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (dnn_linear): Linear(in_features=64, out_features=1, bias=False)\n",
       "      (gnet): VoucherGraphNet(\n",
       "        (emb_dic): ModuleDict(\n",
       "          (atc_emb): Embedding(344082, 16)\n",
       "          (ord_emb): Embedding(344082, 16)\n",
       "          (item_category_id): Embedding(6000, 1)\n",
       "          (item_price_level): Embedding(300, 1)\n",
       "          (promotion_id): Embedding(600, 16)\n",
       "          (voucher_min_spend): Embedding(500, 1)\n",
       "          (voucher_discount_amount): Embedding(500, 1)\n",
       "        )\n",
       "        (convs): ModuleList(\n",
       "          (0): GraphConv(18, 16)\n",
       "          (1): GraphConv(16, 16)\n",
       "        )\n",
       "        (pools): ModuleList(\n",
       "          (0): TopKPooling(16, ratio=0.9, multiplier=1)\n",
       "          (1): TopKPooling(16, ratio=0.9, multiplier=1)\n",
       "        )\n",
       "        (linears): ModuleList(\n",
       "          (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (gnet_before): VoucherGraphNet(\n",
       "        (emb_dic): ModuleDict(\n",
       "          (atc_emb): Embedding(344082, 16)\n",
       "          (ord_emb): Embedding(344082, 16)\n",
       "          (item_category_id): Embedding(6000, 1)\n",
       "          (item_price_level): Embedding(300, 1)\n",
       "          (promotion_id): Embedding(600, 16)\n",
       "          (voucher_min_spend): Embedding(500, 1)\n",
       "          (voucher_discount_amount): Embedding(500, 1)\n",
       "        )\n",
       "        (convs): ModuleList(\n",
       "          (0): GraphConv(18, 16)\n",
       "          (1): GraphConv(16, 16)\n",
       "        )\n",
       "        (pools): ModuleList(\n",
       "          (0): TopKPooling(16, ratio=0.9, multiplier=1)\n",
       "          (1): TopKPooling(16, ratio=0.9, multiplier=1)\n",
       "        )\n",
       "        (linears): ModuleList(\n",
       "          (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  ),\n",
       "  {'eval_auc': 0.7865292742427323, 'eval_logloss': 0.36200660894000375},\n",
       "  array([[0.01149733],\n",
       "         [0.03468504],\n",
       "         [0.12029126],\n",
       "         ...,\n",
       "         [0.50393295],\n",
       "         [0.0808762 ],\n",
       "         [0.02275017]], dtype=float32),\n",
       "  array([1, 0, 0, ..., 0, 0, 0]))}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "i = 0\n",
    "lw = 1\n",
    "\n",
    "colors = [\"cornflowerblue\", \"darkorange\", \"red\", \"blue\", \"green\", \"violet\", \"black\", \"purple\", \"olive\", \"cyan\"]\n",
    "\n",
    "\n",
    "for model_name, (model, res, pred1, test_label1) in results.items():\n",
    "    fpr[i], tpr[i], _ = roc_curve(test_label1.astype(int),  pred1)\n",
    "    roc_auc = auc(fpr[i], tpr[i])\n",
    "    plt.plot(fpr[i], tpr[i], color=colors[i], lw=lw, label = model_name + ' ROC curve (area = ' + str(round(roc_auc, 4)) + ')')\n",
    "\n",
    "    i += 1\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    \n",
    "plt.title('User-Voucher Redemption Dataset ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------+---------------+---------------+---------+\n",
      "|      Model       |  AUC   | RelaImpr(DNN) | RelaImpr(DIN) | Logloss |\n",
      "+------------------+--------+---------------+---------------+---------+\n",
      "|        LR        | 0.7377 |     -9.07%    |    -14.52%    |  0.3897 |\n",
      "|     xgBoost      | 0.7480 |     -5.10%    |    -10.78%    |  0.3841 |\n",
      "|       DNN        | 0.7614 |     0.00%     |     -5.99%    |  0.3783 |\n",
      "|       WDL        | 0.7708 |     3.63%     |     -2.58%    |  0.3719 |\n",
      "|       DIN        | 0.7780 |     6.37%     |     0.00%     |  0.3679 |\n",
      "| DMBGN_AvgPooling | 0.7794 |     6.89%     |     0.49%     |  0.3697 |\n",
      "| DMBGN_Pretrained | 0.7813 |     7.62%     |     1.17%     |  0.3663 |\n",
      "|      DMBGN       | 0.7865 |     9.63%     |     3.06%     |  0.3620 |\n",
      "+------------------+--------+---------------+---------------+---------+\n"
     ]
    }
   ],
   "source": [
    "def relaImpr(a, b):\n",
    "    x = ((a-0.5)/(b-0.5) - 1.0)*100.0\n",
    "    return str(\"%.2f\" % x) + '%'\n",
    "\n",
    "dnn_auc = results['DNN'][1]['eval_auc']\n",
    "din_auc = results['DIN'][1]['eval_auc']\n",
    "\n",
    "table = PrettyTable(['Model','AUC','RelaImpr(DNN)','RelaImpr(DIN)', 'Logloss'], digits = 4, rounds=True)\n",
    "for model_name, (model, res, pred1, test_label1) in results.items():\n",
    "    table.add_row([model_name, \"%.4f\" % res['eval_auc'], relaImpr(res['eval_auc'], dnn_auc), relaImpr(res['eval_auc'], din_auc), \"%.4f\" % res['eval_logloss']])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [1] H Brendan McMahan, Gary Holt, David Sculley, Michael Young, Dietmar Ebner,Julian Grady, Lan Nie, Todd Phillips, Eugene Davydov, Daniel Golovin, et al.2013.  Ad click prediction: a view from the trenches. InProceedings of the 19thACM SIGKDD international conference on Knowledge discovery and data mining.1222–1230.\n",
    "- [2] Guolin Ke, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma,Qiwei Ye, and Tie-Yan Liu. 2017. Lightgbm: A highly efficient gradient boostingdecision tree.Advances in neural information processing systems30 (2017), 3146–3154.\n",
    "- [3] Heng-Tze Cheng, Levent Koc, Jeremiah Harmsen, Tal Shaked, Tushar Chandra,Hrishi Aradhye, Glen Anderson, Greg Corrado, Wei Chai, Mustafa Ispir, RohanAnil, Zakaria Haque, Lichan Hong, Vihan Jain, Xiaobing Liu, and Hemal Shah.2016. Wide & Deep Learning for Recommender Systems.CoRRabs/1606.07792(2016). arXiv:1606.07792  http://arxiv.org/abs/1606.07792 .\n",
    "- [4] Guorui Zhou, Xiaoqiang Zhu, Chenru Song, Ying Fan, Han Zhu, Xiao Ma, YanghuiYan, Junqi Jin, Han Li, and Kun Gai. 2018. Deep interest network for click-throughrate prediction. InProceedings of the 24th ACM SIGKDD International Conferenceon Knowledge Discovery & Data Mining. 1059–1068."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "304.406px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
